{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"KnowledgeBase.csv\")\n",
    "df2 = pd.read_csv(\"KnowledgeBase_majorityvotecluster.csv\")\n",
    "df1.fillna(0,inplace=True)\n",
    "df2.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_char_raw1 = df1[[ 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "df_quality_raw1 = df1[['Completeness', 'Conciseness', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'LabelIssuesPerc', 'FeatureAlgo']]\n",
    "\n",
    "df_raw1 = df1[['Completeness', 'Conciseness', 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'LabelIssuesPerc','nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "\n",
    "df_char_bin1 = df1[['cor.mean_bins', 'cov.mean_bins',\n",
    "       'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins',\n",
    "       'iq_range.mean_bins', 'kurtosis.mean_bins', 'mad.mean_bins',\n",
    "       'max.mean_bins', 'mean.mean_bins', 'median.mean_bins', 'min.mean_bins',\n",
    "       'nr_cor_attr_bins', 'nr_norm_bins', 'nr_outliers_bins',\n",
    "       'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "       'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins',\n",
    "       'attr_to_inst_bins', 'inst_to_attr_bins',\n",
    "       'nr_attr_bins', 'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins',\n",
    "       'attr_conc.mean_bins', 'attr_ent.mean_bins', 'ena_bins',\n",
    "       'snr.mean_bins', 'cEntropy_bins','FeatureAlgo']]\n",
    "\n",
    "df_quality_bin1 = df1[['Completeness_bins',\n",
    "       'Conciseness_bins', 'LabelIssues_bins', 'ClassImbRatio_bins', 'OutlierPerc_bins',\n",
    "       'ClassOverlapPerc_bins','FeatureAlgo']]\n",
    "\n",
    "df_bin1 = df1[['Completeness_bins',\n",
    "       'Conciseness_bins', 'cor.mean_bins', 'cov.mean_bins',\n",
    "       'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins',\n",
    "       'iq_range.mean_bins', 'kurtosis.mean_bins', 'mad.mean_bins',\n",
    "       'max.mean_bins', 'mean.mean_bins', 'median.mean_bins', 'min.mean_bins',\n",
    "       'nr_cor_attr_bins', 'nr_norm_bins', 'nr_outliers_bins',\n",
    "       'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "       'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins',\n",
    "       'LabelIssues_bins', 'ClassImbRatio_bins', 'OutlierPerc_bins',\n",
    "       'ClassOverlapPerc_bins', 'attr_to_inst_bins', 'inst_to_attr_bins',\n",
    "       'nr_attr_bins', 'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins',\n",
    "       'attr_conc.mean_bins', 'attr_ent.mean_bins', 'ena_bins',\n",
    "       'snr.mean_bins', 'cEntropy_bins', 'FeatureAlgo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_char_raw2 = df2[[ 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "df_quality_raw2 = df2[['Completeness', 'Conciseness', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'LabelIssuesPerc', 'FeatureAlgo']]\n",
    "\n",
    "df_raw2 = df2[['Completeness', 'Conciseness', 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'LabelIssuesPerc','nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "\n",
    "df_char_bin2 = df2[['cor.mean_bins', 'cov.mean_bins',\n",
    "       'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins',\n",
    "       'iq_range.mean_bins', 'kurtosis.mean_bins', 'mad.mean_bins',\n",
    "       'max.mean_bins', 'mean.mean_bins', 'median.mean_bins', 'min.mean_bins',\n",
    "       'nr_cor_attr_bins', 'nr_norm_bins', 'nr_outliers_bins',\n",
    "       'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "       'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins',\n",
    "       'attr_to_inst_bins', 'inst_to_attr_bins',\n",
    "       'nr_attr_bins', 'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins',\n",
    "       'attr_conc.mean_bins', 'attr_ent.mean_bins', 'ena_bins',\n",
    "       'snr.mean_bins', 'cEntropy_bins','FeatureAlgo']]\n",
    "\n",
    "df_quality_bin2 = df2[['Completeness_bins',\n",
    "       'Conciseness_bins', 'LabelIssues_bins', 'ClassImbRatio_bins', 'OutlierPerc_bins',\n",
    "       'ClassOverlapPerc_bins','FeatureAlgo']]\n",
    "\n",
    "df_bin2 = df2[['Completeness_bins',\n",
    "       'Conciseness_bins', 'cor.mean_bins', 'cov.mean_bins',\n",
    "       'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins',\n",
    "       'iq_range.mean_bins', 'kurtosis.mean_bins', 'mad.mean_bins',\n",
    "       'max.mean_bins', 'mean.mean_bins', 'median.mean_bins', 'min.mean_bins',\n",
    "       'nr_cor_attr_bins', 'nr_norm_bins', 'nr_outliers_bins',\n",
    "       'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "       'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins',\n",
    "       'LabelIssues_bins', 'ClassImbRatio_bins', 'OutlierPerc_bins',\n",
    "       'ClassOverlapPerc_bins', 'attr_to_inst_bins', 'inst_to_attr_bins',\n",
    "       'nr_attr_bins', 'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins',\n",
    "       'attr_conc.mean_bins', 'attr_ent.mean_bins', 'ena_bins',\n",
    "       'snr.mean_bins', 'cEntropy_bins', 'FeatureAlgo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chisquare    92\n",
      "GR           51\n",
      "fcbf         16\n",
      "relief        8\n",
      "MI            6\n",
      "Name: FeatureAlgo, dtype: int64\n",
      "chisquare    86\n",
      "GR           54\n",
      "fcbf         17\n",
      "relief        8\n",
      "MI            8\n",
      "Name: FeatureAlgo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1['FeatureAlgo'].value_counts())\n",
    "print(df2['FeatureAlgo'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update df_raw\n",
    "df_raw1['labels_tuple'] = df_raw1.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_raw1['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_raw1[df_raw1['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_raw1 = df_filtered\n",
    "\n",
    "#update df_char_raw\n",
    "df_char_raw1['labels_tuple'] = df_char_raw1.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_char_raw1['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_char_raw1[df_char_raw1['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_char_raw1 = df_filtered\n",
    "\n",
    "#update df_quality_raw\n",
    "df_quality_raw1['labels_tuple'] = df_quality_raw1.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_quality_raw1['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_quality_raw1[df_quality_raw1['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_quality_raw1 = df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#update df_raw\n",
    "df_raw2['labels_tuple'] = df_raw2.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_raw2['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_raw2[df_raw2['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_raw2 = df_filtered\n",
    "\n",
    "#update df_char_raw\n",
    "df_char_raw2['labels_tuple'] = df_char_raw2.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_char_raw2['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_char_raw2[df_char_raw2['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_char_raw2 = df_filtered\n",
    "\n",
    "#update df_quality_raw\n",
    "df_quality_raw2['labels_tuple'] = df_quality_raw2.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_quality_raw2['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_quality_raw2[df_quality_raw2['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_quality_raw2 = df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update df_bin\n",
    "df_bin1['labels_tuple'] = df_bin1.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_bin1['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_bin1[df_bin1['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_bin1 = df_filtered\n",
    "\n",
    "#update df_char_bin\n",
    "df_char_bin1['labels_tuple'] = df_char_bin1.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_char_bin1['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_char_bin1[df_char_bin1['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_char_bin1 = df_filtered\n",
    "\n",
    "#update df_quality_bin\n",
    "df_quality_bin1['labels_tuple'] = df_quality_bin1.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_quality_bin1['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_quality_bin1[df_quality_bin1['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_quality_bin1 = df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/d19125691/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#update df_bin\n",
    "df_bin2['labels_tuple'] = df_bin2.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_bin2['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_bin2[df_bin2['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_bin2 = df_filtered\n",
    "\n",
    "#update df_char_bin\n",
    "df_char_bin2['labels_tuple'] = df_char_bin2.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_char_bin2['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_char_bin2[df_char_bin2['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_char_bin2 = df_filtered\n",
    "\n",
    "#update df_quality_bin\n",
    "df_quality_bin2['labels_tuple'] = df_quality_bin2.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_quality_bin2['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_quality_bin2[df_quality_bin2['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_quality_bin2 = df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************KNN - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.622399                    0.377601   \n",
      "df_char_raw                     0.622399                    0.377601   \n",
      "df_quality_raw                  0.527138                    0.472862   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.608696        0.391304  0.652656  0.608696  0.610317   \n",
      "df_char_raw         0.608696        0.391304  0.652656  0.608696  0.610317   \n",
      "df_quality_raw       0.48913         0.51087   0.45243   0.48913  0.457957   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[12, 1, 2, 0, 0], [2, 14, 0, 0, 0], [8, 2, 5,...  \n",
      "df_char_raw     [[12, 1, 2, 0, 0], [2, 14, 0, 0, 0], [8, 2, 5,...  \n",
      "df_quality_raw  [[11, 1, 2, 0, 1], [2, 11, 1, 2, 0], [9, 1, 1,...  \n",
      "\n",
      "\n",
      "**************KNN - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.563896                    0.436104   \n",
      "df_char_raw                     0.563896                    0.436104   \n",
      "df_quality_raw                  0.584228                    0.415772   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.569767        0.430233  0.637987  0.569767  0.577614   \n",
      "df_char_raw         0.569767        0.430233  0.637987  0.569767  0.577614   \n",
      "df_quality_raw      0.523256        0.476744  0.536185  0.523256  0.520857   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[10, 2, 4, 0, 0], [2, 10, 0, 2, 0], [5, 0, 6,...  \n",
      "df_char_raw     [[10, 2, 4, 0, 0], [2, 10, 0, 2, 0], [5, 0, 6,...  \n",
      "df_quality_raw  [[8, 1, 5, 2, 0], [1, 12, 0, 0, 1], [3, 0, 3, ...  \n"
     ]
    }
   ],
   "source": [
    "def evaluate_knn(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=4)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(knn_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "datasets1 = {\n",
    "    'df_raw': df_raw1,\n",
    "    'df_char_raw': df_char_raw1,\n",
    "    'df_quality_raw': df_quality_raw1\n",
    "}\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************KNN - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "datasets2 = {\n",
    "    'df_raw': df_raw2,\n",
    "    'df_char_raw': df_char_raw2,\n",
    "    'df_quality_raw': df_quality_raw2\n",
    "}\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************KNN - Majority clustering**************\\n\")\n",
    "print(comparison_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************DT - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.785524                    0.214476   \n",
      "df_char_raw                     0.744798                    0.255202   \n",
      "df_quality_raw                  0.622584                    0.377416   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw               0.76087         0.23913   0.77033   0.76087  0.753872   \n",
      "df_char_raw         0.728261        0.271739  0.744167  0.728261  0.713651   \n",
      "df_quality_raw      0.586957        0.413043  0.584077  0.586957  0.567055   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[10, 1, 3, 1, 0], [0, 14, 0, 2, 0], [8, 0, 7,...  \n",
      "df_char_raw     [[10, 1, 0, 2, 2], [0, 14, 0, 2, 0], [7, 0, 6,...  \n",
      "df_quality_raw  [[13, 1, 0, 0, 1], [1, 15, 0, 0, 0], [8, 3, 4,...  \n",
      "\n",
      "\n",
      "**************DT - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.688917                    0.311083   \n",
      "df_char_raw                     0.697698                    0.302302   \n",
      "df_quality_raw                   0.64838                     0.35162   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.732558        0.267442  0.757937  0.732558  0.742562   \n",
      "df_char_raw         0.662791        0.337209  0.683856  0.662791  0.670876   \n",
      "df_quality_raw      0.581395        0.418605   0.60829  0.581395  0.589867   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[11, 0, 5, 0, 0], [1, 12, 0, 1, 0], [4, 0, 5,...  \n",
      "df_char_raw     [[6, 0, 8, 0, 2], [1, 11, 0, 2, 0], [4, 0, 5, ...  \n",
      "df_quality_raw  [[7, 0, 6, 3, 0], [1, 12, 0, 1, 0], [4, 1, 4, ...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_decision_tree(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  \n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)    \n",
    "    tree_classifier = DecisionTreeClassifier(random_state=random_state)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(tree_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "    y_pred = tree_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************DT - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************DT - Majority clustering**************\\n\")\n",
    "print(comparison_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************Distance based - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.708696                    0.291304   \n",
      "df_char_raw                     0.708696                    0.291304   \n",
      "df_quality_raw                  0.617391                    0.382609   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.717391        0.282609  0.727137  0.717391   0.71314   \n",
      "df_char_raw         0.717391        0.282609  0.727137  0.717391   0.71314   \n",
      "df_quality_raw      0.586957        0.413043  0.556289  0.586957  0.567659   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[12, 0, 3, 0, 0], [2, 12, 0, 2, 0], [5, 1, 7,...  \n",
      "df_char_raw     [[12, 0, 3, 0, 0], [2, 12, 0, 2, 0], [5, 1, 7,...  \n",
      "df_quality_raw  [[12, 0, 2, 1, 0], [0, 12, 1, 3, 0], [3, 3, 4,...  \n",
      "\n",
      "\n",
      "**************Distance based - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.637209                    0.362791   \n",
      "df_char_raw                     0.637209                    0.362791   \n",
      "df_quality_raw                  0.637209                    0.362791   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.593023        0.406977  0.627966  0.593023  0.600687   \n",
      "df_char_raw         0.593023        0.406977  0.627966  0.593023  0.600687   \n",
      "df_quality_raw      0.604651        0.395349  0.632587  0.604651  0.605682   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[12, 0, 4, 0, 0], [0, 10, 0, 4, 0], [3, 0, 5,...  \n",
      "df_char_raw     [[12, 0, 4, 0, 0], [0, 10, 0, 4, 0], [3, 0, 5,...  \n",
      "df_quality_raw  [[10, 1, 4, 1, 0], [1, 12, 1, 0, 0], [2, 1, 5,...  \n"
     ]
    }
   ],
   "source": [
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "metric_name = 'Euclidean'\n",
    "metric_func = lambda X_train, X_test: np.sqrt(((X_train.values[:, np.newaxis] - X_test.values) ** 2).sum(axis=2))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=33)\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "\n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    \n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predicted_labels = y_train[nearest_indices]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    results1[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "\n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    \n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predicted_labels = y_train[nearest_indices]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    results2[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"**************Distance based - 0.1_0.06**************\\n\")\n",
    "print(results_df1)\n",
    "\n",
    "print(\"\\n\\n**************Distance based - Majority clustering**************\\n\")\n",
    "print(results_df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************Unification - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                               0.8                         0.2   \n",
      "df_char_raw                          0.8                         0.2   \n",
      "df_quality_raw                      0.53                        0.47   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.666667        0.333333  0.666667  0.666667  0.666667   \n",
      "df_char_raw         0.666667        0.333333  0.666667  0.666667  0.666667   \n",
      "df_quality_raw          0.75            0.25      0.75      0.75      0.75   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw                          [[0, 0, 0], [1, 0, 0], [0, 0, 2]]  \n",
      "df_char_raw                     [[0, 0, 0], [1, 0, 0], [0, 0, 2]]  \n",
      "df_quality_raw  [[2, 0, 0, 0], [0, 2, 1, 0], [0, 1, 0, 0], [0,...  \n",
      "\n",
      "\n",
      "**************Unification - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                              0.75                        0.25   \n",
      "df_char_raw                         0.75                        0.25   \n",
      "df_quality_raw                  0.516212                    0.483788   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.666667        0.333333  0.666667  0.666667  0.666667   \n",
      "df_char_raw         0.666667        0.333333  0.666667  0.666667  0.666667   \n",
      "df_quality_raw      0.833333        0.166667  0.722222  0.833333  0.766667   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw                          [[0, 0, 0], [1, 0, 0], [0, 0, 2]]  \n",
      "df_char_raw                     [[0, 0, 0], [1, 0, 0], [0, 0, 2]]  \n",
      "df_quality_raw  [[1, 0, 0, 0], [0, 2, 0, 0], [0, 1, 0, 0], [0,...  \n"
     ]
    }
   ],
   "source": [
    "def unify_features(test_sample, train_data, train_labels):\n",
    "    test_features = test_sample.values\n",
    "    matching_indices = np.all(train_data == test_features, axis=1)\n",
    "    if matching_indices.any():\n",
    "        matching_labels = train_labels[matching_indices]\n",
    "        return np.unique(matching_labels)\n",
    "    return [\"unknown\"]\n",
    "\n",
    "def evaluate_unification(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        predicted_labels = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "            predicted_labels.append(label)\n",
    "        \n",
    "        predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "        valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        if not valid_indices:\n",
    "            continue\n",
    "        \n",
    "        valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "\n",
    "        valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "        cv_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "       \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    predicted_labels = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "        predicted_labels.append(label)\n",
    "    predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "    valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        \n",
    "    valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "    valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "    precision = precision_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(valid_truth, valid_predictions)    \n",
    "    test_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "\n",
    "    return {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_unification(df)\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_unification(df)\n",
    "\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"**************Unification - 0.1_0.06**************\\n\")\n",
    "print(results_df1)\n",
    "\n",
    "print(\"\\n\\n**************Unification - Majority clustering**************\\n\")\n",
    "print(results_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************KNN - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.660348                    0.339652   \n",
      "df_char_bin                     0.584043                    0.415957   \n",
      "df_quality_bin                   0.43221                     0.56779   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin               0.73913         0.26087  0.774245   0.73913  0.719318   \n",
      "df_char_bin         0.532609        0.467391  0.549597  0.532609  0.509996   \n",
      "df_quality_bin      0.315217        0.684783  0.263472  0.315217  0.258322   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[11, 0, 1, 1, 2], [0, 16, 0, 0, 0], [9, 1, 5,...  \n",
      "df_char_bin     [[6, 1, 1, 5, 2], [0, 15, 0, 1, 0], [9, 1, 3, ...  \n",
      "df_quality_bin  [[3, 5, 2, 5, 0], [0, 16, 0, 0, 0], [11, 1, 5,...  \n",
      "\n",
      "\n",
      "**************KNN - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                           0.62792                     0.37208   \n",
      "df_char_bin                      0.52029                     0.47971   \n",
      "df_quality_bin                  0.424808                    0.575192   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.662791        0.337209   0.65302  0.662791  0.653054   \n",
      "df_char_bin         0.430233        0.569767  0.489275  0.430233  0.415669   \n",
      "df_quality_bin      0.383721        0.616279   0.47704  0.383721  0.377925   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[9, 0, 3, 2, 2], [0, 12, 1, 0, 1], [9, 0, 1, ...  \n",
      "df_char_bin     [[5, 4, 3, 3, 1], [0, 14, 0, 0, 0], [4, 3, 1, ...  \n",
      "df_quality_bin  [[6, 2, 2, 6, 0], [2, 8, 0, 2, 2], [4, 1, 4, 3...  \n"
     ]
    }
   ],
   "source": [
    "def evaluate_knn(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(knn_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "datasets1 = {\n",
    "    'df_bin': df_bin1,\n",
    "    'df_char_bin': df_char_bin1,\n",
    "    'df_quality_bin': df_quality_bin1\n",
    "}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************KNN - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "datasets2 = {\n",
    "    'df_bin': df_bin2,\n",
    "    'df_char_bin': df_char_bin2,\n",
    "    'df_quality_bin': df_quality_bin2\n",
    "}\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************KNN - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************DT - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.682007                    0.317993   \n",
      "df_char_bin                     0.587042                    0.412958   \n",
      "df_quality_bin                  0.500037                    0.499963   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.793478        0.206522  0.792472  0.793478   0.77019   \n",
      "df_char_bin         0.554348        0.445652  0.627435  0.554348   0.53412   \n",
      "df_quality_bin      0.456522        0.543478  0.498372  0.456522  0.428068   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[12, 0, 1, 0, 2], [0, 16, 0, 0, 0], [7, 1, 6,...  \n",
      "df_char_bin     [[6, 1, 1, 7, 0], [0, 15, 0, 1, 0], [8, 1, 3, ...  \n",
      "df_quality_bin  [[3, 3, 2, 2, 5], [0, 15, 0, 0, 1], [11, 0, 5,...  \n",
      "\n",
      "\n",
      "**************DT - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.680179                    0.319821   \n",
      "df_char_bin                     0.549403                    0.450597   \n",
      "df_quality_bin                  0.453623                    0.546377   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.755814        0.244186   0.75306  0.755814  0.750533   \n",
      "df_char_bin         0.569767        0.430233  0.566735  0.569767  0.549297   \n",
      "df_quality_bin      0.523256        0.476744  0.500802  0.523256  0.505255   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[11, 1, 2, 1, 1], [0, 13, 0, 0, 1], [6, 0, 4,...  \n",
      "df_char_bin     [[3, 1, 6, 6, 0], [0, 9, 2, 0, 3], [4, 1, 5, 1...  \n",
      "df_quality_bin  [[2, 2, 2, 6, 4], [3, 9, 0, 0, 2], [2, 1, 5, 2...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_decision_tree(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)    \n",
    "    tree_classifier = DecisionTreeClassifier(random_state=random_state)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(tree_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "    y_pred = tree_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "datasets1 = {\n",
    "    'df_bin': df_bin1,\n",
    "    'df_char_bin': df_char_bin1,\n",
    "    'df_quality_bin': df_quality_bin1\n",
    "}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************DT - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "datasets2 = {\n",
    "    'df_bin': df_bin2,\n",
    "    'df_char_bin': df_char_bin2,\n",
    "    'df_quality_bin': df_quality_bin2\n",
    "}\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************DT - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Distance based - 0.1_0.06*************\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.558696                    0.441304   \n",
      "df_char_bin                     0.352174                    0.647826   \n",
      "df_quality_bin                  0.258696                    0.741304   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.663043        0.336957  0.644136  0.663043  0.646848   \n",
      "df_char_bin         0.543478        0.456522  0.633122  0.543478  0.539469   \n",
      "df_quality_bin      0.445652        0.554348  0.444755  0.445652  0.423903   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[10, 0, 4, 1, 0], [0, 15, 1, 0, 0], [10, 1, 3...  \n",
      "df_char_bin     [[9, 1, 0, 4, 1], [1, 9, 0, 6, 0], [9, 1, 4, 4...  \n",
      "df_quality_bin  [[3, 2, 2, 5, 3], [0, 9, 2, 5, 0], [5, 1, 4, 7...  \n",
      "\n",
      "\n",
      "***************Distance based - Majority cluster*************\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.513953                    0.486047   \n",
      "df_char_bin                     0.365116                    0.634884   \n",
      "df_quality_bin                  0.237209                    0.762791   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.639535        0.360465  0.653553  0.639535  0.643612   \n",
      "df_char_bin          0.44186         0.55814  0.495448   0.44186  0.445494   \n",
      "df_quality_bin      0.372093        0.627907  0.444918  0.372093  0.348866   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[7, 0, 3, 5, 1], [0, 11, 2, 0, 1], [6, 0, 3, ...  \n",
      "df_char_bin     [[6, 3, 3, 3, 1], [2, 10, 0, 2, 0], [3, 2, 3, ...  \n",
      "df_quality_bin  [[5, 0, 3, 8, 0], [3, 3, 3, 3, 2], [2, 1, 6, 3...  \n"
     ]
    }
   ],
   "source": [
    "datasets1 = {\n",
    "    'df_bin': df_bin1,\n",
    "    'df_char_bin': df_char_bin1,\n",
    "    'df_quality_bin': df_quality_bin1\n",
    "}\n",
    "datasets2 = {\n",
    "    'df_bin': df_bin2,\n",
    "    'df_char_bin': df_char_bin2,\n",
    "    'df_quality_bin': df_quality_bin2\n",
    "}\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "metric_name = 'Euclidean'\n",
    "metric_func = lambda X_train, X_test: np.sqrt(((X_train.values[:, np.newaxis] - X_test.values) ** 2).sum(axis=2))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=33)\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "    \n",
    "  \n",
    "    cv_accuracies = []\n",
    "\n",
    "        \n",
    "    smote = SMOTE(random_state=33)\n",
    "    \n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    \n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predicted_labels = y_train[nearest_indices]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    results1[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "    \n",
    "  \n",
    "    cv_accuracies = []\n",
    "\n",
    "        \n",
    "    smote = SMOTE(random_state=33)\n",
    "    \n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    \n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predicted_labels = y_train[nearest_indices]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    results2[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"***************Distance based - 0.1_0.06*************\")\n",
    "print(results_df1)\n",
    "print(\"\\n\\n***************Distance based - Majority cluster*************\")\n",
    "print(results_df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Unification - 0.1_0.06**********************\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.187415                    0.812585   \n",
      "df_char_bin                     0.214944                    0.785056   \n",
      "df_quality_bin                  0.191121                    0.808879   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.192771        0.807229   0.20642  0.192771  0.195181   \n",
      "df_char_bin         0.131868        0.868132  0.150536  0.131868  0.137932   \n",
      "df_quality_bin      0.230769        0.769231  0.234008  0.230769  0.221084   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[2, 1, 4, 2, 4], [5, 1, 3, 5, 1], [6, 2, 2, 3...  \n",
      "df_char_bin     [[2, 2, 6, 3, 1], [5, 3, 5, 0, 3], [8, 2, 1, 2...  \n",
      "df_quality_bin  [[7, 3, 1, 4, 0], [4, 1, 4, 3, 3], [4, 3, 5, 5...  \n",
      "***************Unification - majority voting**********************\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.193086                    0.806914   \n",
      "df_char_bin                     0.183586                    0.816414   \n",
      "df_quality_bin                  0.195863                    0.804137   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.194444        0.805556  0.199025  0.194444  0.195565   \n",
      "df_char_bin         0.188235        0.811765  0.212543  0.188235  0.196768   \n",
      "df_quality_bin      0.174419        0.825581  0.205165  0.174419  0.178782   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[3, 1, 5, 2, 3], [1, 0, 1, 3, 4], [3, 2, 2, 3...  \n",
      "df_char_bin     [[3, 3, 3, 3, 4], [3, 1, 4, 5, 1], [5, 2, 2, 2...  \n",
      "df_quality_bin  [[4, 1, 2, 7, 2], [1, 1, 6, 4, 2], [5, 4, 2, 0...  \n"
     ]
    }
   ],
   "source": [
    "def unify_features(test_sample, train_data, train_labels):\n",
    "    test_features = test_sample.values\n",
    "    matching_indices = np.all(train_data == test_features, axis=1)\n",
    "    if matching_indices.any():\n",
    "        matching_labels = train_labels[matching_indices]\n",
    "        return np.unique(matching_labels)\n",
    "    return [\"unknown\"]\n",
    "\n",
    "def evaluate_unification(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "    \n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        predicted_labels = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "            predicted_labels.append(label)\n",
    "        \n",
    "        predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "        valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        if not valid_indices:\n",
    "            continue\n",
    "        \n",
    "        valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "\n",
    "        valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "        cv_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "       \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    predicted_labels = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "        predicted_labels.append(label)\n",
    "    predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "    valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        \n",
    "    valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "    valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "    precision = precision_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(valid_truth, valid_predictions)    \n",
    "    test_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "\n",
    "    return {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "datasets1 = {\n",
    "    'df_bin': df_bin1,\n",
    "    'df_char_bin': df_char_bin1,\n",
    "    'df_quality_bin': df_quality_bin1\n",
    "}\n",
    "datasets2 = {\n",
    "    'df_bin': df_bin2,\n",
    "    'df_char_bin': df_char_bin2,\n",
    "    'df_quality_bin': df_quality_bin2\n",
    "}\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_unification(df)\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_unification(df)\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"***************Unification - 0.1_0.06**********************\")\n",
    "print(results_df1)\n",
    "print(\"***************Unification - majority voting**********************\")\n",
    "print(results_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_normalised1 = pd.read_csv(\"NormalisedDataset_01006.csv\")\n",
    "df_normalised2 = pd.read_csv(\"NormalisedDataset_majoritycluster.csv\")\n",
    "\n",
    "df_normalised_quality1 = df_normalised1[['Completeness_normalized', 'Conciseness_normalized',  'ClassImbRatio_normalized', 'ClassOverlapPerc_normalized',\n",
    "       'OutlierPerc_normalized',  'LabelIssuesPerc_normalized', 'FeatureAlgo_normalized']]\n",
    "df_normalised_char1 = df_normalised1[[ 'cor.mean_normalized', 'cov.mean_normalized',\n",
    "       'eigenvalues.mean_normalized', 'g_mean.mean_normalized',\n",
    "       'h_mean.mean_normalized', 'iq_range.mean_normalized',\n",
    "       'kurtosis.mean_normalized', 'mad.mean_normalized',\n",
    "       'max.mean_normalized', 'mean.mean_normalized', 'median.mean_normalized',\n",
    "       'min.mean_normalized', 'nr_cor_attr_normalized', 'nr_norm_normalized',\n",
    "       'nr_outliers_normalized', 'range.mean_normalized', 'sd.mean_normalized',\n",
    "       'skewness.mean_normalized', 'sparsity.mean_normalized',\n",
    "       't_mean.mean_normalized', 'var.mean_normalized',\n",
    "        'attr_to_inst_normalized',\n",
    "       'inst_to_attr_normalized', 'nr_attr_normalized', 'nr_bin_normalized',\n",
    "       'nr_inst_normalized', 'nr_num_normalized', 'attr_conc.mean_normalized',\n",
    "       'attr_ent.mean_normalized', 'nUnique_normalized', 'ena_normalized', 'snr.mean_normalized',\n",
    "       'cEntropy_normalized', 'FeatureAlgo_normalized']]\n",
    "df_normalised_quality2 = df_normalised2[['Completeness_normalized', 'Conciseness_normalized',  'ClassImbRatio_normalized', 'ClassOverlapPerc_normalized',\n",
    "       'OutlierPerc_normalized',  'LabelIssuesPerc_normalized', 'FeatureAlgo_normalized']]\n",
    "df_normalised_char2 = df_normalised2[[ 'cor.mean_normalized', 'cov.mean_normalized',\n",
    "       'eigenvalues.mean_normalized', 'g_mean.mean_normalized',\n",
    "       'h_mean.mean_normalized', 'iq_range.mean_normalized',\n",
    "       'kurtosis.mean_normalized', 'mad.mean_normalized',\n",
    "       'max.mean_normalized', 'mean.mean_normalized', 'median.mean_normalized',\n",
    "       'min.mean_normalized', 'nr_cor_attr_normalized', 'nr_norm_normalized',\n",
    "       'nr_outliers_normalized', 'range.mean_normalized', 'sd.mean_normalized',\n",
    "       'skewness.mean_normalized', 'sparsity.mean_normalized',\n",
    "       't_mean.mean_normalized', 'var.mean_normalized',\n",
    "        'attr_to_inst_normalized',\n",
    "       'inst_to_attr_normalized', 'nr_attr_normalized', 'nr_bin_normalized',\n",
    "       'nr_inst_normalized', 'nr_num_normalized', 'attr_conc.mean_normalized',\n",
    "       'attr_ent.mean_normalized', 'nUnique_normalized', 'ena_normalized', 'snr.mean_normalized',\n",
    "       'cEntropy_normalized', 'FeatureAlgo_normalized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update df_raw\n",
    "df_normalised1['labels_tuple'] = df_normalised1.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_normalised1['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_normalised1[df_normalised1['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_normalised1 = df_filtered\n",
    "\n",
    "#update df_char_raw\n",
    "df_normalised_char1['labels_tuple'] = df_normalised_char1.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_normalised_char1['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_normalised_char1[df_normalised_char1['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_normalised_char1 = df_filtered\n",
    "\n",
    "#update df_quality_raw\n",
    "df_normalised_quality1['labels_tuple'] = df_normalised_quality1.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_normalised_quality1['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_normalised_quality1[df_normalised_quality1['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_normalised_quality1 = df_filtered\n",
    "\n",
    "\n",
    "#update df_raw\n",
    "df_normalised2['labels_tuple'] = df_normalised2.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_normalised2['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_normalised2[df_normalised2['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_normalised2 = df_filtered\n",
    "\n",
    "#update df_char_raw\n",
    "df_normalised_char2['labels_tuple'] = df_normalised_char2.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_normalised_char2['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_normalised_char2[df_normalised_char2['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_normalised_char2 = df_filtered\n",
    "\n",
    "#update df_quality_raw\n",
    "df_normalised_quality2['labels_tuple'] = df_normalised_quality2.iloc[:, -1].apply(tuple)\n",
    "\n",
    "tuple_counts = df_normalised_quality2['labels_tuple'].value_counts()\n",
    "\n",
    "valid_tuples = tuple_counts[tuple_counts >= 6].index\n",
    "df_filtered = df_normalised_quality2[df_normalised_quality2['labels_tuple'].isin(valid_tuples)].copy()\n",
    "df_filtered = df_filtered.drop('labels_tuple', axis=1)\n",
    "\n",
    "df_normalised_quality2 = df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************KNN - 0.1_0.06**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.682007                    0.317993   \n",
      "df_normalised_char                     0.654795                    0.345205   \n",
      "df_normalised_quality                  0.429397                    0.570603   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.782609        0.217391  0.842689  0.782609   \n",
      "df_normalised_char         0.728261        0.271739  0.740092  0.728261   \n",
      "df_normalised_quality      0.543478        0.456522   0.64301  0.543478   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.767894   \n",
      "df_normalised_char     0.700804   \n",
      "df_normalised_quality  0.545198   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[15, 0, 0, 0, 0], [0, 16, 0, 0, 0], [9, 1, 6,...  \n",
      "df_normalised_char     [[14, 0, 0, 0, 1], [1, 15, 0, 0, 0], [8, 1, 4,...  \n",
      "df_normalised_quality  [[7, 5, 1, 2, 0], [0, 14, 0, 2, 0], [7, 3, 6, ...  \n",
      "\n",
      "\n",
      "**************KNN - Majority clustering**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.624936                    0.375064   \n",
      "df_normalised_char                     0.619011                    0.380989   \n",
      "df_normalised_quality                  0.450469                    0.549531   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.767442        0.232558  0.755003  0.767442   \n",
      "df_normalised_char         0.662791        0.337209  0.645531  0.662791   \n",
      "df_normalised_quality      0.406977        0.593023  0.427028  0.406977   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised           0.75679   \n",
      "df_normalised_char     0.652199   \n",
      "df_normalised_quality  0.411681   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[12, 0, 2, 2, 0], [0, 13, 0, 1, 0], [2, 1, 4,...  \n",
      "df_normalised_char     [[7, 2, 5, 1, 1], [2, 12, 0, 0, 0], [4, 1, 2, ...  \n",
      "df_normalised_quality  [[7, 2, 4, 3, 0], [4, 8, 0, 2, 0], [1, 1, 3, 5...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_knn(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(knn_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "\n",
    "datasets1 = {\n",
    "    'df_normalised': df_normalised1,\n",
    "    'df_normalised_char': df_normalised_char1,\n",
    "    'df_normalised_quality': df_normalised_quality1\n",
    "}\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************KNN - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "datasets2 = {\n",
    "    'df_normalised': df_normalised2,\n",
    "    'df_normalised_char': df_normalised_char2,\n",
    "    'df_normalised_quality': df_normalised_quality2\n",
    "}\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************KNN - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************DT - 0.1_0.06**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.744724                    0.255276   \n",
      "df_normalised_char                     0.706627                    0.293373   \n",
      "df_normalised_quality                  0.434765                    0.565235   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised               0.73913         0.26087  0.725531   0.73913   \n",
      "df_normalised_char         0.717391        0.282609  0.726119  0.717391   \n",
      "df_normalised_quality       0.51087         0.48913  0.515554   0.51087   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.715615   \n",
      "df_normalised_char      0.68756   \n",
      "df_normalised_quality  0.508566   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[12, 0, 1, 2, 0], [0, 16, 0, 0, 0], [7, 0, 5,...  \n",
      "df_normalised_char     [[11, 0, 0, 3, 1], [0, 15, 0, 1, 0], [11, 0, 3...  \n",
      "df_normalised_quality  [[6, 2, 5, 1, 1], [2, 12, 0, 2, 0], [8, 1, 7, ...  \n",
      "\n",
      "\n",
      "**************DT - Majority clustering**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.744246                    0.255754   \n",
      "df_normalised_char                     0.642114                    0.357886   \n",
      "df_normalised_quality                  0.424425                    0.575575   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.802326        0.197674  0.807159  0.802326   \n",
      "df_normalised_char          0.77907         0.22093  0.755409   0.77907   \n",
      "df_normalised_quality      0.430233        0.569767  0.433908  0.430233   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised           0.80287   \n",
      "df_normalised_char     0.758425   \n",
      "df_normalised_quality  0.420728   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[10, 0, 4, 1, 1], [0, 14, 0, 0, 0], [3, 0, 6,...  \n",
      "df_normalised_char     [[10, 2, 3, 0, 1], [0, 13, 0, 0, 1], [4, 0, 3,...  \n",
      "df_normalised_quality  [[4, 6, 4, 2, 0], [1, 10, 0, 1, 2], [1, 3, 3, ...  \n"
     ]
    }
   ],
   "source": [
    "#df_raw decision\n",
    "def evaluate_decision_tree(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "    smote = SMOTE(random_state=33)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)    \n",
    "    tree_classifier = DecisionTreeClassifier(random_state=random_state)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(tree_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "    y_pred = tree_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************DT - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************DT - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Distance - 0.1_0.06**********************\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.802174                    0.197826   \n",
      "df_normalised_char                     0.676087                    0.323913   \n",
      "df_normalised_quality                  0.445652                    0.554348   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.826087        0.173913  0.826094  0.826087   \n",
      "df_normalised_char          0.73913         0.26087   0.74513   0.73913   \n",
      "df_normalised_quality           0.5             0.5  0.494753       0.5   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.806917   \n",
      "df_normalised_char     0.724219   \n",
      "df_normalised_quality  0.488896   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[14, 0, 0, 1, 0], [0, 15, 0, 1, 0], [6, 1, 7,...  \n",
      "df_normalised_char     [[12, 0, 0, 3, 0], [0, 12, 3, 1, 0], [6, 1, 6,...  \n",
      "df_normalised_quality  [[3, 2, 4, 5, 1], [1, 10, 1, 4, 0], [7, 0, 5, ...  \n",
      "***************Distance - majority voting**********************\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.802174                    0.197826   \n",
      "df_normalised_char                     0.676087                    0.323913   \n",
      "df_normalised_quality                  0.445652                    0.554348   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.826087        0.173913  0.826094  0.826087   \n",
      "df_normalised_char          0.73913         0.26087   0.74513   0.73913   \n",
      "df_normalised_quality           0.5             0.5  0.494753       0.5   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.806917   \n",
      "df_normalised_char     0.724219   \n",
      "df_normalised_quality  0.488896   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[14, 0, 0, 1, 0], [0, 15, 0, 1, 0], [6, 1, 7,...  \n",
      "df_normalised_char     [[12, 0, 0, 3, 0], [0, 12, 3, 1, 0], [6, 1, 6,...  \n",
      "df_normalised_quality  [[3, 2, 4, 5, 1], [1, 10, 1, 4, 0], [7, 0, 5, ...  \n"
     ]
    }
   ],
   "source": [
    "datasets1 = {\n",
    "    'df_normalised': df_normalised1,\n",
    "    'df_normalised_char': df_normalised_char1,\n",
    "    'df_normalised_quality': df_normalised_quality1\n",
    "}\n",
    "\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "datasets2 = {\n",
    "    'df_normalised': df_normalised2,\n",
    "    'df_normalised_char': df_normalised_char2,\n",
    "    'df_normalised_quality': df_normalised_quality2\n",
    "}\n",
    "\n",
    "metric_name = 'Euclidean'\n",
    "metric_func = lambda X_train, X_test: np.sqrt(((X_train.values[:, np.newaxis] - X_test.values) ** 2).sum(axis=2))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=33)\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "  \n",
    "    cv_accuracies = []\n",
    "        \n",
    "    smote = SMOTE(random_state=33)\n",
    "  \n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    \n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predicted_labels = y_train[nearest_indices]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    results1[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "  \n",
    "    cv_accuracies = []\n",
    "        \n",
    "    smote = SMOTE(random_state=33)\n",
    "  \n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    \n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predicted_labels = y_train[nearest_indices]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    results2[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "\n",
    "print(\"***************Distance - 0.1_0.06**********************\")\n",
    "print(results_df1)\n",
    "print(\"***************Distance - majority voting**********************\")\n",
    "print(results_df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Unification - 0.1_0.06**********************\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.487242                    0.512758   \n",
      "df_normalised_char                     0.155642                    0.844358   \n",
      "df_normalised_quality                  0.199483                    0.800517   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.105263        0.894737  0.133705  0.105263   \n",
      "df_normalised_char         0.130952        0.869048  0.142452  0.130952   \n",
      "df_normalised_quality      0.181818        0.818182  0.208175  0.181818   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised           0.10649   \n",
      "df_normalised_char     0.135007   \n",
      "df_normalised_quality  0.190806   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[1, 2, 1, 0, 1], [3, 1, 0, 3, 0], [2, 2, 0, 3...  \n",
      "df_normalised_char     [[0, 1, 3, 4, 4], [2, 2, 4, 4, 3], [9, 1, 4, 2...  \n",
      "df_normalised_quality  [[1, 3, 4, 1, 0], [3, 3, 3, 2, 0], [4, 1, 1, 6...  \n",
      "***************Unification - majority voting**********************\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.468274                    0.531726   \n",
      "df_normalised_char                     0.150254                    0.849746   \n",
      "df_normalised_quality                  0.212909                    0.787091   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.741935        0.258065  0.758833  0.741935   \n",
      "df_normalised_char         0.133333        0.866667  0.148605  0.133333   \n",
      "df_normalised_quality      0.227273        0.772727  0.246717  0.227273   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised            0.7447   \n",
      "df_normalised_char     0.138968   \n",
      "df_normalised_quality  0.231687   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[2, 0, 1, 0, 1], [1, 9, 0, 0, 0], [0, 0, 3, 0...  \n",
      "df_normalised_char     [[1, 2, 1, 2, 8], [0, 1, 4, 4, 2], [3, 2, 1, 0...  \n",
      "df_normalised_quality  [[3, 0, 5, 4, 2], [2, 5, 1, 3, 1], [2, 2, 2, 2...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def unify_features(test_sample, train_data, train_labels):\n",
    "    test_features = test_sample.values\n",
    "    matching_indices = np.all(train_data == test_features, axis=1)\n",
    "    if matching_indices.any():\n",
    "        matching_labels = train_labels[matching_indices]\n",
    "        return np.unique(matching_labels)\n",
    "    return [\"unknown\"]\n",
    "\n",
    "def evaluate_unification(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "   \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "    \n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        predicted_labels = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "            predicted_labels.append(label)\n",
    "        \n",
    "        predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "        valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        if not valid_indices:\n",
    "            continue\n",
    "        \n",
    "        valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "\n",
    "        valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "        cv_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "       \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    predicted_labels = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "        predicted_labels.append(label)\n",
    "    predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "    valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        \n",
    "    valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "    valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "    precision = precision_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(valid_truth, valid_predictions)    \n",
    "    test_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "\n",
    "    return {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_unification(df)\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_unification(df)\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"***************Unification - 0.1_0.06**********************\")\n",
    "print(results_df1)\n",
    "print(\"***************Unification - majority voting**********************\")\n",
    "print(results_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- nr_inst <= 335.50\n",
      "|   |--- cEntropy <= 0.95\n",
      "|   |   |--- iq_range.mean <= 310.88\n",
      "|   |   |   |--- cEntropy <= 0.41\n",
      "|   |   |   |   |--- cor.mean <= 0.24\n",
      "|   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |   |--- cor.mean >  0.24\n",
      "|   |   |   |   |   |--- class: relief\n",
      "|   |   |   |--- cEntropy >  0.41\n",
      "|   |   |   |   |--- attr_to_inst <= 0.36\n",
      "|   |   |   |   |   |--- inst_to_attr <= 8.72\n",
      "|   |   |   |   |   |   |--- LabelIssuesPerc <= 0.02\n",
      "|   |   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |   |   |   |--- LabelIssuesPerc >  0.02\n",
      "|   |   |   |   |   |   |   |--- class: GR\n",
      "|   |   |   |   |   |--- inst_to_attr >  8.72\n",
      "|   |   |   |   |   |   |--- attr_to_inst <= 0.01\n",
      "|   |   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |   |   |   |--- attr_to_inst >  0.01\n",
      "|   |   |   |   |   |   |   |--- ena <= -40.54\n",
      "|   |   |   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |   |   |   |   |--- ena >  -40.54\n",
      "|   |   |   |   |   |   |   |   |--- OutlierPerc <= 0.03\n",
      "|   |   |   |   |   |   |   |   |   |--- kurtosis.mean <= 33.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: GR\n",
      "|   |   |   |   |   |   |   |   |   |--- kurtosis.mean >  33.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- OutlierPerc <= 0.00\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: GR\n",
      "|   |   |   |   |   |   |   |   |   |   |--- OutlierPerc >  0.00\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: relief\n",
      "|   |   |   |   |   |   |   |   |--- OutlierPerc >  0.03\n",
      "|   |   |   |   |   |   |   |   |   |--- class: GR\n",
      "|   |   |   |   |--- attr_to_inst >  0.36\n",
      "|   |   |   |   |   |--- class: relief\n",
      "|   |   |--- iq_range.mean >  310.88\n",
      "|   |   |   |--- class: chisquare\n",
      "|   |--- cEntropy >  0.95\n",
      "|   |   |--- nr_cor_attr <= 0.01\n",
      "|   |   |   |--- cEntropy <= 0.98\n",
      "|   |   |   |   |--- g_mean.mean <= 1.79\n",
      "|   |   |   |   |   |--- nr_num <= 29.50\n",
      "|   |   |   |   |   |   |--- class: GR\n",
      "|   |   |   |   |   |--- nr_num >  29.50\n",
      "|   |   |   |   |   |   |--- class: relief\n",
      "|   |   |   |   |--- g_mean.mean >  1.79\n",
      "|   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |--- cEntropy >  0.98\n",
      "|   |   |   |   |--- class: fcbf\n",
      "|   |   |--- nr_cor_attr >  0.01\n",
      "|   |   |   |--- attr_conc.mean <= 0.08\n",
      "|   |   |   |   |--- range.mean <= 0.82\n",
      "|   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |   |--- range.mean >  0.82\n",
      "|   |   |   |   |   |--- class: GR\n",
      "|   |   |   |--- attr_conc.mean >  0.08\n",
      "|   |   |   |   |--- nr_cor_attr <= 0.76\n",
      "|   |   |   |   |   |--- g_mean.mean <= 35.44\n",
      "|   |   |   |   |   |   |--- skewness.mean <= 0.06\n",
      "|   |   |   |   |   |   |   |--- range.mean <= 3.54\n",
      "|   |   |   |   |   |   |   |   |--- class: relief\n",
      "|   |   |   |   |   |   |   |--- range.mean >  3.54\n",
      "|   |   |   |   |   |   |   |   |--- class: GR\n",
      "|   |   |   |   |   |   |--- skewness.mean >  0.06\n",
      "|   |   |   |   |   |   |   |--- class: relief\n",
      "|   |   |   |   |   |--- g_mean.mean >  35.44\n",
      "|   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |   |--- nr_cor_attr >  0.76\n",
      "|   |   |   |   |   |--- class: chisquare\n",
      "|--- nr_inst >  335.50\n",
      "|   |--- mad.mean <= 1.00\n",
      "|   |   |--- LabelIssuesPerc <= 0.00\n",
      "|   |   |   |--- snr.mean <= 1.24\n",
      "|   |   |   |   |--- class: relief\n",
      "|   |   |   |--- snr.mean >  1.24\n",
      "|   |   |   |   |--- cor.mean <= 0.05\n",
      "|   |   |   |   |   |--- class: fcbf\n",
      "|   |   |   |   |--- cor.mean >  0.05\n",
      "|   |   |   |   |   |--- attr_conc.mean <= 0.00\n",
      "|   |   |   |   |   |   |--- class: fcbf\n",
      "|   |   |   |   |   |--- attr_conc.mean >  0.00\n",
      "|   |   |   |   |   |   |--- class: relief\n",
      "|   |   |--- LabelIssuesPerc >  0.00\n",
      "|   |   |   |--- nr_cor_attr <= 0.12\n",
      "|   |   |   |   |--- attr_conc.mean <= 0.01\n",
      "|   |   |   |   |   |--- class: GR\n",
      "|   |   |   |   |--- attr_conc.mean >  0.01\n",
      "|   |   |   |   |   |--- nr_num <= 7.50\n",
      "|   |   |   |   |   |   |--- snr.mean <= 4.88\n",
      "|   |   |   |   |   |   |   |--- class: relief\n",
      "|   |   |   |   |   |   |--- snr.mean >  4.88\n",
      "|   |   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |   |   |--- nr_num >  7.50\n",
      "|   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |--- nr_cor_attr >  0.12\n",
      "|   |   |   |   |--- min.mean <= 0.81\n",
      "|   |   |   |   |   |--- class: relief\n",
      "|   |   |   |   |--- min.mean >  0.81\n",
      "|   |   |   |   |   |--- class: GR\n",
      "|   |--- mad.mean >  1.00\n",
      "|   |   |--- max.mean <= 177.98\n",
      "|   |   |   |--- Completeness <= 0.00\n",
      "|   |   |   |   |--- cEntropy <= 0.97\n",
      "|   |   |   |   |   |--- cEntropy <= 0.88\n",
      "|   |   |   |   |   |   |--- attr_to_inst <= 0.00\n",
      "|   |   |   |   |   |   |   |--- class: fcbf\n",
      "|   |   |   |   |   |   |--- attr_to_inst >  0.00\n",
      "|   |   |   |   |   |   |   |--- sparsity.mean <= 0.20\n",
      "|   |   |   |   |   |   |   |   |--- nr_bin <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: GR\n",
      "|   |   |   |   |   |   |   |   |--- nr_bin >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- skewness.mean <= -0.82\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |   |   |   |   |   |   |--- skewness.mean >  -0.82\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: relief\n",
      "|   |   |   |   |   |   |   |--- sparsity.mean >  0.20\n",
      "|   |   |   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |   |   |--- cEntropy >  0.88\n",
      "|   |   |   |   |   |   |--- snr.mean <= 1.18\n",
      "|   |   |   |   |   |   |   |--- class: relief\n",
      "|   |   |   |   |   |   |--- snr.mean >  1.18\n",
      "|   |   |   |   |   |   |   |--- class: fcbf\n",
      "|   |   |   |   |--- cEntropy >  0.97\n",
      "|   |   |   |   |   |--- var.mean <= 6.94\n",
      "|   |   |   |   |   |   |--- class: relief\n",
      "|   |   |   |   |   |--- var.mean >  6.94\n",
      "|   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |--- Completeness >  0.00\n",
      "|   |   |   |   |--- kurtosis.mean <= -0.42\n",
      "|   |   |   |   |   |--- class: GR\n",
      "|   |   |   |   |--- kurtosis.mean >  -0.42\n",
      "|   |   |   |   |   |--- sparsity.mean <= 0.41\n",
      "|   |   |   |   |   |   |--- class: fcbf\n",
      "|   |   |   |   |   |--- sparsity.mean >  0.41\n",
      "|   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |--- max.mean >  177.98\n",
      "|   |   |   |--- inst_to_attr <= 634.88\n",
      "|   |   |   |   |--- attr_ent.mean <= 1.70\n",
      "|   |   |   |   |   |--- Completeness <= 0.00\n",
      "|   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |   |   |--- Completeness >  0.00\n",
      "|   |   |   |   |   |   |--- eigenvalues.mean <= 2572799.41\n",
      "|   |   |   |   |   |   |   |--- attr_conc.mean <= 0.13\n",
      "|   |   |   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |   |   |   |   |--- attr_conc.mean >  0.13\n",
      "|   |   |   |   |   |   |   |   |--- class: relief\n",
      "|   |   |   |   |   |   |--- eigenvalues.mean >  2572799.41\n",
      "|   |   |   |   |   |   |   |--- class: relief\n",
      "|   |   |   |   |--- attr_ent.mean >  1.70\n",
      "|   |   |   |   |   |--- eigenvalues.mean <= 1959.32\n",
      "|   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |   |   |--- eigenvalues.mean >  1959.32\n",
      "|   |   |   |   |   |   |--- class: chisquare\n",
      "|   |   |   |--- inst_to_attr >  634.88\n",
      "|   |   |   |   |--- class: relief\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "def evaluate_decision_tree(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  \n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    smote = SMOTE(random_state=33)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)    \n",
    "    tree_classifier = DecisionTreeClassifier(random_state=random_state)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(tree_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "    y_pred = tree_classifier.predict(X_test)\n",
    "    rules = export_text(tree_classifier, feature_names=list(X_train.columns))\n",
    "    print(rules)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'model': tree_classifier,\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "datasets = {\n",
    "    'df_raw': df_raw,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    results[name] = evaluate_decision_tree(df)\n",
    "\n",
    "with open('df_raw_decision_tree_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(results['df_raw']['model'], model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_raw decision\n",
    "def evaluate_decision_tree(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "    smote = SMOTE(random_state=33)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)    \n",
    "    tree_classifier = DecisionTreeClassifier(random_state=random_state)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(tree_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "    y_pred = tree_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'model': tree_classifier,\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "datasets = {\n",
    "    'df_normalised': df_normalised\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    results[name] = evaluate_decision_tree(df)\n",
    "\n",
    "with open('df_raw_normalised_decision_tree_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(results['df_normalised']['model'], model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".deeplearningClass",
   "language": "python",
   "name": ".deeplearningclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68ad885796f6f0b806db95b15cf2a015a244c9adabe8d6cffa3fc143090837a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
