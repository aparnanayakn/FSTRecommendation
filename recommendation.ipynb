{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"./optimalalphabeta/dearr_cont/dearr0.1_0.06.csv\")\n",
    "#df1 = pd.read_csv(\"bordascores_top3.csv\")\n",
    "df2 = pd.read_csv(\"df_mfeatures.csv\")\n",
    "df3 = pd.read_csv(\"BinnedMetaFeatures.csv\")\n",
    "df1 = df1[['File','FeatureAlgo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df1.merge(df2, on='File').merge(df3, on='File')\n",
    "merged_df.to_csv(\"KnowledgeBase.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"majority_voted_labels_clusteredearr.csv\")\n",
    "merged_df = df1.merge(df2, on='File').merge(df3, on='File')\n",
    "merged_df.to_csv(\"KnowledgeBase_majorityvotecluster.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"KnowledgeBase.csv\")\n",
    "df2 = pd.read_csv(\"KnowledgeBase_majorityvotecluster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_char_raw1 = df1[[ 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "df_quality_raw1 = df1[['Completeness', 'Conciseness', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'LabelIssuesPerc', 'FeatureAlgo']]\n",
    "\n",
    "df_raw1 = df1[['Completeness', 'Conciseness', 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'LabelIssuesPerc','nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "\n",
    "df_char_bin1 = df1[['cor.mean_bins', 'cov.mean_bins',\n",
    "       'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins',\n",
    "       'iq_range.mean_bins', 'kurtosis.mean_bins', 'mad.mean_bins',\n",
    "       'max.mean_bins', 'mean.mean_bins', 'median.mean_bins', 'min.mean_bins',\n",
    "       'nr_cor_attr_bins', 'nr_norm_bins', 'nr_outliers_bins',\n",
    "       'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "       'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins',\n",
    "       'attr_to_inst_bins', 'inst_to_attr_bins',\n",
    "       'nr_attr_bins', 'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins',\n",
    "       'attr_conc.mean_bins', 'attr_ent.mean_bins', 'ena_bins',\n",
    "       'snr.mean_bins', 'cEntropy_bins','FeatureAlgo']]\n",
    "\n",
    "df_quality_bin1 = df1[['Completeness_bins',\n",
    "       'Conciseness_bins', 'LabelIssues_bins', 'ClassImbRatio_bins', 'OutlierPerc_bins',\n",
    "       'ClassOverlapPerc_bins','FeatureAlgo']]\n",
    "\n",
    "df_bin1 = df1[['Completeness_bins',\n",
    "       'Conciseness_bins', 'cor.mean_bins', 'cov.mean_bins',\n",
    "       'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins',\n",
    "       'iq_range.mean_bins', 'kurtosis.mean_bins', 'mad.mean_bins',\n",
    "       'max.mean_bins', 'mean.mean_bins', 'median.mean_bins', 'min.mean_bins',\n",
    "       'nr_cor_attr_bins', 'nr_norm_bins', 'nr_outliers_bins',\n",
    "       'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "       'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins',\n",
    "       'LabelIssues_bins', 'ClassImbRatio_bins', 'OutlierPerc_bins',\n",
    "       'ClassOverlapPerc_bins', 'attr_to_inst_bins', 'inst_to_attr_bins',\n",
    "       'nr_attr_bins', 'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins',\n",
    "       'attr_conc.mean_bins', 'attr_ent.mean_bins', 'ena_bins',\n",
    "       'snr.mean_bins', 'cEntropy_bins', 'FeatureAlgo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_char_raw2 = df2[[ 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "df_quality_raw2 = df2[['Completeness', 'Conciseness', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'LabelIssuesPerc', 'FeatureAlgo']]\n",
    "\n",
    "df_raw2 = df2[['Completeness', 'Conciseness', 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'LabelIssuesPerc','nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "\n",
    "df_char_bin2 = df2[['cor.mean_bins', 'cov.mean_bins',\n",
    "       'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins',\n",
    "       'iq_range.mean_bins', 'kurtosis.mean_bins', 'mad.mean_bins',\n",
    "       'max.mean_bins', 'mean.mean_bins', 'median.mean_bins', 'min.mean_bins',\n",
    "       'nr_cor_attr_bins', 'nr_norm_bins', 'nr_outliers_bins',\n",
    "       'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "       'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins',\n",
    "       'attr_to_inst_bins', 'inst_to_attr_bins',\n",
    "       'nr_attr_bins', 'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins',\n",
    "       'attr_conc.mean_bins', 'attr_ent.mean_bins', 'ena_bins',\n",
    "       'snr.mean_bins', 'cEntropy_bins','FeatureAlgo']]\n",
    "\n",
    "df_quality_bin2 = df2[['Completeness_bins',\n",
    "       'Conciseness_bins', 'LabelIssues_bins', 'ClassImbRatio_bins', 'OutlierPerc_bins',\n",
    "       'ClassOverlapPerc_bins','FeatureAlgo']]\n",
    "\n",
    "df_bin2 = df2[['Completeness_bins',\n",
    "       'Conciseness_bins', 'cor.mean_bins', 'cov.mean_bins',\n",
    "       'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins',\n",
    "       'iq_range.mean_bins', 'kurtosis.mean_bins', 'mad.mean_bins',\n",
    "       'max.mean_bins', 'mean.mean_bins', 'median.mean_bins', 'min.mean_bins',\n",
    "       'nr_cor_attr_bins', 'nr_norm_bins', 'nr_outliers_bins',\n",
    "       'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "       'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins',\n",
    "       'LabelIssues_bins', 'ClassImbRatio_bins', 'OutlierPerc_bins',\n",
    "       'ClassOverlapPerc_bins', 'attr_to_inst_bins', 'inst_to_attr_bins',\n",
    "       'nr_attr_bins', 'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins',\n",
    "       'attr_conc.mean_bins', 'attr_ent.mean_bins', 'ena_bins',\n",
    "       'snr.mean_bins', 'cEntropy_bins', 'FeatureAlgo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAW DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************KNN - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.506878                    0.493122   \n",
      "df_char_raw                     0.506878                    0.493122   \n",
      "df_quality_raw                  0.499471                    0.500529   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.571429        0.428571  0.516104  0.571429  0.542356   \n",
      "df_char_raw         0.571429        0.428571  0.516104  0.571429  0.542356   \n",
      "df_quality_raw           0.4             0.6  0.331815       0.4  0.361196   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[7, 0, 2, 1, 0], [2, 0, 0, 0, 0], [2, 2, 13, ...  \n",
      "df_char_raw     [[7, 0, 2, 1, 0], [2, 0, 0, 0, 0], [2, 2, 13, ...  \n",
      "df_quality_raw  [[2, 0, 5, 3, 0], [0, 0, 2, 0, 0], [6, 0, 12, ...  \n",
      "\n",
      "\n",
      "**************KNN - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.513757                    0.486243   \n",
      "df_char_raw                     0.513757                    0.486243   \n",
      "df_quality_raw                  0.521429                    0.478571   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.542857        0.457143  0.461224  0.542857  0.496525   \n",
      "df_char_raw         0.542857        0.457143  0.461224  0.542857  0.496525   \n",
      "df_quality_raw      0.314286        0.685714  0.253061  0.314286  0.279537   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[7, 1, 3, 0, 0], [2, 0, 0, 0, 0], [2, 1, 12, ...  \n",
      "df_char_raw     [[7, 1, 3, 0, 0], [2, 0, 0, 0, 0], [2, 1, 12, ...  \n",
      "df_quality_raw  [[2, 0, 7, 2, 0], [1, 0, 1, 0, 0], [6, 0, 9, 1...  \n"
     ]
    }
   ],
   "source": [
    "#k-NN\n",
    "def evaluate_knn(df, random_state=42):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  \n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(knn_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "datasets1 = {\n",
    "    'df_raw': df_raw1,\n",
    "    'df_char_raw': df_char_raw1,\n",
    "    'df_quality_raw': df_quality_raw1\n",
    "}\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************KNN - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "datasets2 = {\n",
    "    'df_raw': df_raw2,\n",
    "    'df_char_raw': df_char_raw2,\n",
    "    'df_quality_raw': df_quality_raw2\n",
    "}\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************KNN - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************DT - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.623016                    0.376984   \n",
      "df_char_raw                     0.594444                    0.405556   \n",
      "df_quality_raw                  0.536772                    0.463228   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.542857        0.457143  0.540977  0.542857  0.539683   \n",
      "df_char_raw         0.514286        0.485714  0.494874  0.514286  0.501253   \n",
      "df_quality_raw      0.371429        0.628571  0.390765  0.371429  0.378947   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[5, 0, 2, 1, 0], [1, 0, 1, 0, 0], [3, 0, 13, ...  \n",
      "df_char_raw     [[5, 0, 2, 1, 0], [1, 0, 1, 0, 0], [3, 1, 13, ...  \n",
      "df_quality_raw  [[2, 1, 4, 0, 1], [2, 0, 0, 0, 0], [6, 0, 11, ...  \n",
      "\n",
      "\n",
      "**************DT - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.585979                    0.414021   \n",
      "df_char_raw                     0.571693                    0.428307   \n",
      "df_quality_raw                  0.478836                    0.521164   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.542857        0.457143   0.52015  0.542857  0.527347   \n",
      "df_char_raw         0.542857        0.457143  0.511579  0.542857   0.52423   \n",
      "df_quality_raw      0.457143        0.542857  0.468908  0.457143  0.458009   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[6, 0, 3, 1, 1], [1, 0, 1, 0, 0], [1, 0, 12, ...  \n",
      "df_char_raw     [[6, 0, 3, 2, 0], [1, 0, 1, 0, 0], [1, 0, 12, ...  \n",
      "df_quality_raw  [[5, 1, 4, 0, 1], [2, 0, 0, 0, 0], [2, 1, 10, ...  \n"
     ]
    }
   ],
   "source": [
    "#decision\n",
    "\n",
    "def evaluate_decision_tree(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  \n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    tree_classifier = DecisionTreeClassifier(random_state=random_state)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(tree_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "    y_pred = tree_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************DT - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************DT - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************Distance based - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.530924                    0.469076   \n",
      "df_char_raw                     0.530924                    0.469076   \n",
      "df_quality_raw                  0.444202                    0.555798   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.485714        0.514286   0.44517  0.485714  0.463957   \n",
      "df_char_raw         0.485714        0.514286   0.44517  0.485714  0.463957   \n",
      "df_quality_raw      0.428571        0.571429  0.424047  0.428571  0.417724   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[4, 0, 4, 0], [1, 0, 1, 0], [3, 0, 13, 4], [2...  \n",
      "df_char_raw     [[4, 0, 4, 0], [1, 0, 1, 0], [3, 0, 13, 4], [2...  \n",
      "df_quality_raw  [[5, 0, 2, 0, 1], [1, 0, 1, 0, 0], [6, 0, 10, ...  \n",
      "\n",
      "\n",
      "**************Distance based - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.513613                    0.486387   \n",
      "df_char_raw                     0.513613                    0.486387   \n",
      "df_quality_raw                   0.44437                     0.55563   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.457143        0.542857      0.42  0.457143  0.434797   \n",
      "df_char_raw         0.457143        0.542857      0.42  0.457143  0.434797   \n",
      "df_quality_raw      0.485714        0.514286  0.469231  0.485714  0.474762   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[5, 0, 6, 0], [1, 0, 1, 0], [2, 0, 10, 4], [2...  \n",
      "df_char_raw     [[5, 0, 6, 0], [1, 0, 1, 0], [2, 0, 10, 4], [2...  \n",
      "df_quality_raw  [[7, 0, 3, 0, 1], [1, 0, 1, 0, 0], [3, 0, 9, 3...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "metric_name = 'Euclidean'\n",
    "metric_func = lambda X_train, X_test: np.sqrt(((X_train.values[:, np.newaxis] - X_test.values) ** 2).sum(axis=2))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        cv_error_rate = 1 - cv_accuracy\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "      \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    nearest_labels = y_encoded[nearest_indices]\n",
    "    predicted_labels = y_train[nearest_indices] \n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "        \n",
    "    test_accuracy =accuracy_score(y_test, predicted_labels)\n",
    "\n",
    "    results1[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': (test_accuracy),\n",
    "        'Test Error Rate': (1 - test_accuracy),\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score':f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        cv_error_rate = 1 - cv_accuracy\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "      \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    nearest_labels = y_encoded[nearest_indices]\n",
    "    predicted_labels = y_train[nearest_indices] \n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "        \n",
    "    test_accuracy =accuracy_score(y_test, predicted_labels)\n",
    "\n",
    "    results2[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': (test_accuracy),\n",
    "        'Test Error Rate': (1 - test_accuracy),\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score':f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"**************Distance based - 0.1_0.06**************\\n\")\n",
    "print(results_df1)\n",
    "\n",
    "print(\"\\n\\n**************Distance based - Majority clustering**************\\n\")\n",
    "print(results_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************Unification - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.722222                    0.277778   \n",
      "df_char_raw                     0.722222                    0.277778   \n",
      "df_quality_raw                  0.387937                    0.612063   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision Recall  F1 Score  \\\n",
      "df_raw                   NaN             NaN         0      0         0   \n",
      "df_char_raw              NaN             NaN         0      0         0   \n",
      "df_quality_raw           0.5             0.5  0.833333    0.5  0.611111   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw                                                         []  \n",
      "df_char_raw                                                    []  \n",
      "df_quality_raw  [[1, 0, 0, 1], [1, 2, 1, 0], [0, 0, 0, 0], [0,...  \n",
      "\n",
      "\n",
      "**************Unification - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.722222                    0.277778   \n",
      "df_char_raw                     0.722222                    0.277778   \n",
      "df_quality_raw                  0.319365                    0.680635   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision Recall  F1 Score  \\\n",
      "df_raw                   NaN             NaN         0      0         0   \n",
      "df_char_raw              NaN             NaN         0      0         0   \n",
      "df_quality_raw           0.5             0.5  0.833333    0.5  0.611111   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw                                                         []  \n",
      "df_char_raw                                                    []  \n",
      "df_quality_raw  [[1, 0, 0, 1], [1, 2, 1, 0], [0, 0, 0, 0], [0,...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "def unify_features(test_sample, train_data, train_labels):\n",
    "    test_features = test_sample.values\n",
    "    matching_indices = np.all(train_data == test_features, axis=1)\n",
    "    if matching_indices.any():\n",
    "        matching_labels = train_labels[matching_indices]\n",
    "        return np.unique(matching_labels)\n",
    "    return [\"unknown\"]\n",
    "\n",
    "def evaluate_unification(df, random_state=42):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "        \n",
    "        predicted_labels = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "            predicted_labels.append(label)\n",
    "        \n",
    "        predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "        valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        \n",
    "        if not valid_indices:\n",
    "            continue\n",
    "        \n",
    "        valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "        valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "        cv_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "       \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=2)\n",
    "\n",
    "    predicted_labels = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "        predicted_labels.append(label)\n",
    "    predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "    valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        \n",
    "    valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "    valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "    precision = precision_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(valid_truth, valid_predictions)    \n",
    "    test_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "\n",
    "    return {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_unification(df)\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_unification(df)\n",
    "\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"**************Unification - 0.1_0.06**************\\n\")\n",
    "print(results_df1)\n",
    "\n",
    "print(\"\\n\\n**************Unification - Majority clustering**************\\n\")\n",
    "print(results_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIN data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************KNN - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.413228                    0.586772   \n",
      "df_char_bin                     0.522222                    0.477778   \n",
      "df_quality_bin                  0.434921                    0.565079   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.342857        0.657143  0.316902  0.342857  0.328389   \n",
      "df_char_bin         0.485714        0.514286  0.407937  0.485714  0.443392   \n",
      "df_quality_bin      0.371429        0.628571  0.334485  0.371429  0.350158   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[1, 0, 7, 0], [2, 0, 0, 0], [8, 0, 11, 1], [2...  \n",
      "df_char_bin     [[2, 0, 6, 0], [1, 0, 0, 1], [4, 0, 15, 1], [2...  \n",
      "df_quality_bin  [[2, 0, 6, 0], [1, 0, 1, 0], [8, 0, 11, 1], [2...  \n",
      "\n",
      "\n",
      "**************KNN - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.412963                    0.587037   \n",
      "df_char_bin                     0.485714                    0.514286   \n",
      "df_quality_bin                  0.419577                    0.580423   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin                   0.4             0.6  0.321008       0.4  0.354262   \n",
      "df_char_bin         0.428571        0.571429  0.333333  0.428571  0.368571   \n",
      "df_quality_bin           0.4             0.6   0.32782       0.4  0.354286   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[5, 0, 6, 0], [2, 0, 0, 0], [7, 0, 9, 0], [3,...  \n",
      "df_char_bin     [[3, 0, 8, 0], [1, 0, 0, 1], [3, 0, 12, 1], [2...  \n",
      "df_quality_bin  [[6, 0, 5, 0], [1, 0, 1, 0], [8, 0, 8, 0], [4,...  \n"
     ]
    }
   ],
   "source": [
    "def evaluate_knn(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  \n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(knn_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "datasets1 = {\n",
    "    'df_bin': df_bin1,\n",
    "    'df_char_bin': df_char_bin1,\n",
    "    'df_quality_bin': df_quality_bin1\n",
    "}\n",
    "datasets2 = {\n",
    "    'df_bin': df_bin2,\n",
    "    'df_char_bin': df_char_bin2,\n",
    "    'df_quality_raw': df_quality_bin2\n",
    "}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************KNN - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************KNN - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************DT - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.478307                    0.521693   \n",
      "df_char_bin                     0.478571                    0.521429   \n",
      "df_quality_bin                  0.384392                    0.615608   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.371429        0.628571  0.352381  0.371429      0.36   \n",
      "df_char_bin         0.428571        0.571429    0.3953  0.428571   0.41049   \n",
      "df_quality_bin      0.314286        0.685714  0.273292  0.314286  0.292359   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[2, 0, 6, 0, 0], [1, 0, 0, 1, 0], [7, 0, 11, ...  \n",
      "df_char_bin     [[2, 0, 6, 0, 0], [1, 0, 0, 1, 0], [5, 0, 13, ...  \n",
      "df_quality_bin  [[0, 0, 8, 0], [2, 0, 0, 0], [9, 0, 11, 0], [1...  \n",
      "\n",
      "\n",
      "**************DT - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.499471                    0.500529   \n",
      "df_char_bin                     0.478307                    0.521693   \n",
      "df_quality_raw                  0.369577                    0.630423   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.257143        0.742857  0.220802  0.257143  0.237516   \n",
      "df_char_bin              0.4             0.6   0.32517       0.4  0.357529   \n",
      "df_quality_raw      0.257143        0.742857  0.194805  0.257143  0.221053   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[2, 1, 8, 0], [1, 0, 0, 1], [7, 2, 7, 0], [2,...  \n",
      "df_char_bin     [[3, 0, 8, 0, 0], [1, 0, 0, 1, 0], [3, 0, 11, ...  \n",
      "df_quality_raw  [[1, 0, 9, 1], [2, 0, 0, 0], [7, 0, 8, 1], [1,...  \n"
     ]
    }
   ],
   "source": [
    "def evaluate_decision_tree(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "        \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  \n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    tree_classifier = DecisionTreeClassifier(random_state=random_state)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(tree_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "    y_pred = tree_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "results1 = {}\n",
    "datasets1 = {\n",
    "    'df_bin': df_bin1,\n",
    "    'df_char_bin': df_char_bin1,\n",
    "    'df_quality_bin': df_quality_bin1\n",
    "}\n",
    "datasets2 = {\n",
    "    'df_bin': df_bin2,\n",
    "    'df_char_bin': df_char_bin2,\n",
    "    'df_quality_raw': df_quality_bin2\n",
    "}\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************DT - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************DT - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Distance based - 0.1_0.06*************\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.387059                    0.612941   \n",
      "df_char_bin                     0.474118                    0.525882   \n",
      "df_quality_bin                  0.323361                    0.676639   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.314286        0.685714  0.304762  0.314286  0.309222   \n",
      "df_char_bin         0.371429        0.628571  0.370748  0.371429  0.370112   \n",
      "df_quality_bin      0.371429        0.628571  0.275132  0.371429  0.316109   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[1, 0, 7, 0, 0], [0, 0, 0, 2, 0], [6, 0, 10, ...  \n",
      "df_char_bin     [[0, 0, 8, 0, 0], [1, 0, 0, 1, 0], [7, 0, 11, ...  \n",
      "df_quality_bin  [[0, 0, 8, 0], [0, 0, 1, 1], [3, 0, 13, 4], [0...  \n",
      "\n",
      "\n",
      "***************Distance based - Majority cluster*************\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.392941                    0.607059   \n",
      "df_char_bin                     0.456807                    0.543193   \n",
      "df_quality_bin                   0.29479                     0.70521   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.257143        0.742857  0.258217  0.257143  0.252698   \n",
      "df_char_bin         0.314286        0.685714  0.290533  0.314286  0.300439   \n",
      "df_quality_bin      0.257143        0.742857  0.158242  0.257143  0.195918   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[2, 0, 8, 1, 0], [0, 0, 0, 2, 0], [5, 1, 7, 2...  \n",
      "df_char_bin     [[1, 0, 9, 1, 0], [1, 0, 0, 1, 0], [6, 0, 7, 2...  \n",
      "df_quality_bin  [[0, 0, 10, 1], [0, 0, 1, 1], [3, 2, 9, 2], [0...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "datasets1 = {\n",
    "    'df_bin': df_bin1,\n",
    "    'df_char_bin': df_char_bin1,\n",
    "    'df_quality_bin': df_quality_bin1\n",
    "}\n",
    "datasets2 = {\n",
    "    'df_bin': df_bin2,\n",
    "    'df_char_bin': df_char_bin2,\n",
    "    'df_quality_bin': df_quality_bin2\n",
    "}\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "\n",
    "metric_name = 'Euclidean'\n",
    "metric_func = lambda X_train, X_test: np.sqrt(((X_train.values[:, np.newaxis] - X_test.values) ** 2).sum(axis=2))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "        \n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        cv_error_rate = 1 - cv_accuracy\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "      \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    nearest_labels = y_encoded[nearest_indices]\n",
    "    predicted_labels = y_train[nearest_indices] \n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "        \n",
    "    test_accuracy =accuracy_score(y_test, predicted_labels)\n",
    "\n",
    "    results1[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': (test_accuracy),\n",
    "        'Test Error Rate': (1 - test_accuracy),\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score':f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"***************Distance based - 0.1_0.06*************\")\n",
    "print(results_df1)\n",
    "\n",
    "\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "        \n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        cv_error_rate = 1 - cv_accuracy\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "      \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    nearest_labels = y_encoded[nearest_indices]\n",
    "    predicted_labels = y_train[nearest_indices] \n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "        \n",
    "    test_accuracy =accuracy_score(y_test, predicted_labels)\n",
    "\n",
    "    results2[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': (test_accuracy),\n",
    "        'Test Error Rate': (1 - test_accuracy),\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score':f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n***************Distance based - Majority cluster*************\")\n",
    "\n",
    "print(results_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Unification - 0.1_0.06**********************\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.468067                    0.531933   \n",
      "df_char_bin                     0.315363                    0.684637   \n",
      "df_quality_bin                  0.248192                    0.751808   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.368421        0.631579  0.424812  0.368421  0.389516   \n",
      "df_char_bin         0.242424        0.757576  0.470041  0.242424   0.31527   \n",
      "df_quality_bin       0.30303         0.69697  0.587205   0.30303  0.390374   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[3, 0, 2, 1], [0, 0, 1, 0], [4, 1, 4, 2], [0,...  \n",
      "df_char_bin     [[1, 0, 2, 4, 0], [0, 0, 1, 0, 0], [7, 3, 7, 3...  \n",
      "df_quality_bin  [[2, 1, 2, 1, 2], [1, 0, 0, 0, 0], [4, 2, 8, 4...  \n",
      "***************Unification - majority voting**********************\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.461251                    0.538749   \n",
      "df_char_bin                     0.327566                    0.672434   \n",
      "df_quality_bin                  0.267725                    0.732275   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.315789        0.684211  0.332707  0.315789  0.321188   \n",
      "df_char_bin         0.212121        0.787879  0.394949  0.212121  0.261319   \n",
      "df_quality_bin      0.272727        0.727273  0.478114  0.272727  0.339869   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[3, 0, 2, 1], [0, 0, 1, 0], [4, 1, 3, 2], [0,...  \n",
      "df_char_bin     [[1, 2, 1, 2, 1], [0, 0, 1, 0, 0], [9, 2, 5, 3...  \n",
      "df_quality_bin  [[2, 1, 2, 1, 2], [1, 0, 0, 0, 0], [3, 2, 7, 4...  \n"
     ]
    }
   ],
   "source": [
    "def unify_features(test_sample, train_data, train_labels):\n",
    "    test_features = test_sample.values\n",
    "    matching_indices = np.all(train_data == test_features, axis=1)\n",
    "    if matching_indices.any():\n",
    "        matching_labels = train_labels[matching_indices]\n",
    "        return np.unique(matching_labels)\n",
    "    return [\"unknown\"]\n",
    "\n",
    "def evaluate_unification(df, random_state=42):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "        \n",
    "        predicted_labels = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "            predicted_labels.append(label)\n",
    "        \n",
    "        predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "        valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        \n",
    "        if not valid_indices:\n",
    "            continue\n",
    "        \n",
    "        valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "        valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "        cv_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "       \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=2)\n",
    "    predicted_labels = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "        predicted_labels.append(label)\n",
    "    predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "    valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        \n",
    "    valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "    valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "    precision = precision_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(valid_truth, valid_predictions)    \n",
    "    test_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "\n",
    "    return {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "datasets1 = {\n",
    "    'df_bin': df_bin1,\n",
    "    'df_char_bin': df_char_bin1,\n",
    "    'df_quality_bin': df_quality_bin1\n",
    "}\n",
    "datasets2 = {\n",
    "    'df_bin': df_bin2,\n",
    "    'df_char_bin': df_char_bin2,\n",
    "    'df_quality_bin': df_quality_bin2\n",
    "}\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_unification(df)\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_unification(df)\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"***************Unification - 0.1_0.06**********************\")\n",
    "print(results_df1)\n",
    "print(\"***************Unification - majority voting**********************\")\n",
    "print(results_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_normalised1 = pd.read_csv(\"NormalisedDataset_01006.csv\")\n",
    "df_normalised2 = pd.read_csv(\"NormalisedDataset_majoritycluster.csv\")\n",
    "\n",
    "df_normalised_quality1 = df_normalised1[['Completeness_normalized', 'Conciseness_normalized',  'ClassImbRatio_normalized', 'ClassOverlapPerc_normalized',\n",
    "       'OutlierPerc_normalized',  'LabelIssuesPerc_normalized', 'FeatureAlgo_normalized']]\n",
    "df_normalised_char1 = df_normalised1[[ 'cor.mean_normalized', 'cov.mean_normalized',\n",
    "       'eigenvalues.mean_normalized', 'g_mean.mean_normalized',\n",
    "       'h_mean.mean_normalized', 'iq_range.mean_normalized',\n",
    "       'kurtosis.mean_normalized', 'mad.mean_normalized',\n",
    "       'max.mean_normalized', 'mean.mean_normalized', 'median.mean_normalized',\n",
    "       'min.mean_normalized', 'nr_cor_attr_normalized', 'nr_norm_normalized',\n",
    "       'nr_outliers_normalized', 'range.mean_normalized', 'sd.mean_normalized',\n",
    "       'skewness.mean_normalized', 'sparsity.mean_normalized',\n",
    "       't_mean.mean_normalized', 'var.mean_normalized',\n",
    "        'attr_to_inst_normalized',\n",
    "       'inst_to_attr_normalized', 'nr_attr_normalized', 'nr_bin_normalized',\n",
    "       'nr_inst_normalized', 'nr_num_normalized', 'attr_conc.mean_normalized',\n",
    "       'attr_ent.mean_normalized', 'nUnique_normalized', 'ena_normalized', 'snr.mean_normalized',\n",
    "       'cEntropy_normalized', 'FeatureAlgo_normalized']]\n",
    "df_normalised_quality2 = df_normalised2[['Completeness_normalized', 'Conciseness_normalized',  'ClassImbRatio_normalized', 'ClassOverlapPerc_normalized',\n",
    "       'OutlierPerc_normalized',  'LabelIssuesPerc_normalized', 'FeatureAlgo_normalized']]\n",
    "df_normalised_char2 = df_normalised2[[ 'cor.mean_normalized', 'cov.mean_normalized',\n",
    "       'eigenvalues.mean_normalized', 'g_mean.mean_normalized',\n",
    "       'h_mean.mean_normalized', 'iq_range.mean_normalized',\n",
    "       'kurtosis.mean_normalized', 'mad.mean_normalized',\n",
    "       'max.mean_normalized', 'mean.mean_normalized', 'median.mean_normalized',\n",
    "       'min.mean_normalized', 'nr_cor_attr_normalized', 'nr_norm_normalized',\n",
    "       'nr_outliers_normalized', 'range.mean_normalized', 'sd.mean_normalized',\n",
    "       'skewness.mean_normalized', 'sparsity.mean_normalized',\n",
    "       't_mean.mean_normalized', 'var.mean_normalized',\n",
    "        'attr_to_inst_normalized',\n",
    "       'inst_to_attr_normalized', 'nr_attr_normalized', 'nr_bin_normalized',\n",
    "       'nr_inst_normalized', 'nr_num_normalized', 'attr_conc.mean_normalized',\n",
    "       'attr_ent.mean_normalized', 'nUnique_normalized', 'ena_normalized', 'snr.mean_normalized',\n",
    "       'cEntropy_normalized', 'FeatureAlgo_normalized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************KNN - 0.1_0.06**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.449735                    0.550265   \n",
      "df_normalised_char                     0.470899                    0.529101   \n",
      "df_normalised_quality                  0.428042                    0.571958   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.542857        0.457143  0.487912  0.542857   \n",
      "df_normalised_char         0.428571        0.571429  0.388889  0.428571   \n",
      "df_normalised_quality      0.457143        0.542857  0.380952  0.457143   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.508844   \n",
      "df_normalised_char      0.39599   \n",
      "df_normalised_quality  0.413605   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[5, 0, 3, 0], [1, 0, 0, 1], [5, 0, 14, 1], [2...  \n",
      "df_normalised_char     [[5, 0, 3, 0], [0, 0, 2, 0], [9, 0, 10, 1], [2...  \n",
      "df_normalised_quality  [[1, 0, 5, 2], [2, 0, 0, 0], [3, 0, 15, 2], [0...  \n",
      "\n",
      "\n",
      "**************KNN - Majority clustering**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.434656                    0.565344   \n",
      "df_normalised_char                     0.470635                    0.529365   \n",
      "df_normalised_quality                  0.392063                    0.607937   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.485714        0.514286  0.581418  0.485714   \n",
      "df_normalised_char         0.428571        0.571429  0.497479  0.428571   \n",
      "df_normalised_quality      0.342857        0.657143  0.253524  0.342857   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.474014   \n",
      "df_normalised_char     0.405318   \n",
      "df_normalised_quality  0.282271   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[5, 0, 6, 0], [1, 1, 0, 0], [6, 0, 10, 0], [2...  \n",
      "df_normalised_char     [[6, 0, 5, 0], [0, 0, 2, 0], [8, 0, 8, 0], [3,...  \n",
      "df_normalised_quality  [[1, 0, 8, 2], [2, 0, 0, 0], [3, 0, 11, 2], [0...  \n"
     ]
    }
   ],
   "source": [
    "def evaluate_knn(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  \n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(knn_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "datasets1 = {\n",
    "    'df_normalised': df_normalised1,\n",
    "    'df_normalised_char': df_normalised_char1,\n",
    "    'df_normalised_quality': df_normalised_quality1\n",
    "}\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************KNN - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "datasets2 = {\n",
    "    'df_normalised': df_normalised2,\n",
    "    'df_normalised_char': df_normalised_char2,\n",
    "    'df_normalised_quality': df_normalised_quality2\n",
    "}\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************KNN - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************DT - 0.1_0.06**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.623545                    0.376455   \n",
      "df_normalised_char                     0.485714                    0.514286   \n",
      "df_normalised_quality                  0.492593                    0.507407   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.514286        0.485714  0.515934  0.514286   \n",
      "df_normalised_char         0.457143        0.542857  0.431232  0.457143   \n",
      "df_normalised_quality      0.485714        0.514286  0.391461  0.485714   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.501587   \n",
      "df_normalised_char     0.438723   \n",
      "df_normalised_quality  0.414736   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[7, 0, 1, 0, 0], [0, 0, 1, 1, 0], [4, 0, 11, ...  \n",
      "df_normalised_char     [[4, 0, 4, 0], [2, 0, 0, 0], [5, 0, 12, 3], [2...  \n",
      "df_normalised_quality  [[1, 0, 7, 0, 0], [1, 0, 1, 0, 0], [1, 1, 16, ...  \n",
      "\n",
      "\n",
      "**************DT - Majority clustering**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.601852                    0.398148   \n",
      "df_normalised_char                     0.520899                    0.479101   \n",
      "df_normalised_quality                  0.427778                    0.572222   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.542857        0.457143  0.540952  0.542857   \n",
      "df_normalised_char         0.428571        0.571429  0.348639  0.428571   \n",
      "df_normalised_quality      0.371429        0.628571  0.258776  0.371429   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.541214   \n",
      "df_normalised_char      0.38375   \n",
      "df_normalised_quality  0.288636   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[8, 0, 3, 0, 0], [0, 0, 1, 1, 0], [2, 0, 9, 3...  \n",
      "df_normalised_char     [[5, 0, 6, 0], [1, 0, 1, 0], [4, 0, 10, 2], [2...  \n",
      "df_normalised_quality  [[1, 0, 10, 0, 0], [2, 0, 0, 0, 0], [2, 1, 12,...  \n"
     ]
    }
   ],
   "source": [
    "def evaluate_decision_tree(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  \n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    tree_classifier = DecisionTreeClassifier(random_state=random_state)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(tree_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "    y_pred = tree_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************DT - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************DT - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.456639                    0.543361   \n",
      "df_normalised_char                     0.497143                    0.502857   \n",
      "df_normalised_quality                   0.39916                     0.60084   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.542857        0.457143  0.474258  0.542857   \n",
      "df_normalised_char         0.457143        0.542857  0.428571  0.457143   \n",
      "df_normalised_quality      0.428571        0.571429  0.390476  0.428571   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.506234   \n",
      "df_normalised_char         0.44   \n",
      "df_normalised_quality  0.401732   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[4, 0, 4, 0], [1, 0, 0, 1], [3, 0, 15, 2], [1...  \n",
      "df_normalised_char     [[3, 0, 4, 0, 1], [2, 0, 0, 0, 0], [5, 0, 13, ...  \n",
      "df_normalised_quality  [[1, 0, 5, 2, 0], [2, 0, 0, 0, 0], [1, 1, 14, ...  \n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.422017                    0.577983   \n",
      "df_normalised_char                     0.462353                    0.537647   \n",
      "df_normalised_quality                  0.358655                    0.641345   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.485714        0.514286  0.413112  0.485714   \n",
      "df_normalised_char         0.428571        0.571429  0.344218  0.428571   \n",
      "df_normalised_quality      0.342857        0.657143  0.279714  0.342857   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.438462   \n",
      "df_normalised_char     0.381131   \n",
      "df_normalised_quality  0.287201   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[5, 0, 6, 0], [1, 0, 0, 1], [2, 0, 12, 2], [1...  \n",
      "df_normalised_char     [[4, 0, 6, 0, 1], [2, 0, 0, 0, 0], [4, 0, 11, ...  \n",
      "df_normalised_quality  [[1, 0, 8, 2, 0], [2, 0, 0, 0, 0], [1, 1, 11, ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "datasets1 = {\n",
    "    'df_normalised': df_normalised1,\n",
    "    'df_normalised_char': df_normalised_char1,\n",
    "    'df_normalised_quality': df_normalised_quality1\n",
    "}\n",
    "\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "datasets2 = {\n",
    "    'df_normalised': df_normalised2,\n",
    "    'df_normalised_char': df_normalised_char2,\n",
    "    'df_normalised_quality': df_normalised_quality2\n",
    "}\n",
    "\n",
    "\n",
    "metric_name = 'Euclidean'\n",
    "metric_func = lambda X_train, X_test: np.sqrt(((X_train.values[:, np.newaxis] - X_test.values) ** 2).sum(axis=2))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=33)\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        cv_error_rate = 1 - cv_accuracy\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "      \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    nearest_labels = y_encoded[nearest_indices]\n",
    "    predicted_labels = y_train[nearest_indices] \n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "        \n",
    "    test_accuracy =accuracy_score(y_test, predicted_labels)\n",
    "\n",
    "    results1[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': (test_accuracy),\n",
    "        'Test Error Rate': (1 - test_accuracy),\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score':f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        cv_error_rate = 1 - cv_accuracy\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "      \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    nearest_labels = y_encoded[nearest_indices]\n",
    "    predicted_labels = y_train[nearest_indices] \n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "        \n",
    "    test_accuracy =accuracy_score(y_test, predicted_labels)\n",
    "\n",
    "    results2[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': (test_accuracy),\n",
    "        'Test Error Rate': (1 - test_accuracy),\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score':f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "\n",
    "print(results_df1)\n",
    "\n",
    "\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(results_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Unification - 0.1_0.06**********************\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.431263                    0.568737   \n",
      "df_normalised_char                     0.319669                    0.680331   \n",
      "df_normalised_quality                  0.253957                    0.746043   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised                  0.25            0.75  0.295833      0.25   \n",
      "df_normalised_char         0.333333        0.666667  0.447619  0.333333   \n",
      "df_normalised_quality       0.30303         0.69697  0.581818   0.30303   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.265873   \n",
      "df_normalised_char     0.381944   \n",
      "df_normalised_quality  0.387205   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[1, 0, 2, 0], [1, 0, 0, 0], [2, 0, 2, 3], [0,...  \n",
      "df_normalised_char     [[3, 0, 3, 1], [0, 0, 0, 0], [1, 2, 3, 3], [1,...  \n",
      "df_normalised_quality  [[2, 1, 1, 3, 1], [0, 0, 0, 1, 0], [7, 2, 8, 4...  \n",
      "***************Unification - majority voting**********************\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.376148                    0.623852   \n",
      "df_normalised_char                     0.333992                    0.666008   \n",
      "df_normalised_quality                  0.271436                    0.728564   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.333333        0.666667  0.391667  0.333333   \n",
      "df_normalised_char         0.333333        0.666667       0.4  0.333333   \n",
      "df_normalised_quality      0.242424        0.757576  0.412121  0.242424   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.337121   \n",
      "df_normalised_char     0.361111   \n",
      "df_normalised_quality  0.296296   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[2, 0, 1, 0], [1, 0, 0, 0], [2, 0, 2, 3], [0,...  \n",
      "df_normalised_char     [[3, 0, 3, 1], [0, 0, 0, 0], [1, 2, 2, 2], [1,...  \n",
      "df_normalised_quality  [[2, 1, 1, 3, 1], [0, 0, 0, 1, 0], [7, 2, 6, 4...  \n"
     ]
    }
   ],
   "source": [
    "def unify_features(test_sample, train_data, train_labels):\n",
    "    test_features = test_sample.values\n",
    "    matching_indices = np.all(train_data == test_features, axis=1)\n",
    "    if matching_indices.any():\n",
    "        matching_labels = train_labels[matching_indices]\n",
    "        return np.unique(matching_labels)\n",
    "    return [\"unknown\"]\n",
    "\n",
    "def evaluate_unification(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "        \n",
    "        predicted_labels = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "            predicted_labels.append(label)\n",
    "        \n",
    "        predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "        valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        \n",
    "        if not valid_indices:\n",
    "            continue\n",
    "        \n",
    "        valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "        valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "        cv_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "       \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=2)\n",
    "    predicted_labels = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "        predicted_labels.append(label)\n",
    "    predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "    valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        \n",
    "    valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "    valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "    precision = precision_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(valid_truth, valid_predictions)    \n",
    "    test_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "\n",
    "    return {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_unification(df)\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_unification(df)\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"***************Unification - 0.1_0.06**********************\")\n",
    "print(results_df1)\n",
    "print(\"***************Unification - majority voting**********************\")\n",
    "print(results_df2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".deeplearningClass",
   "language": "python",
   "name": ".deeplearningclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68ad885796f6f0b806db95b15cf2a015a244c9adabe8d6cffa3fc143090837a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
