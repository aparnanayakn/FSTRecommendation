{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this file considers feature selection technique as label\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import jenkspy\n",
    "from ast import literal_eval\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"df_mfeatures.csv\")\n",
    "df2 = pd.read_csv(\"df_ensemble_allfeatures.csv\")\n",
    "\n",
    "binDF = pd.read_csv(\"BinnedMetaFeatures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df1[['File', 'Completeness', 'Conciseness', 'cor.mean', 'cov.mean',\n",
    "       'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', 'kurtosis.mean', \n",
    "       'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr',\n",
    "       'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean',\n",
    "       'sparsity.mean', 't_mean.mean',   'var.mean', 'ClassImbRatio',\n",
    "       'ClassOverlapPerc', 'OutlierPerc', 'attr_to_inst', 'inst_to_attr', 'nr_attr',\n",
    "        'nr_bin',  'nr_inst', 'nr_num', 'attr_conc.mean', 'attr_ent.mean', 'ena', 'nUnique' ,'snr.mean', 'cEntropy','LabelIssuesPerc']] #SyntaxAccuracy removed\n",
    "\n",
    "df_imp_subset = df1[['File', 'cov.mean',\n",
    "       'eigenvalues.mean', 'iq_range.mean',\n",
    "        'kurtosis.mean', 'inst_to_attr',\n",
    "        'skewness.mean', 'mean.mean',\n",
    "       'sparsity.mean','nr_inst', 'nr_num',\n",
    "        'attr_conc.mean', 'attr_ent.mean', \n",
    "        'ena', 'snr.mean', 'cEntropy','LabelIssuesPerc']] #SyntaxAccuracy removed\n",
    "\n",
    "df_bin_new = binDF[['Completeness_bins', 'Conciseness_bins',  'cor.mean_bins', 'cov.mean_bins', \n",
    "              'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins', 'iq_range.mean_bins', 'kurtosis.mean_bins',\n",
    "              'mad.mean_bins', 'max.mean_bins',  'mean.mean_bins', 'median.mean_bins',  'min.mean_bins', 'nr_cor_attr_bins', \n",
    "              'nr_norm_bins', 'nr_outliers_bins', 'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "              'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins', 'LabelIssues_bins', 'ClassImbRatio_bins', \n",
    "              'OutlierPerc_bins', 'ClassOverlapPerc_bins', 'attr_to_inst_bins', 'inst_to_attr_bins', 'nr_attr_bins',\n",
    "              'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins', 'attr_conc.mean_bins', 'cEntropy_bins', 'ena_bins', 'snr.mean_bins', 'nUnique_bins','attr_ent.mean_bins', 'File']] #'SyntaxAccuracy_bins' removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 17)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_imp_subset).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority voting calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Majority vote labels saved to 'majority_voted_labels.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "\n",
    "path = os.getcwd()+'/optimalalphabeta/dearr_cont/'  \n",
    "csv_files = glob(os.path.join(path, 'dearr*.csv'))\n",
    "\n",
    "labels_dict = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        dataset_id = row['File']  \n",
    "        best_fs = row['FeatureAlgo']     \n",
    "        \n",
    "        if dataset_id not in labels_dict:\n",
    "            labels_dict[dataset_id] = []\n",
    "        labels_dict[dataset_id].append(best_fs)\n",
    "\n",
    "majority_labels = {\n",
    "    dataset: Counter(fs_list).most_common(1)[0][0]\n",
    "    for dataset, fs_list in labels_dict.items()\n",
    "}\n",
    "\n",
    "majority_df = pd.DataFrame(list(majority_labels.items()), columns=['File', 'FeatureAlgo'])\n",
    "majority_df.to_csv('majority_voted_labels.csv', index=False)\n",
    "\n",
    "print(\" Majority vote labels saved to 'majority_voted_labels.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority voting based on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "\n",
    "path = os.getcwd()+'/optimalalphabeta/clusteredearr/'  # replace with the path to your 36 CSVs\n",
    "csv_files = glob(os.path.join(path, 'dearr*.csv'))\n",
    "\n",
    "labels_dict = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        dataset_id = row['File']  # replace 'Dataset' with your actual column name\n",
    "        best_fs = row['FeatureAlgo']     # replace 'Best_FS' with your actual column name\n",
    "        \n",
    "        if dataset_id not in labels_dict:\n",
    "            labels_dict[dataset_id] = []\n",
    "        labels_dict[dataset_id].append(best_fs)\n",
    "\n",
    "majority_labels = {\n",
    "    dataset: Counter(fs_list).most_common(1)[0][0]\n",
    "    for dataset, fs_list in labels_dict.items()\n",
    "}\n",
    "\n",
    "majority_df = pd.DataFrame(list(majority_labels.items()), columns=['File', 'FeatureAlgo'])\n",
    "majority_df.to_csv('majority_voted_labels_clusteredearr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging two dataframes to add target feature\n",
    "df1 = pd.read_csv('majority_voted_labels_clusteredearr.csv')\n",
    "\n",
    "df2 = pd.read_csv('meta-features-cont.csv')\n",
    "merged_df = pd.merge(df1, df2, on='File', how='inner')  # use 'left', 'right', or 'outer' as needed\n",
    "\n",
    "merged_df.to_csv(\"majorityvoteclusteredearrdataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_mapping = {\n",
    "    'MI': ('Uni', 'Information'),\n",
    "    'GR': ('Uni', 'Information'),\n",
    "    'fcbf': ('Multi', 'Information'),\n",
    "    'chisquare': ('Uni', 'Dependency'),\n",
    "    'mRMR': ('Multi', 'Dependency'),\n",
    "    'cfs': ('Multi', 'Dependency'),\n",
    "    'relief': ('Uni', 'Distance'),\n",
    "    'relieff': ('Uni', 'Distance'),\n",
    "    'multisurf': ('Multi', 'Distance')\n",
    "}\n",
    "\n",
    "def get_setting(algo):\n",
    "    return fs_mapping.get(algo, ('Unknown', 'Unknown'))  # default if not found\n",
    "\n",
    "\n",
    "merged_df[['FS_Setting', 'FS_Type']] = merged_df['FeatureAlgo'].apply(lambda x: pd.Series(get_setting(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def correlation_filter(df, threshold=0.9):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    return df.drop(columns=to_drop)\n",
    "df1 = pd.read_csv('majority_voted_labels_clusteredearr.csv')\n",
    "\n",
    "df2 = pd.read_csv('meta-features-cont.csv')\n",
    "# Separate the 'File' column\n",
    "file_col = df2['File']\n",
    "\n",
    "# Apply correlation filter to the rest of the columns\n",
    "X_filtered = correlation_filter(df2.drop(columns=['File']))\n",
    "\n",
    "X_filtered['File'] = file_col\n",
    "\n",
    "X_filtered = pd.merge(X_filtered, df1 , on='File', how='inner')  # use 'left', 'right', or 'outer' as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features based on model importance:\n",
      "['cor.mean', 'cov.mean', 'eigenvalues.mean', 'iq_range.mean', 'kurtosis.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean', 'var.mean', 'inst_to_attr', 'nr_inst', 'nr_num', 'attr_conc.mean', 'attr_ent.mean', 'ena', 'snr.mean', 'cEntropy', 'LabelIssuesPerc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "X = merged_df.drop(['File', 'FeatureAlgo','FS_Setting','FS_Type'], axis=1)\n",
    "X = X.apply(le.fit_transform)\n",
    "y=merged_df['FeatureAlgo']\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Select features with importance greater than the mean importance\n",
    "selector = SelectFromModel(clf, threshold='mean', prefit=True)\n",
    "X_selected = selector.transform(X)\n",
    "\n",
    "# Get feature names\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Selected Features based on model importance:\")\n",
    "print(selected_features.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = list(set(selected_features.tolist()).union(set(X_filtered.columns)))\n",
    "common_features = list(set(selected_features.tolist()).intersection(set(X_filtered.columns)))\n",
    "len(common_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features = set(df_imp_subset.columns) - set(['File'])\n",
    "common_features = list(set(selected_features.tolist()).intersection(set(X_filtered.columns)).intersection(set(df_imp_subset.columns)))\n",
    "all_features = list(set(selected_features.tolist()).union(set(X_filtered.columns)).union(set(imp_features)))\n",
    "all_features = list(set(all_features)-set(['FeatureAlgo','File']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attr_conc.mean',\n",
       " 'inst_to_attr',\n",
       " 'attr_ent.mean',\n",
       " 'cov.mean',\n",
       " 'eigenvalues.mean',\n",
       " 'kurtosis.mean',\n",
       " 'cEntropy',\n",
       " 'sparsity.mean',\n",
       " 'nr_inst',\n",
       " 'ena',\n",
       " 'snr.mean',\n",
       " 'LabelIssuesPerc']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, _tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_rules_with_support_confidence(tree_model, feature_names, X, y):\n",
    "    tree_ = tree_model.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    \n",
    "    paths = []\n",
    "    rules = []\n",
    "\n",
    "    def recurse(node, path, conds):\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            left_path = path.copy()\n",
    "            left_path.append(f\"({name} <= {threshold:.3f})\")\n",
    "            recurse(tree_.children_left[node], left_path, conds)\n",
    "\n",
    "            right_path = path.copy()\n",
    "            right_path.append(f\"({name} > {threshold:.3f})\")\n",
    "            recurse(tree_.children_right[node], right_path, conds)\n",
    "        else:\n",
    "            path_str = \" and \".join(path)\n",
    "            support = tree_.n_node_samples[node] / tree_.n_node_samples[0]\n",
    "            value = tree_.value[node][0]\n",
    "            predicted_class = np.argmax(value)\n",
    "            confidence = value[predicted_class] / np.sum(value)\n",
    "            rules.append((path_str, predicted_class, support, confidence))\n",
    "\n",
    "    recurse(0, [], rules)\n",
    "\n",
    "    return pd.DataFrame(rules, columns=[\"Rule\", \"Predicted_Class\", \"Support\", \"Confidence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Rule  Predicted_Class  \\\n",
      "0   (cEntropy <= 30.000) and (eigenvalues.mean <= ...                0   \n",
      "1   (cEntropy <= 30.000) and (eigenvalues.mean <= ...                4   \n",
      "2   (cEntropy <= 30.000) and (eigenvalues.mean > 2...                3   \n",
      "3   (cEntropy <= 30.000) and (eigenvalues.mean > 2...                4   \n",
      "4   (cEntropy <= 30.000) and (eigenvalues.mean > 2...                3   \n",
      "10  (cEntropy > 30.000) and (snr.mean > 127.500) a...                5   \n",
      "5   (cEntropy > 30.000) and (snr.mean <= 127.500) ...                3   \n",
      "7   (cEntropy > 30.000) and (snr.mean <= 127.500) ...                3   \n",
      "6   (cEntropy > 30.000) and (snr.mean <= 127.500) ...                5   \n",
      "9   (cEntropy > 30.000) and (snr.mean > 127.500) a...                0   \n",
      "\n",
      "     Support  Confidence  \n",
      "0   0.007246    1.000000  \n",
      "1   0.007246    1.000000  \n",
      "2   0.007246    1.000000  \n",
      "3   0.007246    1.000000  \n",
      "4   0.144928    1.000000  \n",
      "10  0.007246    1.000000  \n",
      "5   0.065217    0.888889  \n",
      "7   0.065217    0.777778  \n",
      "6   0.050725    0.714286  \n",
      "9   0.050725    0.714286  \n",
      "Feature_Algo Report (all features):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.80      0.55        10\n",
      "           1       0.00      0.00      0.00         3\n",
      "           3       0.62      0.67      0.64        12\n",
      "           4       0.50      0.14      0.22         7\n",
      "           5       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.51        35\n",
      "   macro avg       0.51      0.39      0.38        35\n",
      "weighted avg       0.52      0.51      0.46        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Without clustering - all-features\n",
    "le = LabelEncoder()\n",
    "#X = merged_df.drop(['File','FS_Setting','FS_Type','FeatureAlgo'], axis=1)\n",
    "X = merged_df[common_features]\n",
    "X = X.apply(le.fit_transform)\n",
    "\n",
    "y = merged_df['FeatureAlgo'] # Encode both\n",
    "label_encoder = LabelEncoder().fit(y)\n",
    "y = label_encoder.transform(y)\n",
    "list(label_encoder.classes_)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.8)\n",
    "\n",
    "# Train a simple tree (can be one of your hierarchical models)\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "clf.fit(X_train, y_train)  # y_train can be FS_Type or FS_Setting\n",
    "\n",
    "# Get readable rules with metrics\n",
    "rule_df = get_rules_with_support_confidence(clf, feature_names=X_train.columns.tolist(), X=X_train, y=y_train)\n",
    "\n",
    "# Display top rules\n",
    "print(rule_df.sort_values(by='Confidence', ascending=False).head(10))\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_type_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Feature_Algo Report (all features):\")\n",
    "print(classification_report(y_test, y_type_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'GR', 1: 'MI', 2: 'cfs', 3: 'chisquare', 4: 'fcbf', 5: 'relief'}\n"
     ]
    }
   ],
   "source": [
    "int_to_label = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "print(int_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Rule  Predicted_Class  \\\n",
      "0                             (FeatureAlgo <= 0.500)                0   \n",
      "1  (FeatureAlgo > 0.500) and (FeatureAlgo <= 3.50...                1   \n",
      "2  (FeatureAlgo > 0.500) and (FeatureAlgo <= 3.50...                2   \n",
      "3  (FeatureAlgo > 0.500) and (FeatureAlgo <= 3.50...                3   \n",
      "4  (FeatureAlgo > 0.500) and (FeatureAlgo > 3.500...                4   \n",
      "5  (FeatureAlgo > 0.500) and (FeatureAlgo > 3.500...                5   \n",
      "\n",
      "    Support  Confidence  \n",
      "0  0.275362         1.0  \n",
      "1  0.079710         1.0  \n",
      "2  0.007246         1.0  \n",
      "3  0.391304         1.0  \n",
      "4  0.130435         1.0  \n",
      "5  0.115942         1.0  \n"
     ]
    }
   ],
   "source": [
    "#With clustering\n",
    "le = LabelEncoder()\n",
    "#X = merged_df.drop(['File','FS_Setting','FS_Type','FeatureAlgo'], axis=1)\n",
    "X = merged_df[all_features]\n",
    "X = X.apply(le.fit_transform)\n",
    "\n",
    "y = merged_df['FeatureAlgo'] # Encode both\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.8)\n",
    "\n",
    "# Train a simple tree (can be one of your hierarchical models)\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "clf.fit(X_train, y_train)  # y_train can be FS_Type or FS_Setting\n",
    "\n",
    "# Get readable rules with metrics\n",
    "rule_df = get_rules_with_support_confidence(clf, feature_names=X_train.columns.tolist(), X=X_train, y=y_train)\n",
    "\n",
    "# Display top rules\n",
    "print(rule_df.sort_values(by='Confidence', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Rule  Predicted_Class  \\\n",
      "0                             (FeatureAlgo <= 0.500)                0   \n",
      "1  (FeatureAlgo > 0.500) and (FeatureAlgo <= 3.50...                1   \n",
      "2  (FeatureAlgo > 0.500) and (FeatureAlgo <= 3.50...                2   \n",
      "3  (FeatureAlgo > 0.500) and (FeatureAlgo <= 3.50...                3   \n",
      "4  (FeatureAlgo > 0.500) and (FeatureAlgo > 3.500...                4   \n",
      "5  (FeatureAlgo > 0.500) and (FeatureAlgo > 3.500...                5   \n",
      "\n",
      "    Support  Confidence  \n",
      "0  0.275362         1.0  \n",
      "1  0.079710         1.0  \n",
      "2  0.007246         1.0  \n",
      "3  0.391304         1.0  \n",
      "4  0.130435         1.0  \n",
      "5  0.115942         1.0  \n"
     ]
    }
   ],
   "source": [
    "#Without clustering\n",
    "le = LabelEncoder()\n",
    "#X = merged_df.drop(['File','FS_Setting','FS_Type','FeatureAlgo'], axis=1)\n",
    "X = merged_df[all_features]\n",
    "X = X.apply(le.fit_transform)\n",
    "\n",
    "y = merged_df['FeatureAlgo'] # Encode both\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.8)\n",
    "\n",
    "# Train a simple tree (can be one of your hierarchical models)\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "clf.fit(X_train, y_train)  # y_train can be FS_Type or FS_Setting\n",
    "\n",
    "# Get readable rules with metrics\n",
    "rule_df = get_rules_with_support_confidence(clf, feature_names=X_train.columns.tolist(), X=X_train, y=y_train)\n",
    "\n",
    "# Display top rules\n",
    "print(rule_df.sort_values(by='Confidence', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomOverSampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-fbd659be8b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You can chain oversamplers in a pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mover_sampler1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msmote1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'not majority'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 1: Random oversample small classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomOverSampler' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# You can chain oversamplers in a pipeline\n",
    "over_sampler1 = RandomOverSampler(random_state=42)\n",
    "smote1 = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "\n",
    "# Step 1: Random oversample small classes\n",
    "X_ros, y_ros = over_sampler1.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 2: Apply SMOTE to remaining minority classes\n",
    "X_balanced, y_balanced = smote1.fit_resample(X_ros, y_ros)\n",
    "\n",
    "clf5 = clf = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "#(class_weight='balanced', random_state=42)\n",
    "clf5.fit(X_balanced, y_balanced)\n",
    "\n",
    "y_type_pred = clf5.predict(X_test)\n",
    "\n",
    "print(\"Feature_Algo Report (common features):\")\n",
    "print(classification_report(y_test, y_type_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_Algo Report (all features):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          GR       1.00      1.00      1.00        10\n",
      "          MI       1.00      1.00      1.00         3\n",
      "   chisquare       1.00      1.00      1.00        12\n",
      "        fcbf       1.00      1.00      1.00         7\n",
      "      relief       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        35\n",
      "   macro avg       1.00      1.00      1.00        35\n",
      "weighted avg       1.00      1.00      1.00        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Without clustering\n",
    "clf.fit(X_train, y_train)  # y_train can be FS_Type or FS_Setting\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_type_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Feature_Algo Report (all features):\")\n",
    "print(classification_report(y_test, y_type_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_Algo Report (common features):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          GR       1.00      1.00      1.00        10\n",
      "          MI       1.00      1.00      1.00         3\n",
      "   chisquare       1.00      1.00      1.00        12\n",
      "        fcbf       1.00      1.00      1.00         7\n",
      "      relief       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        35\n",
      "   macro avg       1.00      1.00      1.00        35\n",
      "weighted avg       1.00      1.00      1.00        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Without clustering\n",
    "clf.fit(X_train, y_train)  # y_train can be FS_Type or FS_Setting\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_type_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Feature_Algo Report (common features):\")\n",
    "print(classification_report(y_test, y_type_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_df.to_csv(\"rules.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features based on model importance:\n",
      "['cor.mean', 'cov.mean', 'eigenvalues.mean', 'iq_range.mean', 'kurtosis.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean', 'var.mean', 'inst_to_attr', 'nr_inst', 'nr_num', 'attr_conc.mean', 'attr_ent.mean', 'ena', 'snr.mean', 'cEntropy', 'LabelIssuesPerc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "X = merged_df.drop(['File', 'FeatureAlgo'], axis=1)\n",
    "X = X.apply(le.fit_transform)\n",
    "y=merged_df['FeatureAlgo']\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Select features with importance greater than the mean importance\n",
    "selector = SelectFromModel(clf, threshold='mean', prefit=True)\n",
    "X_selected = selector.transform(X)\n",
    "\n",
    "# Get feature names\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Selected Features based on model importance:\")\n",
    "print(selected_features.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = list(set(selected_features.tolist()).union(set(X_filtered.columns)))\n",
    "common_features = list(set(selected_features.tolist()).intersection(set(X_filtered.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcu_scores(df):\n",
    "    scores = []\n",
    "    #labels = df['FS_Setting_encoded']\n",
    "    labels = df['FS_Type_encoded']\n",
    "    #labels = df['FeatureAlgo']\n",
    "    features = df.drop(['FeatureAlgo', 'File'], axis=1)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    features = features.apply(le.fit_transform)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=42, train_size=0.8)\n",
    "\n",
    "    param_grid_mlp = {\n",
    "        'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "        'solver': ['sgd', 'adam'],\n",
    "        'alpha': [0.0001, 0.05],\n",
    "        'max_iter': [100, 200, 500]\n",
    "    }\n",
    "\n",
    "    param_grid_lr = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['saga']\n",
    "    }\n",
    "\n",
    "    param_grid_svc = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    }\n",
    "\n",
    "    param_grid_dt = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'ccp_alpha': [0.1, .01, .001],\n",
    "              'max_depth' : [5, 7, 9],\n",
    "              'criterion' :['gini', 'entropy']\n",
    "             }\n",
    "\n",
    "    mlp_clf = GridSearchCV(MLPClassifier(random_state=1), param_grid_mlp, cv=5)\n",
    "    lr_clf = GridSearchCV(LogisticRegression(random_state=0, max_iter=1000), param_grid_lr, cv=5)\n",
    "    dt_clf = GridSearchCV(DecisionTreeClassifier(), param_grid_dt, cv=5)\n",
    "    svc_clf = GridSearchCV(LinearSVC(random_state=0), param_grid_svc, cv=5)\n",
    "\n",
    "    mlp_clf.fit(X_train, y_train)\n",
    "    lr_clf.fit(X_train, y_train)\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    svc_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    mlp_predicted = mlp_clf.predict(X_test)\n",
    "    lr_predicted = lr_clf.predict(X_test)\n",
    "    dt_predicted = dt_clf.predict(X_test)\n",
    "    svc_predicted = svc_clf.predict(X_test)\n",
    "\n",
    "    # Append F1 scores\n",
    "    for clf_name, predicted in zip(\n",
    "        ['MLP', 'LR', 'RF', 'SVC'],\n",
    "        [mlp_predicted, lr_predicted, dt_predicted, svc_predicted]\n",
    "    ):\n",
    "        scores.append(f1_score(predicted, y_test, average='macro'))\n",
    "        scores.append(f1_score(predicted, y_test, average='micro'))\n",
    "        scores.append(f1_score(predicted, y_test, average='weighted'))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_Algo Report (common features):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          GR       0.71      1.00      0.83        10\n",
      "          MI       0.00      0.00      0.00         3\n",
      "   chisquare       1.00      1.00      1.00        12\n",
      "        fcbf       1.00      0.86      0.92         7\n",
      "      relief       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.89        35\n",
      "   macro avg       0.74      0.77      0.75        35\n",
      "weighted avg       0.83      0.89      0.85        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare X and multiple y targets\n",
    "X = merged_df.drop(['File','FeatureAlgo'], axis=1)\n",
    "X = X.apply(le.fit_transform)\n",
    "\n",
    "y = merged_df['FeatureAlgo'] # Encode both\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.8)\n",
    "\n",
    "# Base model\n",
    "base_clf3 = RandomForestClassifier()\n",
    "\n",
    "# Train a simple tree (can be one of your hierarchical models)\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "base_clf3.fit(X_train, y_train)  # y_train can be FS_Type or FS_Setting\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_type_pred = base_clf3.predict(X_test)\n",
    "\n",
    "print(\"Feature_Algo Report (common features):\")\n",
    "print(classification_report(y_test, y_type_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_Algo Report (common features):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          GR       0.57      0.80      0.67        10\n",
      "          MI       0.00      0.00      0.00         3\n",
      "   chisquare       0.69      0.92      0.79        12\n",
      "        fcbf       0.33      0.14      0.20         7\n",
      "      relief       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.60        35\n",
      "   macro avg       0.42      0.44      0.41        35\n",
      "weighted avg       0.51      0.60      0.53        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# You can chain oversamplers in a pipeline\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "smote = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "\n",
    "# Step 1: Random oversample small classes\n",
    "X_ros, y_ros = over_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 2: Apply SMOTE to remaining minority classes\n",
    "X_balanced, y_balanced = smote.fit_resample(X_ros, y_ros)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf4 = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "clf4.fit(X_balanced, y_balanced)\n",
    "\n",
    "y_type_pred = clf4.predict(X_test)\n",
    "\n",
    "print(\"Feature_Algo Report (common features):\")\n",
    "print(classification_report(y_test, y_type_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 29)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fs_mapping = {\n",
    "    'MI': ('Uni', 'Information'),\n",
    "    'GR': ('Uni', 'Information'),\n",
    "    'fcbf': ('Multi', 'Information'),\n",
    "    'chisquare': ('Uni', 'Dependency'),\n",
    "    'mRMR': ('Multi', 'Dependency'),\n",
    "    'cfs': ('Multi', 'Dependency'),\n",
    "    'relief': ('Uni', 'Distance'),\n",
    "    'relieff': ('Uni', 'Distance'),\n",
    "    'multisurf': ('Multi', 'Distance')\n",
    "}\n",
    "\n",
    "def get_setting(algo):\n",
    "    return fs_mapping.get(algo, ('Unknown', 'Unknown'))  # default if not found\n",
    "\n",
    "\n",
    "merged_df[['FS_Setting', 'FS_Type']] = merged_df['FeatureAlgo'].apply(lambda x: pd.Series(get_setting(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_Algo Report (common features):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Dependency       0.58      0.92      0.71        12\n",
      "    Distance       0.00      0.00      0.00         3\n",
      " Information       0.94      0.75      0.83        20\n",
      "\n",
      "    accuracy                           0.74        35\n",
      "   macro avg       0.51      0.56      0.51        35\n",
      "weighted avg       0.73      0.74      0.72        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare X and multiple y targets\n",
    "X = merged_df.drop(['File','FS_Setting','FS_Type','FeatureAlgo'], axis=1)\n",
    "X = X.apply(le.fit_transform)\n",
    "\n",
    "y = merged_df['FS_Type'] # Encode both\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.8)\n",
    "\n",
    "# Base model\n",
    "base_clf4 = RandomForestClassifier()\n",
    "\n",
    "# Train a simple tree (can be one of your hierarchical models)\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "base_clf4.fit(X_train, y_train)  # y_train can be FS_Type or FS_Setting\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_type_pred = base_clf4.predict(X_test)\n",
    "\n",
    "print(\"Feature_Algo Report (common features):\")\n",
    "print(classification_report(y_test, y_type_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_Algo Report (common features):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          GR       0.67      0.40      0.50        10\n",
      "          MI       0.33      0.33      0.33         3\n",
      "         cfs       0.00      0.00      0.00         0\n",
      "   chisquare       0.56      0.42      0.48        12\n",
      "        fcbf       0.25      0.14      0.18         7\n",
      "      relief       0.17      0.67      0.27         3\n",
      "\n",
      "    accuracy                           0.37        35\n",
      "   macro avg       0.33      0.33      0.29        35\n",
      "weighted avg       0.47      0.37      0.39        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Prepare X and multiple y targets\n",
    "X = merged_df.drop(['File','FS_Setting','FS_Type','FeatureAlgo'], axis=1)\n",
    "X = X.apply(le.fit_transform)\n",
    "\n",
    "y = merged_df['FeatureAlgo'] # Encode both\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.8)\n",
    "\n",
    "# You can chain oversamplers in a pipeline\n",
    "over_sampler1 = RandomOverSampler(random_state=42)\n",
    "smote1 = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "\n",
    "# Step 1: Random oversample small classes\n",
    "X_ros, y_ros = over_sampler1.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 2: Apply SMOTE to remaining minority classes\n",
    "X_balanced, y_balanced = smote1.fit_resample(X_ros, y_ros)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf5 = clf = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "#(class_weight='balanced', random_state=42)\n",
    "clf5.fit(X_balanced, y_balanced)\n",
    "\n",
    "y_type_pred = clf5.predict(X_test)\n",
    "\n",
    "print(\"Feature_Algo Report (common features):\")\n",
    "print(classification_report(y_test, y_type_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, _tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_rules_with_support_confidence(tree_model, feature_names, X, y):\n",
    "    tree_ = tree_model.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    \n",
    "    paths = []\n",
    "    rules = []\n",
    "\n",
    "    def recurse(node, path, conds):\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            left_path = path.copy()\n",
    "            left_path.append(f\"({name} <= {threshold:.3f})\")\n",
    "            recurse(tree_.children_left[node], left_path, conds)\n",
    "\n",
    "            right_path = path.copy()\n",
    "            right_path.append(f\"({name} > {threshold:.3f})\")\n",
    "            recurse(tree_.children_right[node], right_path, conds)\n",
    "        else:\n",
    "            path_str = \" and \".join(path)\n",
    "            support = tree_.n_node_samples[node] / tree_.n_node_samples[0]\n",
    "            value = tree_.value[node][0]\n",
    "            predicted_class = np.argmax(value)\n",
    "            confidence = value[predicted_class] / np.sum(value)\n",
    "            rules.append((path_str, predicted_class, support, confidence))\n",
    "\n",
    "    recurse(0, [], rules)\n",
    "\n",
    "    return pd.DataFrame(rules, columns=[\"Rule\", \"Predicted_Class\", \"Support\", \"Confidence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Rule  Predicted_Class  \\\n",
      "0        (cEntropy <= 30.000) and (var.mean <= 2.500)                2   \n",
      "1   (cEntropy <= 30.000) and (var.mean > 2.500) an...                0   \n",
      "2   (cEntropy <= 30.000) and (var.mean > 2.500) an...                2   \n",
      "3   (cEntropy <= 30.000) and (var.mean > 2.500) an...                0   \n",
      "4   (cEntropy > 30.000) and (sparsity.mean <= 95.5...                0   \n",
      "9   (cEntropy > 30.000) and (sparsity.mean > 95.50...                0   \n",
      "10  (cEntropy > 30.000) and (sparsity.mean > 95.50...                0   \n",
      "6   (cEntropy > 30.000) and (sparsity.mean <= 95.5...                2   \n",
      "11  (cEntropy > 30.000) and (sparsity.mean > 95.50...                2   \n",
      "7   (cEntropy > 30.000) and (sparsity.mean <= 95.5...                0   \n",
      "\n",
      "     Support  Confidence  \n",
      "0   0.014493    1.000000  \n",
      "1   0.007246    1.000000  \n",
      "2   0.007246    1.000000  \n",
      "3   0.144928    1.000000  \n",
      "4   0.021739    1.000000  \n",
      "9   0.079710    1.000000  \n",
      "10  0.014493    1.000000  \n",
      "6   0.442029    0.819672  \n",
      "11  0.086957    0.750000  \n",
      "7   0.065217    0.666667  \n"
     ]
    }
   ],
   "source": [
    "# Prepare X and multiple y targets\n",
    "X = merged_df.drop(['File','FS_Setting','FS_Type','FeatureAlgo'], axis=1)\n",
    "X = X.apply(le.fit_transform)\n",
    "\n",
    "y = merged_df['FS_Type'] # Encode both\n",
    "\n",
    "# Train a simple tree (can be one of your hierarchical models)\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "clf.fit(X_train, y_train)  # y_train can be FS_Type or FS_Setting\n",
    "\n",
    "# Get readable rules with metrics\n",
    "rule_df = get_rules_with_support_confidence(clf, feature_names=X_train.columns.tolist(), X=X_train, y=y_train)\n",
    "\n",
    "# Display top rules\n",
    "print(rule_df.sort_values(by='Confidence', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Information\n",
       "1       Dependency\n",
       "2       Dependency\n",
       "3      Information\n",
       "4      Information\n",
       "          ...     \n",
       "168    Information\n",
       "169       Distance\n",
       "170     Dependency\n",
       "171       Distance\n",
       "172    Information\n",
       "Name: FS_Type, Length: 173, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['FS_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".deeplearningClass",
   "language": "python",
   "name": ".deeplearningclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
