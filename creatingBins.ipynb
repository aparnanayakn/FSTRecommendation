{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import jenkspy\n",
    "\n",
    "import postProcessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to run only once\n",
    "#df = pd.read_csv(\"MetaFeatures.csv\")\n",
    "\n",
    "#temp = []\n",
    "#for i in df['LabelIssues']:\n",
    " #   if(i == '[]'):\n",
    " #       temp.append(0)\n",
    "  #  else:\n",
    "   #     temp.append(1)\n",
    "\n",
    "#df['LabelIssuesPerc']  = temp\n",
    "#df['LabelIssuesPerc'].value_counts()\n",
    "\n",
    "#df.to_csv(\"df_mfeatures.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"df_mfeatures.csv\")\n",
    "df2 = pd.read_csv(\"df_ensemble_allfeatures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['File', 'Completeness', 'MissColumns', 'Conciseness', 'SyntaxAccuracy',\n",
       "       'InvalidColumns', 'cor.mean', 'cor.sd', 'cov.mean', 'cov.sd',\n",
       "       'eigenvalues.mean', 'eigenvalues.sd', 'g_mean.mean', 'g_mean.sd',\n",
       "       'h_mean.mean', 'h_mean.sd', 'iq_range.mean', 'iq_range.sd',\n",
       "       'kurtosis.mean', 'kurtosis.sd', 'mad.mean', 'mad.sd', 'max.mean',\n",
       "       'max.sd', 'mean.mean', 'mean.sd', 'median.mean', 'median.sd',\n",
       "       'min.mean', 'min.sd', 'nr_cor_attr', 'nr_norm', 'nr_outliers',\n",
       "       'range.mean', 'range.sd', 'sd.mean', 'sd.sd', 'skewness.mean',\n",
       "       'skewness.sd', 'sparsity.mean', 'sparsity.sd', 't_mean.mean',\n",
       "       't_mean.sd', 'var.mean', 'var.sd', 'ClassImbPoints', 'ClassImbRatio',\n",
       "       'ClassOverlapPoints', 'ClassOverlapPerc', 'OutlierPoints',\n",
       "       'OutlierPerc', 'LabelIssues', 'attr_to_inst', 'cat_to_num',\n",
       "       'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_cat', 'nr_inst', 'nr_num',\n",
       "       'num_to_cat', 'attr_conc.mean', 'attr_conc.sd', 'attr_ent.mean',\n",
       "       'attr_ent.sd', 't2', 't3', 't4', 'nUnique', 'snr.mean', 'snr.sd', 'snr',\n",
       "       'ena', 'cEntropy', 'LabelIssuesPerc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['File', 'FeatureAlgo', 'Accuracy', 'Precision macro', 'Recall macro',\n",
       "       'Precision weight', 'Recall weight', 'Time FS', 'Features',\n",
       "       'Time ensemble', 'class index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax accuracy is 0 for all data points, as datasets has same valid column types. Hence, dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df, dict_values = postProcessing.generate_categories(df1)\n",
    "bin_df.to_csv(\"BinnedMetaFeatures.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating limits for each metric\n",
    "item_limits = {}\n",
    "features = []\n",
    "for item in dict_values.items():\n",
    "  temp = []\n",
    "  temp.append(item[0])\n",
    "  temp.append(item[1][0])\n",
    "  temp.append(item[1][1])\n",
    "  temp.append(item[1][1])\n",
    "  temp.append(item[1][2])\n",
    "  features.append(temp)\n",
    "\n",
    "df_new = pd.DataFrame(features)\n",
    "\n",
    "df_new.columns = ['features','small_lower','small_upper','big_lower','big_upper']\n",
    "df_new.set_index('features')\n",
    "df_new.to_csv(\"BinLimits.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating normalised values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def check_continuous_and_normalize(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]) and df[column].nunique() > 20:\n",
    "            mean = df[column].mean()\n",
    "            std = df[column].std()\n",
    "            new_column_name = f\"{column}_normalized\"\n",
    "            df[new_column_name] = np.where((df[column] >= mean - std) & (df[column] <= mean + std), 1, 0)\n",
    "        else:\n",
    "            print(\"column\",column)\n",
    "            new_column_name = f\"{column}_normalized\"\n",
    "            df[new_column_name] = df[column]\n",
    "\n",
    "    df.drop(columns=df.columns.difference([col for col in df.columns if '_normalized' in col]), inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column nr_norm\n",
      "column ClassImbRatio\n",
      "column nUnique\n",
      "column FeatureAlgo\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"KnowledgeBase.csv\")\n",
    "df1 =  df[['Completeness', 'Conciseness', 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'LabelIssuesPerc','nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "df_normalised = check_continuous_and_normalize(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalised.to_csv(\"NormalisedDataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(df):\n",
    "    statistics = []\n",
    "\n",
    "    for column in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]) and df[column].nunique() > 20:\n",
    "            mean = df[column].mean()\n",
    "            std = df[column].std()\n",
    "            statistics.append({'Column': column, 'Mean': mean, 'Standard Deviation': std})\n",
    "    return pd.DataFrame(statistics)\n",
    "\n",
    "\n",
    "statistics_df = calculate_statistics(df1)\n",
    "\n",
    "statistics_df.to_csv('NormalizationValues.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".deeplearningClass",
   "language": "python",
   "name": ".deeplearningclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
