{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n",
      "* Owlready2 * Running Pellet...\n",
      "    /usr/lib/jvm/java-17-openjdk-amd64/bin/java -Xmx2000M -cp /home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/xercesImpl-2.10.0.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jgrapht-jdk1.5.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jcl-over-slf4j-1.6.4.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/xml-apis-1.4.01.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/httpclient-4.2.3.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/commons-codec-1.6.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/antlr-3.2.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jena-core-2.10.0.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jena-arq-2.10.0.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/httpcore-4.2.2.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/slf4j-api-1.6.4.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/log4j-1.2.16.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jena-tdb-0.10.0.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/antlr-runtime-3.2.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jena-iri-0.9.5.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/owlapi-distribution-3.4.3-bin.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/pellet-2.3.1.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/aterm-java-1.6.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/slf4j-log4j12-1.6.4.jar pellet.Pellet realize --loader Jena --input-format N-Triples --infer-prop-values --infer-data-prop-values --ignore-imports /tmp/tmpfj1x1k9c\n",
      "* Owlready2 * Pellet took 0.8578104972839355 seconds\n",
      "* Owlready * (NB: only changes on entities loaded in Python are shown, other changes are done but not listed)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd1\n",
    "import jenkspy\n",
    "import numpy as np\n",
    "from owlready2 import *\n",
    "import ast \n",
    "import rdflib\n",
    "import re\n",
    "\n",
    "owlready2.JAVA_EXE =\"/usr/lib/jvm/java-17-openjdk-amd64/bin/java\"\n",
    "\n",
    "onto = get_ontology(\"file:///home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS_git/onto/MtLv2.owl\").load()\n",
    "#onto = get_ontology(\"file:///home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS_git/MtL_Enriched.owl\").load()\n",
    "\n",
    "dcat = get_namespace(\"http://www.w3.org/ns/dcat/\")\n",
    "dqv = get_namespace(\"http://www.w3.org/ns/dqv/\")\n",
    "mtl = get_ontology(\"https://purl.archive.org/domain/mtl#\")\n",
    "#onto.base_iri = \"https://purl.archive.org/domain/mtl#\"\n",
    "rdf=get_namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "dmop = get_ontology(\"http://www.e-lico.eu/ontologies/dmo/DMOP/DMOP.owl\")\n",
    "dmop.base_iri = \"http://www.e-lico.eu/ontologies/dmo/DMOP/DMOP.owl#\"\n",
    "dmop1 = get_ontology(\"http://www.e-LICO.eu/ontologies/dmo/DMOP/DMOP.owl\")\n",
    "dmop1.base_iri = \"http://www.e-LICO.eu/ontologies/dmo/DMOP/DMOP.owl#\"\n",
    "pd = get_ontology(\"http://www.e-lico.eu/ontologies/dmo/DMOP/PD.owl\")\n",
    "pd.base_iri = \"http://www.e-lico.eu/ontologies/dmo/DMOP/PD.owl#\"\n",
    "\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No need to run this if MtL_enriched is imported\n",
    "#Run this is MtL is imported\n",
    "with onto:\n",
    "    #MI\n",
    "    #(nr_inst <= 167.000) and (nr_inst > 99.500) and (range.mean > 3.788) and (attr_conc.mean > 0.053)\n",
    "    #float_gt_995_lt_167 = ConstrainedDatatype(float, min_exclusive = 99.5, max_inclusive = 167.0)\n",
    "    float_lt_167 = ConstrainedDatatype(float, max_inclusive = 167.0)\n",
    "    float_gt_995 = ConstrainedDatatype(float, min_exclusive = 99.5)\n",
    "    float_gt_378 = ConstrainedDatatype(float, min_exclusive = 3.788)         \n",
    "    float_gt_053 = ConstrainedDatatype(float, min_exclusive = 0.053)        \n",
    "    #Relief\n",
    "    #(nr_inst > 167.000) and (cov.mean <= 1.289) and (OutlierPerc > 0.012) and (cEntropy > 0.440) and (nr_outliers <= 12.500)\n",
    "    # and (ena <= 2.249) and (range.mean > 0.740) and (ena > -38.058) and (ena <= -0.690)\n",
    "    float_gt_38_lt_224 = ConstrainedDatatype(float, min_exclusive = -38.078, max_inclusive = 2.249)\n",
    "        \n",
    "    float_gt_167 = ConstrainedDatatype(float, min_exclusive = 167.000)\n",
    "    float_lt_128 = ConstrainedDatatype(float, max_inclusive = 1.289)\n",
    "    float_gt_012 = ConstrainedDatatype(float, min_exclusive = 0.012)\n",
    "    float_gt_044 = ConstrainedDatatype(float, min_exclusive = 0.044)         \n",
    "    float_lt_125 = ConstrainedDatatype(float, max_inclusive = 12.5)\n",
    "    float_gt_074 = ConstrainedDatatype(float, min_exclusive = 0.74)  \n",
    "\n",
    "    float_le_128 = ConstrainedDatatype(float, max_exclusive=1.289)\n",
    "          \n",
    "    #GR\n",
    "    #(nr_inst > 167.000) and (cov.mean > 1.289) and (nr_inst <= 372.000) and (ena <= 13.853) and (LabelIssuesPerc <= 0.068) and (cEntropy <= 0.990)\n",
    "  #  float_gt_167_lt_372 =  ConstrainedDatatype(float,  min_exclusive = 167.00, max_inclusive = 372.0)\n",
    "    float_lt_372 =  ConstrainedDatatype(float, max_inclusive = 372.0)\n",
    "\n",
    "   # float_gt_167_lt_372_1 = ConstrainedDatatype(float, min_exclusive = 167)\n",
    "  #  float_gt_167_lt_372_2 =  ConstrainedDatatype(float, max_inclusive = 372)\n",
    "    float_lt_068 = ConstrainedDatatype(float, max_inclusive = 0.068)\n",
    "    float_gt_128 = ConstrainedDatatype(float, min_exclusive = 1.289)         \n",
    "    float_lt_138 = ConstrainedDatatype(float, max_inclusive = 13.853)\n",
    "    float_lt_099 = ConstrainedDatatype(float, max_inclusive = 0.99)\n",
    "    #FCBF\n",
    "    #(nr_inst > 167.000) and (cov.mean > 1.289) and (nr_inst > 372.000) and (cor.mean > 0.119) and (skewness.mean <= 4.130) and (inst_to_attr <= 267.375)\n",
    "    # and (median.mean <= 26234.938) and (ClassImbRatio <= 0.733) and (ena > -0.405)\n",
    "    \"\"\"float_gt_167_2 = ConstrainedDatatype(float, min_exclusive = 167.0)\n",
    "    float_gt_128_2 = ConstrainedDatatype(float, min_exclusive = 1.289)\"\"\"\n",
    "    float_gt_119 = ConstrainedDatatype(float, min_exclusive = 0.119)\n",
    "    float_lt_413 = ConstrainedDatatype(float, max_inclusive = 4.13)\n",
    "    float_lt_267 = ConstrainedDatatype(float, max_inclusive = 267.375)         \n",
    "    float_lt_26234 = ConstrainedDatatype(float, max_inclusive = 26234.938)\n",
    "    float_lt_073 = ConstrainedDatatype(float, max_inclusive = 0.733)\n",
    "    float_gt_040 = ConstrainedDatatype(float, min_exclusive = -0.405)       \n",
    "    #Chisquare\n",
    "    #(nr_inst > 167.000) and (cov.mean <= 1.289) and (OutlierPerc <= 0.012) and (inst_to_attr <= 1614.176) and (nr_inst > 343.000)\n",
    "    # and (attr_ent.mean <= 3.683) and (nr_inst > 413.000)\n",
    "    \"\"\" float_gt_167_3 = ConstrainedDatatype(float, min_exclusive = 167.0)\n",
    "    #float_lt_128_2 = ConstrainedDatatype(float, max_inclusive = 1.289) \"\"\"\n",
    "    float_lt_012 = ConstrainedDatatype(float, max_inclusive = 0.012)\n",
    "    float_lt_1614 = ConstrainedDatatype(float, max_inclusive = 1614.176)\n",
    "    float_lt_3683 = ConstrainedDatatype(float, max_inclusive = 3.683)\n",
    "\n",
    "    #MI value constraints\n",
    "    class MIConstraintsInstances1(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_167)]\n",
    "\n",
    "    class MIConstraintsInstances2(mtl.Mean):\n",
    "        equivalent_to = [ MIConstraintsInstances1 &\n",
    "        mtl.hasDatavalue.some(float_gt_995)]\n",
    "\n",
    "    class MIConstraintsRange(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_378)]             \n",
    "\n",
    "    class MIConstraintsAttr(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_053)]             \n",
    "\n",
    "    #Relief value constraints\n",
    "    class ReliefConstraintsENA(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_38_lt_224) ]\n",
    "\n",
    "    class ReliefConstraintsRange(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_074)]             \n",
    "\n",
    "    class ReliefConstraintsInstances(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_167)]\n",
    "\n",
    "    AllDisjoint([MIConstraintsInstances1, ReliefConstraintsInstances])\n",
    "\n",
    "    class ReliefConstraintsCov(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_128)]\n",
    "\n",
    "    class ReliefConstraintsOutlierPerc(mtl.Mean):           \n",
    "        equivalent_to =  [mtl.Mean & mtl.hasDatavalue.some(float_gt_012)]\n",
    "\n",
    "    class ReliefConstraintscEntropy(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_044)]           \n",
    "\n",
    "    class ReliefConstraintsNrOut(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_125)]\n",
    "\n",
    "    #GR value constraints\n",
    "    '''class GRConstraintsInstances1(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_167)]'''\n",
    "\n",
    "    class GRConstraintsInstances2(mtl.Mean):\n",
    "        equivalent_to = [ ReliefConstraintsInstances & \n",
    "        mtl.hasDatavalue.some(float_lt_372)]\n",
    "        \n",
    "    class GRConstraintsCov(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_128)]\n",
    "\n",
    "    class GRConstraintsENA(mtl.Mean):            \n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_138)]\n",
    "\n",
    "    class GRConstraintsLabelissue(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_068)]\n",
    "\n",
    "    class GRConstraintscEntropy(mtl.Mean):         \n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_099)]\n",
    "\n",
    "    AllDisjoint([ReliefConstraintsCov, GRConstraintsCov])\n",
    "\n",
    "    #FCBF value constraints\n",
    "    \"\"\"class FCBFConstraintsCov(mtl.Mean):            \n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_128_2)]\n",
    "\n",
    "    class FCBFConstraintsInstances(mtl.Mean):         \n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_167_2)]\"\"\"\n",
    "\n",
    "    class FCBFConstraintsCorr(mtl.Mean):            \n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_119)]\n",
    "\n",
    "    class FCBFConstraintsSkew(mtl.Mean):            \n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_413)]\n",
    "\n",
    "    class FCBFConstraintsInstAttr(mtl.Mean):            \n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_267)]\n",
    "\n",
    "    class FCBFConstraintsMedian(mtl.Mean):            \n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_26234)]\n",
    "\n",
    "    class FCBFConstraintsClassImb(mtl.Mean):             \n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_073)]\n",
    "\n",
    "    class FCBFConstraintsENA(mtl.Mean):              \n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_040)]\n",
    "\n",
    "    #Chisquare value constraints\n",
    "    class ChisquareConstraintsOutlierPerc(mtl.Mean):\n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_012)]\n",
    "\n",
    "    AllDisjoint([ReliefConstraintsOutlierPerc, ChisquareConstraintsOutlierPerc])\n",
    "    \n",
    "    class ChisquareConstraintsInstAttr(mtl.Mean):\n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_1614)]\n",
    "\n",
    "    class ChisquareConstraintsAttrEnt(mtl.Mean):\n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_3683)]\n",
    "\n",
    "    #MI constraints mean\n",
    "    class MIMean1(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        dmop1.NumberOfInstances & mtl.qlocation.some(mtl.MIConstraintsInstances2)\n",
    "    ]\n",
    "\n",
    "    class MIMean2(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.Range & mtl.qlocation.some(mtl.MIConstraintsRange) ]\n",
    "\n",
    "    class MIMean3(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.AttributeConcentration & mtl.qlocation.some(mtl.MIConstraintsAttr) ]\n",
    "\n",
    "    #Relief constaints mean\n",
    "    class ReliefMean1(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        mtl.EqNumberOfAttributes & mtl.qlocation.some(mtl.ReliefConstraintsENA)\n",
    "    ]\n",
    "\n",
    "    class ReliefMean2(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.Range & mtl.qlocation.some(mtl.ReliefConstraintsRange) ]\n",
    "\n",
    "    class ReliefMean3(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            dmop1.NumberOfInstances & mtl.qlocation.some(mtl.ReliefConstraintsInstances) ]\n",
    "\n",
    "    class ReliefMean4(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        mtl.Covariance & mtl.qlocation.some(mtl.ReliefConstraintsCov)\n",
    "    ]\n",
    "\n",
    "    class ReliefMean5(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.NumberOfOutliers & mtl.qlocation.some(mtl.ReliefConstraintsNrOut) ]\n",
    "\n",
    "    class ReliefMean6(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.ClassEntropy & mtl.qlocation.some(mtl.ReliefConstraintscEntropy) ]\n",
    "\n",
    "    class ReliefMean7(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.OutlierDetection & mtl.qlocation.some(mtl.ReliefConstraintsOutlierPerc) ]\n",
    "\n",
    "    #GR constraints mean\n",
    "    class GRMean1(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        mtl.EqNumberOfAttributes & mtl.qlocation.some(mtl.GRConstraintsENA)\n",
    "    ]\n",
    "\n",
    "    class GRMean2(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            dmop1.NumberOfInstances & mtl.qlocation.some(mtl.GRConstraintsInstances2) ]\n",
    "\n",
    "    class GRMean3(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        mtl.Covariance & mtl.qlocation.some(mtl.GRConstraintsCov)\n",
    "    ]\n",
    "\n",
    "    class GRMean4(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.LabelNoise & mtl.qlocation.some(mtl.GRConstraintsLabelissue) ]\n",
    "\n",
    "    class GRMean5(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.ClassEntropy & mtl.qlocation.some(mtl.GRConstraintscEntropy) ]\n",
    "\n",
    "    #FCBF constraints mean\n",
    "    class FCBFMean1(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "        mtl.Correlation & mtl.qlocation.some(mtl.FCBFConstraintsCorr)   ]\n",
    "\n",
    "    class FCBFMean2(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "        mtl.Skewness & mtl.qlocation.some(mtl.FCBFConstraintsSkew)   ]\n",
    "\n",
    "    class FCBFMean3(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "        dmop1.ProportionOfInstancesPerFeature & mtl.qlocation.some(mtl.FCBFConstraintsInstAttr)   ]\n",
    "\n",
    "    class FCBFMean4(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "        mtl.MedianOfAttributes & mtl.qlocation.some(mtl.FCBFConstraintsMedian)   ]\n",
    "\n",
    "    class FCBFMean5(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "        mtl.ClassImbalance & mtl.qlocation.some(mtl.FCBFConstraintsClassImb)   ]\n",
    "\n",
    "    class FCBFMean6(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "        mtl.EqNumberOfAttributes & mtl.qlocation.some(mtl.FCBFConstraintsENA)   ]\n",
    "\n",
    "    \"\"\"class FCBFMean7(dmop1.DataCharacteristic): \n",
    "        equivalent_to = [\n",
    "            dmop1.NumberOfInstances & mtl.qlocation.some(mtl.FCBFConstraintsInstances) ]\n",
    "\n",
    "    class FCBFMean8(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        mtl.Covariance & mtl.qlocation.some(mtl.FCBFConstraintsCov)]\"\"\"\n",
    "\n",
    "    #Chisquare\n",
    "    class ChisquareMean2(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.OutlierDetection & mtl.qlocation.some(mtl.ChisquareConstraintsOutlierPerc) ]\n",
    "\n",
    "    class ChisquareMean3(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            dmop1.ProportionOfInstancesPerFeature & mtl.qlocation.some(mtl.ChisquareConstraintsInstAttr) ]\n",
    "\n",
    "    class ChisquareMean4(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.AttributesEntropy & mtl.qlocation.some(mtl.ChisquareConstraintsAttrEnt) ]\n",
    "\n",
    "    #MI dataset\n",
    "    class MIRelevantData(dmop.LabeledDataSet):\n",
    "        equivalent_to = [ dmop.LabeledDataSet &\n",
    "            mtl.hasQuality.some(mtl.MIMean1) & mtl.hasQuality.some(mtl.MIMean2) & mtl.hasQuality.some(mtl.MIMean3)  \n",
    "        ]\n",
    "\n",
    "    #Relief dataset\n",
    "    class ReliefRelevantData(dmop.LabeledDataSet):\n",
    "        equivalent_to = [ dmop.LabeledDataSet &\n",
    "            mtl.hasQuality.some(mtl.ReliefMean1) & mtl.hasQuality.some(mtl.ReliefMean2) &\n",
    "            mtl.hasQuality.some(mtl.ReliefMean3) & mtl.hasQuality.some(mtl.ReliefMean4)&\n",
    "            mtl.hasQuality.some(mtl.ReliefMean5) & mtl.hasQuality.some(mtl.ReliefMean6)&\n",
    "            mtl.hasQuality.some(mtl.ReliefMean7) \n",
    "        ]\n",
    "\n",
    "    #GR dataset\n",
    "    class GRRelevantData(dmop.LabeledDataSet):\n",
    "        equivalent_to = [ dmop.LabeledDataSet &\n",
    "            mtl.hasQuality.some(mtl.GRMean1) & mtl.hasQuality.some(mtl.GRMean2) &\n",
    "            mtl.hasQuality.some(mtl.GRMean3) & mtl.hasQuality.some(mtl.GRMean4)&\n",
    "            mtl.hasQuality.some(mtl.GRMean5)  \n",
    "            # &mtl.hasQuality.only(mtl.GRMean1|mtl.GRMean2 |mtl.GRMean3 |mtl.GRMean4|mtl.GRMean5)\n",
    "        ]\n",
    "\n",
    "    #FCBF relevant data\n",
    "    class FCBFRelevantData(dmop.LabeledDataSet):\n",
    "        equivalent_to = [ dmop.LabeledDataSet &\n",
    "            mtl.hasQuality.some(mtl.FCBFMean1) & mtl.hasQuality.some(mtl.FCBFMean2) &\n",
    "            mtl.hasQuality.some(mtl.FCBFMean3) & mtl.hasQuality.some(mtl.FCBFMean4) &\n",
    "            mtl.hasQuality.some(mtl.FCBFMean5) & mtl.hasQuality.some(mtl.FCBFMean6) &\n",
    "            mtl.hasQuality.some(mtl.ReliefMean3) & mtl.hasQuality.some(mtl.GRMean3) \n",
    "        ]\n",
    "\n",
    "    #Chisquare dataset\n",
    "    class ChisquareRelevantData(dmop.LabeledDataSet):\n",
    "        equivalent_to = [ dmop.LabeledDataSet &\n",
    "            mtl.hasQuality.some(mtl.ReliefMean3) & mtl.hasQuality.some(mtl.ChisquareMean2) &\n",
    "            mtl.hasQuality.some(mtl.ChisquareMean3) & mtl.hasQuality.some(mtl.ChisquareMean4)&\n",
    "            mtl.hasQuality.some(mtl.ReliefMean4)  \n",
    "        ]\n",
    "\n",
    "    #MI Task\n",
    "    class MITask(mtl.FeatureSelectionRecommendationTask):\n",
    "      #  pass\n",
    "        equivalent_to = [\n",
    "        mtl.FeatureSelectionRecommendationTask &\n",
    "        dmop.specifiesInputClass.exactly(1, mtl.MIRelevantData) &\n",
    "        dmop.specifiesOutputClass.exactly(1,mtl.MIRecommendation)]\n",
    "\n",
    "    #Relief Task\n",
    "    class ReliefTask(mtl.FeatureSelectionRecommendationTask):\n",
    "    #    pass\n",
    "        equivalent_to = [\n",
    "        mtl.FeatureSelectionRecommendationTask &\n",
    "        dmop.specifiesInputClass.exactly(1, mtl.ReliefRelevantData) &\n",
    "        dmop.specifiesOutputClass.exactly(1,mtl.ReliefRecommendation)\n",
    "    ]   \n",
    "\n",
    "    #GR Task\n",
    "    class GRTask(mtl.FeatureSelectionRecommendationTask):\n",
    "       # pass\n",
    "        equivalent_to = [\n",
    "        mtl.FeatureSelectionRecommendationTask &\n",
    "        dmop.specifiesInputClass.exactly(1, mtl.GRRelevantData) &\n",
    "        dmop.specifiesOutputClass.exactly(1,mtl.GRRecommendation)\n",
    "    ]\n",
    "    #FCBF Task\n",
    "    class FCBFTask(mtl.FeatureSelectionRecommendationTask):\n",
    "     #   pass\n",
    "        equivalent_to = [\n",
    "        mtl.FeatureSelectionRecommendationTask &\n",
    "        dmop.specifiesInputClass.exactly(1, mtl.FCBFRelevantData) &\n",
    "        dmop.specifiesOutputClass.exactly(1,mtl.FCBFRecommendation)\n",
    "\n",
    "    ]\n",
    "\n",
    "    #Chisquare Task\n",
    "    class ChisquareTask(mtl.FeatureSelectionRecommendationTask):\n",
    "    #    pass\n",
    "        equivalent_to = [\n",
    "        mtl.FeatureSelectionRecommendationTask &\n",
    "        dmop.specifiesInputClass.exactly(1, mtl.ChisquareRelevantData) &\n",
    "        dmop.specifiesOutputClass.exactly(1,mtl.ChisquareRecommendation)\n",
    "    ]\n",
    "\n",
    " #   AllDisjoint([mtl.MIRecommendation, mtl.ChisquareRecommendation, mtl.GRRecommendation, mtl.FCBFRecommendation, mtl.ReliefRecommendation])\n",
    "\n",
    "    #mtl.GRRelevantData.isSpecifiedInputOf.append(onto.GRTask)\n",
    "   # mtl.GRRecommendation.isSpecifiedOutputOf.append(mtl.GRTask)\n",
    "    mtl.GRRecommendation.recommends.append(mtl.GainRatio)\n",
    "  #  mtl.MITask.specifiesInputClass.append(mtl.MIRelevantData)\n",
    "\n",
    "    #mtl.MIRelevantData.isSpecifiedInputOf.append(onto.MITask)\n",
    "    #mtl.MIRecommendation.isSpecifiedOutputOf.append(mtl.MITask)\n",
    "    mtl.MIRecommendation.recommends.append(mtl.MutualInformation)\n",
    "\n",
    "    #mtl.ReliefRelevantData.isSpecifiedInputOf.append(onto.ReliefTask)    \n",
    "    #mtl.ReliefRecommendation.isSpecifiedOutputOf = mtl.ReliefTask\n",
    "    mtl.ReliefRecommendation.recommends.append(mtl.Relief)\n",
    "    \n",
    "    #mtl.ChisquareRelevantData.isSpecifiedInputOf.append(onto.ChisquareTask)    \n",
    "    #mtl.ChisquareRecommendation.isSpecifiedOutputOf = mtl.ChisquareTask\n",
    "    mtl.ChisquareRecommendation.recommends.append(mtl.ChiSquare)\n",
    "    \n",
    "   # mtl.FCBFRelevantData.isSpecifiedInputOf.append(onto.FCBFTask)    \n",
    "    #mtl.FCBFRecommendation.isSpecifiedOutputOf = mtl.FCBFRecommendation   \n",
    "    mtl.FCBFRecommendation.recommends.append(mtl.FCBF)\n",
    "#sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)\n",
    "onto.save(\"MtL_Enriched1.owl\",format = \"rdfxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)\n",
    "\n",
    "#FOR MI - Run this and last cell \n",
    "    #(nr_inst <= 167.000) and (nr_inst > 99.500) and (range.mean > 3.788) and (attr_conc.mean > 0.053)\n",
    "\n",
    "mtla = mtl.LearningFromTaskProperties(\"task1\")\n",
    "mtlt = onto.FeatureSelectionRecommendationTask(\"mtask1\")\n",
    "mtla.addresses.append(mtlt)\n",
    "\n",
    "fileObject = dmop.LabeledDataSet(\"dataset1\", namespace=onto) \n",
    "fsr_output = onto.FeatureSelectionRecommendation(\"output1\")\n",
    "\n",
    "mtlt.specifiesInputClass = [fileObject]\n",
    "mtlt.specifiesOutputClass = [fsr_output]\n",
    "\n",
    "nInstance = dmop1.NumberOfInstances(\"instance1\", namespace=onto)\n",
    "fileObject.hasQuality.append(nInstance)\n",
    "q3 = mtl.Mean(\"mean1\")\n",
    "nInstance.qlocation.append(q3) \n",
    "q3.hasDatavalue.append(100.0)\n",
    "\n",
    "rRange = mtl.Range(\"range1\", namespace=onto)\n",
    "fileObject.hasQuality.append(rRange)\n",
    "q2 = mtl.Mean(\"mean2\")\n",
    "rRange.qlocation = [q2]\n",
    "q2.hasDatavalue.append(10.0)\n",
    "\n",
    "attrConc = mtl.AttributeConcentration(\"attrconc\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrConc)\n",
    "q4 = mtl.Mean(\"mean3\")\n",
    "attrConc.qlocation = [q4]\n",
    "q4.hasDatavalue.append(0.23)\n",
    "\n",
    "covR = mtl.Covariance(\"cov\", namespace=onto)\n",
    "fileObject.hasQuality.append(covR)\n",
    "q5 = mtl.Mean(\"mean4\")\n",
    "covR.qlocation = [q5]\n",
    "q5.hasDatavalue.append(0.23)\n",
    "\n",
    "cEntr = mtl.ClassEntropy(\"clasEntropy\", namespace=onto)\n",
    "fileObject.hasQuality.append(cEntr)\n",
    "q6 = mtl.Mean(\"mean5\")\n",
    "cEntr.qlocation = [q6]\n",
    "q6.hasDatavalue.append(0.23)\n",
    "\n",
    "outDet = mtl.OutlierDetection(\"outDetection\", namespace=onto)\n",
    "fileObject.hasQuality.append(outDet)\n",
    "q7 = mtl.Mean(\"mean6\")\n",
    "outDet.qlocation = [q7]\n",
    "q7.hasDatavalue.append(0.23)\n",
    "\n",
    "nrOut = mtl.NumberOfOutliers(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(nrOut)\n",
    "q8 = mtl.Mean(\"mean7\")\n",
    "nrOut.qlocation = [q8]\n",
    "q8.hasDatavalue.append(0.012)\n",
    "\n",
    "instFeat = dmop1.ProportionOfInstancesPerFeature(\"instAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(instFeat)\n",
    "q12 = mtl.Mean(\"mean8\")\n",
    "instFeat.qlocation = [q12]\n",
    "q12.hasDatavalue.append(0.23)\n",
    "\n",
    "attrEntr = mtl.AttributesEntropy(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrEntr)\n",
    "q9 = mtl.Mean(\"mean9\")\n",
    "attrEntr.qlocation = [q9]\n",
    "q9.hasDatavalue.append(0.23)\n",
    "\n",
    "corr = mtl.Correlation(\"corr\", namespace=onto)\n",
    "fileObject.hasQuality.append(corr)\n",
    "q10 = mtl.Mean(\"mean10\")\n",
    "corr.qlocation = [q10]\n",
    "q10.hasDatavalue.append(0.23)\n",
    "\n",
    "medAttr = mtl.MedianOfAttributes(\"medAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(medAttr)\n",
    "q11 = mtl.Mean(\"mean11\")\n",
    "medAttr.qlocation = [q11]\n",
    "q11.hasDatavalue.append(0.23)\n",
    "\n",
    "classImb = mtl.ClassImbalance(\"classImb\", namespace=onto)\n",
    "fileObject.hasQuality.append(classImb)\n",
    "q13 = mtl.Mean(\"mean12\")\n",
    "classImb.qlocation = [q13]\n",
    "q13.hasDatavalue.append(0.23)\n",
    "\n",
    "ena = mtl.EqNumberOfAttributes(\"ena\", namespace=onto)\n",
    "fileObject.hasQuality.append(ena)\n",
    "q14 = mtl.Mean(\"mean13\")\n",
    "ena.qlocation = [q14]\n",
    "q14.hasDatavalue.append(0.23)\n",
    "\n",
    "labelNoise = mtl.LabelNoise(\"labelNoise\", namespace=onto)\n",
    "fileObject.hasQuality.append(labelNoise)\n",
    "q15 = mtl.Mean(\"mean14\")\n",
    "labelNoise.qlocation = [q15]\n",
    "q15.hasDatavalue.append(0.23)\n",
    "\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mtl.MIRelevantData in fileObject.is_a:\n",
    "    task2 = fileObject.isSpecifiedInputOf[0]\n",
    "    inputs = task2.specifiesOutputClass\n",
    "    print(task2.is_a, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd1\n",
    "import jenkspy\n",
    "import numpy as np\n",
    "from owlready2 import *\n",
    "import ast \n",
    "import rdflib\n",
    "import re\n",
    "\n",
    "owlready2.JAVA_EXE =\"/usr/lib/jvm/java-17-openjdk-amd64/bin/java\"\n",
    "\n",
    "onto = get_ontology(\"file:///home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS_git/onto/MtL_Enriched.owl\").load()\n",
    "\n",
    "dcat = get_namespace(\"http://www.w3.org/ns/dcat/\")\n",
    "dqv = get_namespace(\"http://www.w3.org/ns/dqv/\")\n",
    "mtl = get_ontology(\"https://purl.archive.org/domain/mtl#\")\n",
    "#onto.base_iri = \"https://purl.archive.org/domain/mtl#\"\n",
    "rdf=get_namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "dmop = get_ontology(\"http://www.e-lico.eu/ontologies/dmo/DMOP/DMOP.owl\")\n",
    "dmop.base_iri = \"http://www.e-lico.eu/ontologies/dmo/DMOP/DMOP.owl#\"\n",
    "dmop1 = get_ontology(\"http://www.e-LICO.eu/ontologies/dmo/DMOP/DMOP.owl\")\n",
    "dmop1.base_iri = \"http://www.e-LICO.eu/ontologies/dmo/DMOP/DMOP.owl#\"\n",
    "pd = get_ontology(\"http://www.e-lico.eu/ontologies/dmo/DMOP/PD.owl\")\n",
    "pd.base_iri = \"http://www.e-lico.eu/ontologies/dmo/DMOP/PD.owl#\"\n",
    "#sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To check each feature selection technique as recommendation, run corresponding feature selection technique cell followed by the last cell i.e output cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR MI - Run this and last cell \n",
    "    #(nr_inst <= 167.000) and (nr_inst > 99.500) and (range.mean > 3.788) and (attr_conc.mean > 0.053)\n",
    "\n",
    "mtla = mtl.LearningFromTaskProperties(\"task1\")\n",
    "mtlt = onto.FeatureSelectionRecommendationTask(\"mtask1\")\n",
    "mtla.addresses.append(mtlt)\n",
    "\n",
    "fileObject = dmop.LabeledDataSet(\"dataset1\", namespace=onto) \n",
    "fsr_output = onto.FeatureSelectionRecommendation(\"output1\")\n",
    "\n",
    "mtlt.specifiesInputClass = [fileObject]\n",
    "mtlt.specifiesOutputClass = [fsr_output]\n",
    "\n",
    "nInstance = dmop1.NumberOfInstances(\"instance1\", namespace=onto)\n",
    "fileObject.hasQuality.append(nInstance)\n",
    "q3 = mtl.Mean(\"mean1\")\n",
    "nInstance.qlocation.append(q3) \n",
    "q3.hasDatavalue.append(100.0)\n",
    "\n",
    "rRange = mtl.Range(\"range1\", namespace=onto)\n",
    "fileObject.hasQuality.append(rRange)\n",
    "q2 = mtl.Mean(\"mean2\")\n",
    "rRange.qlocation = [q2]\n",
    "q2.hasDatavalue.append(10.0)\n",
    "\n",
    "attrConc = mtl.AttributeConcentration(\"attrconc\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrConc)\n",
    "q4 = mtl.Mean(\"mean3\")\n",
    "attrConc.qlocation = [q4]\n",
    "q4.hasDatavalue.append(0.23)\n",
    "\n",
    "covR = mtl.Covariance(\"cov\", namespace=onto)\n",
    "fileObject.hasQuality.append(covR)\n",
    "q5 = mtl.Mean(\"mean4\")\n",
    "covR.qlocation = [q5]\n",
    "q5.hasDatavalue.append(0.23)\n",
    "\n",
    "cEntr = mtl.ClassEntropy(\"clasEntropy\", namespace=onto)\n",
    "fileObject.hasQuality.append(cEntr)\n",
    "q6 = mtl.Mean(\"mean5\")\n",
    "cEntr.qlocation = [q6]\n",
    "q6.hasDatavalue.append(0.23)\n",
    "\n",
    "outDet = mtl.OutlierDetection(\"outDetection\", namespace=onto)\n",
    "fileObject.hasQuality.append(outDet)\n",
    "q7 = mtl.Mean(\"mean6\")\n",
    "outDet.qlocation = [q7]\n",
    "q7.hasDatavalue.append(0.23)\n",
    "\n",
    "nrOut = mtl.NumberOfOutliers(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(nrOut)\n",
    "q8 = mtl.Mean(\"mean7\")\n",
    "nrOut.qlocation = [q8]\n",
    "q8.hasDatavalue.append(0.012)\n",
    "\n",
    "instFeat = dmop1.ProportionOfInstancesPerFeature(\"instAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(instFeat)\n",
    "q12 = mtl.Mean(\"mean8\")\n",
    "instFeat.qlocation = [q12]\n",
    "q12.hasDatavalue.append(0.23)\n",
    "\n",
    "attrEntr = mtl.AttributesEntropy(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrEntr)\n",
    "q9 = mtl.Mean(\"mean9\")\n",
    "attrEntr.qlocation = [q9]\n",
    "q9.hasDatavalue.append(0.23)\n",
    "\n",
    "corr = mtl.Correlation(\"corr\", namespace=onto)\n",
    "fileObject.hasQuality.append(corr)\n",
    "q10 = mtl.Mean(\"mean10\")\n",
    "corr.qlocation = [q10]\n",
    "q10.hasDatavalue.append(0.23)\n",
    "\n",
    "medAttr = mtl.MedianOfAttributes(\"medAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(medAttr)\n",
    "q11 = mtl.Mean(\"mean11\")\n",
    "medAttr.qlocation = [q11]\n",
    "q11.hasDatavalue.append(0.23)\n",
    "\n",
    "classImb = mtl.ClassImbalance(\"classImb\", namespace=onto)\n",
    "fileObject.hasQuality.append(classImb)\n",
    "q13 = mtl.Mean(\"mean12\")\n",
    "classImb.qlocation = [q13]\n",
    "q13.hasDatavalue.append(0.23)\n",
    "\n",
    "ena = mtl.EqNumberOfAttributes(\"ena\", namespace=onto)\n",
    "fileObject.hasQuality.append(ena)\n",
    "q14 = mtl.Mean(\"mean13\")\n",
    "ena.qlocation = [q14]\n",
    "q14.hasDatavalue.append(0.23)\n",
    "\n",
    "labelNoise = mtl.LabelNoise(\"labelNoise\", namespace=onto)\n",
    "fileObject.hasQuality.append(labelNoise)\n",
    "q15 = mtl.Mean(\"mean14\")\n",
    "labelNoise.qlocation = [q15]\n",
    "q15.hasDatavalue.append(0.23)\n",
    "\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2 = fsr_output.isSpecifiedOutputOf[0]\n",
    "inputs = task2.specifiesInputClass\n",
    "print(task2.is_a, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(nr_inst > 167.000) and (cov.mean <= 1.289) and (OutlierPerc > 0.012) and (cEntropy > 0.440) and \n",
    "# (nr_outliers <= 12.500) and (ena <= 2.249) and (range.mean > 0.740) and (ena > -38.058) \n",
    "#Relief\n",
    "\n",
    "mtla = mtl.LearningFromTaskProperties(\"task1\")\n",
    "mtlt = onto.FeatureSelectionRecommendationTask(\"mtask1\")\n",
    "mtla.addresses.append(mtlt)\n",
    "\n",
    "fileObject = dmop.LabeledDataSet(\"dataset1\", namespace=onto) \n",
    "fsr_output = onto.FeatureSelectionRecommendation(\"output1\")\n",
    "\n",
    "mtlt.specifiesInputClass = [fileObject]\n",
    "mtlt.specifiesOutputClass = [fsr_output]\n",
    "\n",
    "nInstance = dmop1.NumberOfInstances(\"instance1\", namespace=onto)\n",
    "fileObject.hasQuality.append(nInstance)\n",
    "q3 = mtl.Mean(\"mean1\")\n",
    "nInstance.qlocation =[q3]\n",
    "q3.hasDatavalue.append(190.0)\n",
    "\n",
    "rRange = mtl.Range(\"range1\", namespace=onto)\n",
    "fileObject.hasQuality.append(rRange)\n",
    "q2 = mtl.Mean(\"mean2\")\n",
    "rRange.qlocation = [q2]\n",
    "q2.hasDatavalue.append(2.1)\n",
    "\n",
    "attrConc = mtl.AttributeConcentration(\"attrconc\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrConc)\n",
    "q4 = mtl.Mean(\"mean3\")\n",
    "attrConc.qlocation = [q4]\n",
    "q4.hasDatavalue.append(0.23)\n",
    "\n",
    "covR = mtl.Covariance(\"cov\", namespace=onto)\n",
    "fileObject.hasQuality.append(covR)\n",
    "q5 = mtl.Mean(\"mean4\")\n",
    "covR.qlocation = [q5]\n",
    "q5.hasDatavalue.append(0.23)\n",
    "\n",
    "cEntr = mtl.ClassEntropy(\"clasEntropy\", namespace=onto)\n",
    "fileObject.hasQuality.append(cEntr)\n",
    "q6 = mtl.Mean(\"mean5\")\n",
    "cEntr.qlocation = [q6]\n",
    "q6.hasDatavalue.append(0.53)\n",
    "\n",
    "outDet = mtl.OutlierDetection(\"outDetection\", namespace=onto)\n",
    "fileObject.hasQuality.append(outDet)\n",
    "q7 = mtl.Mean(\"mean6\")\n",
    "outDet.qlocation = [q7]\n",
    "q7.hasDatavalue.append(0.13)\n",
    "\n",
    "nrOut = mtl.NumberOfOutliers(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(nrOut)\n",
    "q8 = mtl.Mean(\"mean7\")\n",
    "nrOut.qlocation = [q8]\n",
    "q8.hasDatavalue.append(8.2)\n",
    "\n",
    "instFeat = dmop1.ProportionOfInstancesPerFeature(\"instAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(instFeat)\n",
    "q12 = mtl.Mean(\"mean8\")\n",
    "instFeat.qlocation = [q12]\n",
    "q12.hasDatavalue.append(0.23)\n",
    "\n",
    "attrEntr = mtl.AttributesEntropy(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrEntr)\n",
    "q9 = mtl.Mean(\"mean9\")\n",
    "attrEntr.qlocation = [q9]\n",
    "q9.hasDatavalue.append(0.23)\n",
    "\n",
    "corr = mtl.Correlation(\"corr\", namespace=onto)\n",
    "fileObject.hasQuality.append(corr)\n",
    "q10 = mtl.Mean(\"mean10\")\n",
    "corr.qlocation = [q10]\n",
    "q10.hasDatavalue.append(0.23)\n",
    "\n",
    "medAttr = mtl.MedianOfAttributes(\"medAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(medAttr)\n",
    "q11 = mtl.Mean(\"mean11\")\n",
    "medAttr.qlocation = [q11]\n",
    "q11.hasDatavalue.append(0.23)\n",
    "\n",
    "classImb = mtl.ClassImbalance(\"classImb\", namespace=onto)\n",
    "fileObject.hasQuality.append(classImb)\n",
    "q13 = mtl.Mean(\"mean12\")\n",
    "classImb.qlocation = [q13]\n",
    "q13.hasDatavalue.append(0.23)\n",
    "\n",
    "ena = mtl.EqNumberOfAttributes(\"ena\", namespace=onto)\n",
    "fileObject.hasQuality.append(ena)\n",
    "q14 = mtl.Mean(\"mean13\")\n",
    "ena.qlocation = [q14]\n",
    "q14.hasDatavalue.append(0.12)\n",
    "\n",
    "labelNoise = mtl.LabelNoise(\"labelNoise\", namespace=onto)\n",
    "fileObject.hasQuality.append(labelNoise)\n",
    "q15 = mtl.Mean(\"mean14\")\n",
    "labelNoise.qlocation = [q15]\n",
    "q15.hasDatavalue.append(0.23)\n",
    "\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (cov.mean <= 1.289) and (OutlierPerc <= 0.012) and \n",
    "#(inst_to_attr <= 1614.176) and (attr_ent.mean <= 3.683) and (nr_inst > 413.000)\n",
    "#Chisquare\n",
    "mtla = mtl.LearningFromTaskProperties(\"task1\")\n",
    "mtlt = onto.FeatureSelectionRecommendationTask(\"mtask1\")\n",
    "mtla.addresses.append(mtlt)\n",
    "\n",
    "fileObject = dmop.LabeledDataSet(\"dataset1\", namespace=onto) \n",
    "fsr_output = onto.FeatureSelectionRecommendation(\"output1\")\n",
    "\n",
    "mtlt.specifiesInputClass = [fileObject]\n",
    "mtlt.specifiesOutputClass = [fsr_output]\n",
    "\n",
    "nInstance = dmop1.NumberOfInstances(\"instance1\", namespace=onto)\n",
    "fileObject.hasQuality.append(nInstance)\n",
    "q3 = mtl.Mean(\"mean1\")\n",
    "nInstance.qlocation =[q3]\n",
    "q3.hasDatavalue.append(490.0)\n",
    "\n",
    "rRange = mtl.Range(\"range1\", namespace=onto)\n",
    "fileObject.hasQuality.append(rRange)\n",
    "q2 = mtl.Mean(\"mean2\")\n",
    "rRange.qlocation = [q2]\n",
    "q2.hasDatavalue.append(2.1)\n",
    "\n",
    "attrConc = mtl.AttributeConcentration(\"attrconc\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrConc)\n",
    "q4 = mtl.Mean(\"mean3\")\n",
    "attrConc.qlocation = [q4]\n",
    "q4.hasDatavalue.append(0.23)\n",
    "\n",
    "covR = mtl.Covariance(\"cov\", namespace=onto)\n",
    "fileObject.hasQuality.append(covR)\n",
    "q5 = mtl.Mean(\"mean4\")\n",
    "covR.qlocation = [q5]\n",
    "q5.hasDatavalue.append(0.23)\n",
    "\n",
    "cEntr = mtl.ClassEntropy(\"clasEntropy\", namespace=onto)\n",
    "fileObject.hasQuality.append(cEntr)\n",
    "q6 = mtl.Mean(\"mean5\")\n",
    "cEntr.qlocation = [q6]\n",
    "q6.hasDatavalue.append(0.53)\n",
    "\n",
    "outDet = mtl.OutlierDetection(\"outDetection\", namespace=onto)\n",
    "fileObject.hasQuality.append(outDet)\n",
    "q7 = mtl.Mean(\"mean6\")\n",
    "outDet.qlocation = [q7]\n",
    "q7.hasDatavalue.append(0.0)\n",
    "\n",
    "nrOut = mtl.NumberOfOutliers(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(nrOut)\n",
    "q8 = mtl.Mean(\"mean7\")\n",
    "nrOut.qlocation = [q8]\n",
    "q8.hasDatavalue.append(8.2)\n",
    "\n",
    "instFeat = dmop1.ProportionOfInstancesPerFeature(\"instAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(instFeat)\n",
    "q12 = mtl.Mean(\"mean8\")\n",
    "instFeat.qlocation = [q12]\n",
    "q12.hasDatavalue.append(123.43)\n",
    "\n",
    "attrEntr = mtl.AttributesEntropy(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrEntr)\n",
    "q9 = mtl.Mean(\"mean9\")\n",
    "attrEntr.qlocation = [q9]\n",
    "q9.hasDatavalue.append(3.17)\n",
    "\n",
    "corr = mtl.Correlation(\"corr\", namespace=onto)\n",
    "fileObject.hasQuality.append(corr)\n",
    "q10 = mtl.Mean(\"mean10\")\n",
    "corr.qlocation = [q10]\n",
    "q10.hasDatavalue.append(0.23)\n",
    "\n",
    "medAttr = mtl.MedianOfAttributes(\"medAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(medAttr)\n",
    "q11 = mtl.Mean(\"mean11\")\n",
    "medAttr.qlocation = [q11]\n",
    "q11.hasDatavalue.append(0.23)\n",
    "\n",
    "classImb = mtl.ClassImbalance(\"classImb\", namespace=onto)\n",
    "fileObject.hasQuality.append(classImb)\n",
    "q13 = mtl.Mean(\"mean12\")\n",
    "classImb.qlocation = [q13]\n",
    "q13.hasDatavalue.append(0.23)\n",
    "\n",
    "ena = mtl.EqNumberOfAttributes(\"ena\", namespace=onto)\n",
    "fileObject.hasQuality.append(ena)\n",
    "q14 = mtl.Mean(\"mean13\")\n",
    "ena.qlocation = [q14]\n",
    "q14.hasDatavalue.append(0.12)\n",
    "\n",
    "labelNoise = mtl.LabelNoise(\"labelNoise\", namespace=onto)\n",
    "fileObject.hasQuality.append(labelNoise)\n",
    "q15 = mtl.Mean(\"mean14\")\n",
    "labelNoise.qlocation = [q15]\n",
    "q15.hasDatavalue.append(0.23)\n",
    "\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(nr_inst > 167.000) and (nr_inst <= 372.000) and (cov.mean > 1.289)  and (ena <= 13.853) and \n",
    "# (LabelIssuesPerc <= 0.068) and (cEntropy <= 0.990)\n",
    "#GR\n",
    "\n",
    "mtla = mtl.LearningFromTaskProperties(\"task1\")\n",
    "mtlt = onto.FeatureSelectionRecommendationTask(\"mtask1\")\n",
    "mtla.addresses.append(mtlt)\n",
    "\n",
    "fileObject = dmop.LabeledDataSet(\"dataset1\", namespace=onto) \n",
    "fsr_output = onto.FeatureSelectionRecommendation(\"output1\")\n",
    "\n",
    "mtlt.specifiesInputClass = [fileObject]\n",
    "mtlt.specifiesOutputClass = [fsr_output]\n",
    "\n",
    "nInstance = dmop1.NumberOfInstances(\"instance1\", namespace=onto)\n",
    "fileObject.hasQuality.append(nInstance)\n",
    "q3 = mtl.Mean(\"mean1\")\n",
    "nInstance.qlocation =[q3]\n",
    "q3.hasDatavalue.append(320.0)\n",
    "\n",
    "rRange = mtl.Range(\"range1\", namespace=onto)\n",
    "fileObject.hasQuality.append(rRange)\n",
    "q2 = mtl.Mean(\"mean2\")\n",
    "rRange.qlocation = [q2]\n",
    "q2.hasDatavalue.append(2.1)\n",
    "\n",
    "attrConc = mtl.AttributeConcentration(\"attrconc\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrConc)\n",
    "q4 = mtl.Mean(\"mean3\")\n",
    "attrConc.qlocation = [q4]\n",
    "q4.hasDatavalue.append(0.23)\n",
    "\n",
    "covR = mtl.Covariance(\"cov\", namespace=onto)\n",
    "fileObject.hasQuality.append(covR)\n",
    "q5 = mtl.Mean(\"mean4\")\n",
    "covR.qlocation = [q5]\n",
    "q5.hasDatavalue.append(1.3)\n",
    "\n",
    "cEntr = mtl.ClassEntropy(\"clasEntropy\", namespace=onto)\n",
    "fileObject.hasQuality.append(cEntr)\n",
    "q6 = mtl.Mean(\"mean5\")\n",
    "cEntr.qlocation = [q6]\n",
    "q6.hasDatavalue.append(0.53)\n",
    "\n",
    "outDet = mtl.OutlierDetection(\"outDetection\", namespace=onto)\n",
    "fileObject.hasQuality.append(outDet)\n",
    "q7 = mtl.Mean(\"mean6\")\n",
    "outDet.qlocation = [q7]\n",
    "q7.hasDatavalue.append(0.0)\n",
    "\n",
    "nrOut = mtl.NumberOfOutliers(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(nrOut)\n",
    "q8 = mtl.Mean(\"mean7\")\n",
    "nrOut.qlocation = [q8]\n",
    "q8.hasDatavalue.append(8.2)\n",
    "\n",
    "instFeat = dmop1.ProportionOfInstancesPerFeature(\"instAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(instFeat)\n",
    "q12 = mtl.Mean(\"mean8\")\n",
    "instFeat.qlocation = [q12]\n",
    "q12.hasDatavalue.append(123.43)\n",
    "\n",
    "attrEntr = mtl.AttributesEntropy(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrEntr)\n",
    "q9 = mtl.Mean(\"mean9\")\n",
    "attrEntr.qlocation = [q9]\n",
    "q9.hasDatavalue.append(3.6)\n",
    "\n",
    "corr = mtl.Correlation(\"corr\", namespace=onto)\n",
    "fileObject.hasQuality.append(corr)\n",
    "q10 = mtl.Mean(\"mean10\")\n",
    "corr.qlocation = [q10]\n",
    "q10.hasDatavalue.append(0.23)\n",
    "\n",
    "medAttr = mtl.MedianOfAttributes(\"medAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(medAttr)\n",
    "q11 = mtl.Mean(\"mean11\")\n",
    "medAttr.qlocation = [q11]\n",
    "q11.hasDatavalue.append(0.23)\n",
    "\n",
    "classImb = mtl.ClassImbalance(\"classImb\", namespace=onto)\n",
    "fileObject.hasQuality.append(classImb)\n",
    "q13 = mtl.Mean(\"mean12\")\n",
    "classImb.qlocation = [q13]\n",
    "q13.hasDatavalue.append(0.23)\n",
    "\n",
    "ena = mtl.EqNumberOfAttributes(\"ena\", namespace=onto)\n",
    "fileObject.hasQuality.append(ena)\n",
    "q14 = mtl.Mean(\"mean13\")\n",
    "ena.qlocation = [q14]\n",
    "q14.hasDatavalue.append(13.853)\n",
    "\n",
    "labelNoise = mtl.LabelNoise(\"labelNoise\", namespace=onto)\n",
    "fileObject.hasQuality.append(labelNoise)\n",
    "q15 = mtl.Mean(\"mean14\")\n",
    "labelNoise.qlocation = [q15]\n",
    "q15.hasDatavalue.append(0.068)\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FCBF\n",
    "# (cov.mean > 1.289) and (nr_inst > 372.000) and (cor.mean > 0.119) and (skewness.mean <= 4.130) \n",
    "#(inst_to_attr <= 267.375) and (median.mean <= 26234.938) and (ClassImbRatio <= 0.733) and (ena > -0.405)\n",
    "\n",
    "mtla = mtl.LearningFromTaskProperties(\"task1\")\n",
    "mtlt = onto.FeatureSelectionRecommendationTask(\"mtask1\")\n",
    "mtla.addresses.append(mtlt)\n",
    "\n",
    "fileObject = dmop.LabeledDataSet(\"dataset1\", namespace=onto) \n",
    "fsr_output = onto.FeatureSelectionRecommendation(\"output1\")\n",
    "\n",
    "mtlt.specifiesInputClass = [fileObject]\n",
    "mtlt.specifiesOutputClass = [fsr_output]\n",
    "\n",
    "nInstance = dmop1.NumberOfInstances(\"instance1\", namespace=onto)\n",
    "fileObject.hasQuality.append(nInstance)\n",
    "q3 = mtl.Mean(\"mean1\")\n",
    "nInstance.qlocation =[q3]\n",
    "q3.hasDatavalue.append(390.0)\n",
    "\n",
    "rRange = mtl.Range(\"range1\", namespace=onto)\n",
    "fileObject.hasQuality.append(rRange)\n",
    "q2 = mtl.Mean(\"mean2\")\n",
    "rRange.qlocation = [q2]\n",
    "q2.hasDatavalue.append(2.1)\n",
    "\n",
    "attrConc = mtl.AttributeConcentration(\"attrconc\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrConc)\n",
    "q4 = mtl.Mean(\"mean3\")\n",
    "attrConc.qlocation = [q4]\n",
    "q4.hasDatavalue.append(0.23)\n",
    "\n",
    "covR = mtl.Covariance(\"cov\", namespace=onto)\n",
    "fileObject.hasQuality.append(covR)\n",
    "q5 = mtl.Mean(\"mean4\")\n",
    "covR.qlocation = [q5]\n",
    "q5.hasDatavalue.append(1.23)\n",
    "\n",
    "cEntr = mtl.ClassEntropy(\"clasEntropy\", namespace=onto)\n",
    "fileObject.hasQuality.append(cEntr)\n",
    "q6 = mtl.Mean(\"mean5\")\n",
    "cEntr.qlocation = [q6]\n",
    "q6.hasDatavalue.append(0.53)\n",
    "\n",
    "outDet = mtl.OutlierDetection(\"outDetection\", namespace=onto)\n",
    "fileObject.hasQuality.append(outDet)\n",
    "q7 = mtl.Mean(\"mean6\")\n",
    "outDet.qlocation = [q7]\n",
    "q7.hasDatavalue.append(0.0)\n",
    "\n",
    "nrOut = mtl.NumberOfOutliers(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(nrOut)\n",
    "q8 = mtl.Mean(\"mean7\")\n",
    "nrOut.qlocation = [q8]\n",
    "q8.hasDatavalue.append(8.2)\n",
    "\n",
    "instFeat = dmop1.ProportionOfInstancesPerFeature(\"instAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(instFeat)\n",
    "q12 = mtl.Mean(\"mean8\")\n",
    "instFeat.qlocation = [q12]\n",
    "q12.hasDatavalue.append(123.43)\n",
    "\n",
    "attrEntr = mtl.AttributesEntropy(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrEntr)\n",
    "q9 = mtl.Mean(\"mean9\")\n",
    "attrEntr.qlocation = [q9]\n",
    "q9.hasDatavalue.append(3.6)\n",
    "\n",
    "corr = mtl.Correlation(\"corr\", namespace=onto)\n",
    "fileObject.hasQuality.append(corr)\n",
    "q10 = mtl.Mean(\"mean10\")\n",
    "corr.qlocation = [q10]\n",
    "q10.hasDatavalue.append(0.12)\n",
    "\n",
    "medAttr = mtl.MedianOfAttributes(\"medAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(medAttr)\n",
    "q11 = mtl.Mean(\"mean11\")\n",
    "medAttr.qlocation = [q11]\n",
    "q11.hasDatavalue.append(123.3)\n",
    "\n",
    "classImb = mtl.ClassImbalance(\"classImb\", namespace=onto)\n",
    "fileObject.hasQuality.append(classImb)\n",
    "q13 = mtl.Mean(\"mean12\")\n",
    "classImb.qlocation = [q13]\n",
    "q13.hasDatavalue.append(0.23)\n",
    "\n",
    "ena = mtl.EqNumberOfAttributes(\"ena\", namespace=onto)\n",
    "fileObject.hasQuality.append(ena)\n",
    "q14 = mtl.Mean(\"mean13\")\n",
    "ena.qlocation = [q14]\n",
    "q14.hasDatavalue.append(13.853)\n",
    "\n",
    "labelNoise = mtl.LabelNoise(\"labelNoise\", namespace=onto)\n",
    "fileObject.hasQuality.append(labelNoise)\n",
    "q15 = mtl.Mean(\"mean14\")\n",
    "labelNoise.qlocation = [q15]\n",
    "q15.hasDatavalue.append(0.068)\n",
    "\n",
    "skew = mtl.Skewness(\"skew\", namespace=onto)\n",
    "fileObject.hasQuality.append(skew)\n",
    "q16 = mtl.Mean(\"mean15\")\n",
    "skew.qlocation = [q16]\n",
    "q16.hasDatavalue.append(0.068)\n",
    "\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check classification again just to be safe\n",
    "\n",
    "\n",
    "if onto.MIRelevantData in fileObject.is_a:\n",
    "    print(f\"{fileObject.name} satisfies MIRelevantData constraint\")\n",
    "    output = onto.MITask.specifiesOutputClass\n",
    "    print(\"Recommended feature selection technique is\", output[0].recommends)\n",
    "if onto.FCBFRelevantData in fileObject.is_a:\n",
    "    print(f\"{fileObject.name} satisfies FCBFRelevantData constraint\")\n",
    "    output = onto.FCBFTask.specifiesOutputClass\n",
    "    print(\"Recommended feature selection technique is\", output[0].recommends)\n",
    "if onto.ChisquareRelevantData in fileObject.is_a:\n",
    "    print(f\"{fileObject.name} satisfies ChisquareRelevantData constraint\")\n",
    "    output = onto.ChisquareTask.specifiesOutputClass\n",
    "    print(\"Recommended feature selection technique is\", output[0].recommends)\n",
    "if onto.GRRelevantData in fileObject.is_a:\n",
    "    print(f\"{fileObject.name} satisfies GRRelevantData constraint\")\n",
    "    output = onto.GRTask.specifiesOutputClass\n",
    "    print(\"Recommended feature selection technique is\", output[0].recommends)\n",
    "if onto.ReliefRelevantData in fileObject.is_a:\n",
    "    print(f\"{fileObject.name} satisfies ReliefRelevantData constraint\")\n",
    "    output = onto.ReliefTask.specifiesOutputClass\n",
    "    print(\"Recommended feature selection technique is\", output[0].recommends)\n",
    "else:\n",
    "    print(f\"{fileObject.name} does NOT satisfy any constraints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".deeplearningClass",
   "language": "python",
   "name": ".deeplearningclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
