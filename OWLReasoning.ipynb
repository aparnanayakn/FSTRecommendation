{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd1\n",
    "import jenkspy\n",
    "import numpy as np\n",
    "from owlready2 import *\n",
    "import ast \n",
    "import rdflib\n",
    "import re\n",
    "\n",
    "import postProcessing\n",
    "\n",
    "owlready2.JAVA_EXE =\"/usr/lib/jvm/java-17-openjdk-amd64/bin/java\"\n",
    "\n",
    "#onto = get_ontology(\"file:///home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS_git/MtLv2_gitversion.owl\").load()\n",
    "onto = get_ontology(\"file:///home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS_git/MtL_Enriched.owl\").load()\n",
    "\n",
    "dcat = get_namespace(\"http://www.w3.org/ns/dcat/\")\n",
    "dqv = get_namespace(\"http://www.w3.org/ns/dqv/\")\n",
    "mtl = get_ontology(\"https://purl.archive.org/domain/mtl#\")\n",
    "#onto.base_iri = \"https://purl.archive.org/domain/mtl#\"\n",
    "rdf=get_namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "dmop = get_ontology(\"http://www.e-lico.eu/ontologies/dmo/DMOP/DMOP.owl\")\n",
    "dmop.base_iri = \"http://www.e-lico.eu/ontologies/dmo/DMOP/DMOP.owl#\"\n",
    "dmop1 = get_ontology(\"http://www.e-LICO.eu/ontologies/dmo/DMOP/DMOP.owl\")\n",
    "dmop1.base_iri = \"http://www.e-LICO.eu/ontologies/dmo/DMOP/DMOP.owl#\"\n",
    "pd = get_ontology(\"http://www.e-lico.eu/ontologies/dmo/DMOP/PD.owl\")\n",
    "pd.base_iri = \"http://www.e-lico.eu/ontologies/dmo/DMOP/PD.owl#\"\n",
    "#sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No need to run this if MtL_enriched is imported\n",
    "#Run this is MtL is imported\n",
    "\n",
    "with onto:\n",
    "    #MI\n",
    "    #(nr_inst <= 167.000) and (nr_inst > 99.500) and (range.mean > 3.788) and (attr_conc.mean > 0.053)\n",
    "    float_gt_995_lt_167 = ConstrainedDatatype(float, min_exclusive = 99.5, max_inclusive = 167.0)\n",
    "    float_gt_378 = ConstrainedDatatype(float, min_exclusive = 3.788)            # variable changed\n",
    "    float_gt_053 = ConstrainedDatatype(float, min_exclusive = 0.053)            # variable changed\n",
    "    #Relief\n",
    "    #(nr_inst > 167.000) and (cov.mean <= 1.289) and (OutlierPerc > 0.012) and (cEntropy > 0.440) and (nr_outliers <= 12.500)\n",
    "    # and (ena <= 2.249) and (range.mean > 0.740) and (ena > -38.058) and (ena <= -0.690)\n",
    "    float_gt_38_lt_224 = ConstrainedDatatype(float, min_exclusive = -38.078, max_inclusive = 2.249)\n",
    "    float_gt_167 = ConstrainedDatatype(float, min_exclusive = 167.0)\n",
    "    float_lt_128 = ConstrainedDatatype(float, max_inclusive = 1.289)\n",
    "    float_gt_012 = ConstrainedDatatype(float, min_exclusive = 0.012)\n",
    "    float_gt_044 = ConstrainedDatatype(float, min_exclusive = 0.044)            # variable changed\n",
    "    float_lt_125 = ConstrainedDatatype(float, max_inclusive = 12.5)\n",
    "    float_gt_074 = ConstrainedDatatype(float, min_exclusive = 0.74)            # variable changed\n",
    "    #GR\n",
    "    #(nr_inst > 167.000) and (cov.mean > 1.289) and (nr_inst <= 372.000) and (ena <= 13.853) and (LabelIssuesPerc <= 0.068) and (cEntropy <= 0.990)\n",
    "    float_gt_167_lt_372 = ConstrainedDatatype(float, min_exclusive = 167, max_inclusive = 372)\n",
    "    float_lt_068 = ConstrainedDatatype(float, max_inclusive = 0.068)\n",
    "    float_gt_128 = ConstrainedDatatype(float, min_exclusive = 1.289)         \n",
    "    float_lt_138 = ConstrainedDatatype(float, max_inclusive = 13.853)\n",
    "    float_lt_099 = ConstrainedDatatype(float, max_inclusive = 0.99)\n",
    "    #FCBF\n",
    "    #(nr_inst > 167.000) and (cov.mean > 1.289) and (nr_inst > 372.000) and (cor.mean > 0.119) and (skewness.mean <= 4.130) and (inst_to_attr <= 267.375)\n",
    "    # and (median.mean <= 26234.938) and (ClassImbRatio <= 0.733) and (ena > -0.405)\n",
    "    float_gt_167_2 = ConstrainedDatatype(float, min_exclusive = 167.0)\n",
    "    float_gt_128_2 = ConstrainedDatatype(float, min_exclusive = 1.289)\n",
    "    float_gt_119 = ConstrainedDatatype(float, min_exclusive = 0.119)\n",
    "    float_lt_413 = ConstrainedDatatype(float, max_inclusive = 4.13)\n",
    "    float_lt_267 = ConstrainedDatatype(float, max_inclusive = 267.375)         \n",
    "    float_lt_26234 = ConstrainedDatatype(float, max_inclusive = 26234.938)\n",
    "    float_lt_073 = ConstrainedDatatype(float, max_inclusive = 0.733)\n",
    "    float_gt_040 = ConstrainedDatatype(float, min_exclusive = -0.405)       \n",
    "    #Chisquare\n",
    "    #(nr_inst > 167.000) and (cov.mean <= 1.289) and (OutlierPerc <= 0.012) and (inst_to_attr <= 1614.176) and (nr_inst > 343.000)\n",
    "    # and (attr_ent.mean <= 3.683) and (nr_inst > 413.000)\n",
    "    float_gt_167_3 = ConstrainedDatatype(float, min_exclusive = 167.0)\n",
    "    float_lt_128_2 = ConstrainedDatatype(float, max_inclusive = 1.289)\n",
    "    float_lt_012 = ConstrainedDatatype(float, max_inclusive = 0.012)\n",
    "    float_lt_1614 = ConstrainedDatatype(float, max_inclusive = 1614.176)\n",
    "    float_lt_3683 = ConstrainedDatatype(float, max_inclusive = 3.683)\n",
    "\n",
    "\n",
    "    #MI value constraints\n",
    "    class MIConstraintsInstances(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_995_lt_167)]\n",
    "\n",
    "    class MIConstraintsRange(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_378)]             \n",
    "\n",
    "    class MIConstraintsAttr(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_053)]             \n",
    "\n",
    "    #Relief value constraints\n",
    "    class ReliefConstraintsENA(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_38_lt_224)]\n",
    "\n",
    "    class ReliefConstraintsRange(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_074)]             \n",
    "\n",
    "    class ReliefConstraintsInstances(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_167)]\n",
    "\n",
    "    class ReliefConstraintsCov(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_128)]\n",
    "\n",
    "    class ReliefConstraintsOutlierPerc(mtl.Mean):           \n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_012)]\n",
    "\n",
    "    class ReliefConstraintscEntropy(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_044)]           \n",
    "\n",
    "    class ReliefConstraintsNrOut(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_125)]\n",
    "\n",
    "    #GR value constraints\n",
    "    class GRConstraintsInstances(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_167_lt_372)]\n",
    "\n",
    "    class GRConstraintsCov(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_128)]\n",
    "\n",
    "    class GRConstraintsENA(mtl.Mean):            \n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_138)]\n",
    "\n",
    "    class GRConstraintsLabelissue(mtl.Mean):\n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_068)]\n",
    "\n",
    "    class GRConstraintscEntropy(mtl.Mean):         \n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_099)]\n",
    "\n",
    "    #FCBF value constraints\n",
    "    class FCBFConstraintsCov(mtl.Mean):            \n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_128_2)]\n",
    "\n",
    "    class FCBFConstraintsInstances(mtl.Mean):         \n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_167_2)]\n",
    "\n",
    "    class FCBFConstraintsCorr(mtl.Mean):            \n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_119)]\n",
    "\n",
    "    class FCBFConstraintsSkew(mtl.Mean):            \n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_413)]\n",
    "\n",
    "    class FCBFConstraintsInstAttr(mtl.Mean):            \n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_267)]\n",
    "\n",
    "    class FCBFConstraintsMedian(mtl.Mean):            \n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_26234)]\n",
    "\n",
    "    class FCBFConstraintsClassImb(mtl.Mean):             \n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_073)]\n",
    "\n",
    "    class FCBFConstraintsENA(mtl.Mean):              \n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_040)]\n",
    "\n",
    "    #Chisquare value constraints\n",
    "    class ChisquareConstraintsOutlierPerc(mtl.Mean):\n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_012)]\n",
    "\n",
    "    class ChisquareConstraintsInstAttr(mtl.Mean):\n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_1614)]\n",
    "\n",
    "    class ChisquareConstraintsAttrEnt(mtl.Mean):\n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_3683)]\n",
    "\n",
    "    class ChisquareConstraintsInstances(mtl.Mean):\n",
    "        equivalent_to = [mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_gt_167_3)]           \n",
    "\n",
    "    class ChisquareConstraintsCov(mtl.Mean):             \n",
    "        equivalent_to = [ mtl.Mean &\n",
    "        mtl.hasDatavalue.some(float_lt_128_2)]\n",
    "\n",
    "\n",
    "    #MI constraints mean\n",
    "    class MIMean1(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        dmop1.NumberOfInstances & mtl.qlocation.some(mtl.MIConstraintsInstances)\n",
    "    ]\n",
    "\n",
    "    class MIMean2(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.Range & mtl.qlocation.some(mtl.MIConstraintsRange) ]\n",
    "\n",
    "    class MIMean3(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.AttributeConcentration & mtl.qlocation.some(mtl.MIConstraintsAttr) ]\n",
    "\n",
    "    #Relief constaints mean\n",
    "    class ReliefMean1(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        mtl.EqNumberOfAttributes & mtl.qlocation.some(mtl.ReliefConstraintsENA)\n",
    "    ]\n",
    "\n",
    "    class ReliefMean2(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.Range & mtl.qlocation.some(mtl.ReliefConstraintsRange) ]\n",
    "\n",
    "    class ReliefMean3(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            dmop1.NumberOfInstances & mtl.qlocation.some(mtl.ReliefConstraintsInstances) ]\n",
    "\n",
    "    class ReliefMean4(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        mtl.Covariance & mtl.qlocation.some(mtl.ReliefConstraintsCov)\n",
    "    ]\n",
    "\n",
    "    class ReliefMean5(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.NumberOfOutliers & mtl.qlocation.some(mtl.ReliefConstraintsNrOut) ]\n",
    "\n",
    "    class ReliefMean6(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.ClassEntropy & mtl.qlocation.some(mtl.ReliefConstraintscEntropy) ]\n",
    "\n",
    "    class ReliefMean7(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.OutlierDetection & mtl.qlocation.some(mtl.ReliefConstraintsOutlierPerc) ]\n",
    "\n",
    "    #GR constraints mean\n",
    "    class GRMean1(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        mtl.EqNumberOfAttributes & mtl.qlocation.some(mtl.GRConstraintsENA)\n",
    "    ]\n",
    "\n",
    "    class GRMean2(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            dmop1.NumberOfInstances & mtl.qlocation.some(mtl.GRConstraintsInstances) ]\n",
    "\n",
    "    class GRMean3(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        mtl.Covariance & mtl.qlocation.some(mtl.GRConstraintsCov)\n",
    "    ]\n",
    "\n",
    "    class GRMean4(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.LabelNoise & mtl.qlocation.some(mtl.GRConstraintsLabelissue) ]\n",
    "\n",
    "    class GRMean5(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.ClassEntropy & mtl.qlocation.some(mtl.GRConstraintscEntropy) ]\n",
    "\n",
    "    #FCBF constraints mean\n",
    "    class FCBFMean1(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "        mtl.Correlation & mtl.qlocation.some(mtl.FCBFConstraintsCorr)   ]\n",
    "\n",
    "    class FCBFMean2(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "        mtl.Skewness & mtl.qlocation.some(mtl.FCBFConstraintsSkew)   ]\n",
    "\n",
    "    class FCBFMean3(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "        dmop1.ProportionOfInstancesPerFeature & mtl.qlocation.some(mtl.FCBFConstraintsInstAttr)   ]\n",
    "\n",
    "    class FCBFMean4(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "        mtl.MedianOfAttributes & mtl.qlocation.some(mtl.FCBFConstraintsMedian)   ]\n",
    "\n",
    "    class FCBFMean5(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "        mtl.ClassImbalance & mtl.qlocation.some(mtl.FCBFConstraintsClassImb)   ]\n",
    "\n",
    "    class FCBFMean6(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "        mtl.EqNumberOfAttributes & mtl.qlocation.some(mtl.FCBFConstraintsENA)   ]\n",
    "\n",
    "    class FCBFMean7(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            dmop1.NumberOfInstances & mtl.qlocation.some(mtl.FCBFConstraintsInstances) ]\n",
    "\n",
    "    class FCBFMean8(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        mtl.Covariance & mtl.qlocation.some(mtl.FCBFConstraintsCov)\n",
    "    ]\n",
    "\n",
    "    #Chisquare\n",
    "    class ChisquareMean1(dmop1.DataCharacteristic):\n",
    "         equivalent_to = [\n",
    "         dmop1.NumberOfInstances & mtl.qlocation.some(mtl.ChisquareConstraintsInstances)   ]\n",
    "\n",
    "    class ChisquareMean2(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.OutlierDetection & mtl.qlocation.some(mtl.ChisquareConstraintsOutlierPerc) ]\n",
    "\n",
    "    class ChisquareMean3(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            dmop1.ProportionOfInstancesPerFeature & mtl.qlocation.some(mtl.ChisquareConstraintsInstAttr) ]\n",
    "\n",
    "    class ChisquareMean4(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "            mtl.AttributesEntropy & mtl.qlocation.some(mtl.ChisquareConstraintsAttrEnt) ]\n",
    "\n",
    "    class ChisquareMean5(dmop1.DataCharacteristic):\n",
    "        equivalent_to = [\n",
    "        mtl.Covariance & mtl.qlocation.some(mtl.ChisquareConstraintsCov)\n",
    "    ]\n",
    "\n",
    "\n",
    "    #MI dataset\n",
    "    class MIRelevantData(dmop.LabeledDataSet):\n",
    "        equivalent_to = [ dmop.LabeledDataSet &\n",
    "            mtl.hasQuality.some(mtl.MIMean1) & mtl.hasQuality.some(mtl.MIMean2) & mtl.hasQuality.some(mtl.MIMean3)\n",
    "        ]\n",
    "\n",
    "    #Relief dataset\n",
    "    class ReliefRelevantData(dmop.LabeledDataSet):\n",
    "        equivalent_to = [ dmop.LabeledDataSet &\n",
    "            mtl.hasQuality.some(mtl.ReliefMean1) & mtl.hasQuality.some(mtl.ReliefMean2) &\n",
    "            mtl.hasQuality.some(mtl.ReliefMean3) & mtl.hasQuality.some(mtl.ReliefMean4)&\n",
    "            mtl.hasQuality.some(mtl.ReliefMean5) & mtl.hasQuality.some(mtl.ReliefMean6)&\n",
    "            mtl.hasQuality.some(mtl.ReliefMean7)\n",
    "        ]\n",
    "\n",
    "    #GR dataset\n",
    "    class GRRelevantData(dmop.LabeledDataSet):\n",
    "        equivalent_to = [ dmop.LabeledDataSet &\n",
    "            mtl.hasQuality.some(mtl.GRMean1) & mtl.hasQuality.some(mtl.GRMean2) &\n",
    "            mtl.hasQuality.some(mtl.GRMean3) & mtl.hasQuality.some(mtl.GRMean4)&\n",
    "            mtl.hasQuality.some(mtl.GRMean5)\n",
    "        ]\n",
    "\n",
    "    #FCBF relevant data\n",
    "    class FCBFRelevantData(dmop.LabeledDataSet):\n",
    "        equivalent_to = [ dmop.LabeledDataSet &\n",
    "            mtl.hasQuality.some(mtl.FCBFMean1) & mtl.hasQuality.some(mtl.FCBFMean2) &\n",
    "            mtl.hasQuality.some(mtl.FCBFMean3) & mtl.hasQuality.some(mtl.FCBFMean4) &\n",
    "            mtl.hasQuality.some(mtl.FCBFMean5) & mtl.hasQuality.some(mtl.FCBFMean6) &\n",
    "            mtl.hasQuality.some(mtl.FCBFMean7) & mtl.hasQuality.some(mtl.FCBFMean8)\n",
    "        ]\n",
    "\n",
    "    #Chisquare dataset\n",
    "    class ChisquareRelevantData(dmop.LabeledDataSet):\n",
    "        equivalent_to = [ dmop.LabeledDataSet &\n",
    "            mtl.hasQuality.some(mtl.ChisquareMean1) & mtl.hasQuality.some(mtl.ChisquareMean2) &\n",
    "            mtl.hasQuality.some(mtl.ChisquareMean3) & mtl.hasQuality.some(mtl.ChisquareMean4)&\n",
    "            mtl.hasQuality.some(mtl.ChisquareMean5)\n",
    "        ]\n",
    "\n",
    "    #MI Task\n",
    "    class MITask(mtl.FeatureSelectionRecommendationTask):\n",
    "        equivalent_to = [\n",
    "        mtl.FeatureSelectionRecommendationTask &\n",
    "        dmop.specifiesInputClass.exactly(1, mtl.MIRelevantData)\n",
    "       &  dmop.specifiesOutputClass.exactly(1, mtl.MIRecommendation)\n",
    "    ]\n",
    "\n",
    "    #Relief Task\n",
    "    class ReliefTask(mtl.FeatureSelectionRecommendationTask):\n",
    "        equivalent_to = [\n",
    "        mtl.FeatureSelectionRecommendationTask &\n",
    "        dmop.specifiesInputClass.exactly(1, mtl.ReliefRelevantData)\n",
    "       &  dmop.specifiesOutputClass.exactly(1, mtl.ReliefRecommendation)\n",
    "    ]\n",
    "\n",
    "    #GR Task\n",
    "    class GRTask(mtl.FeatureSelectionRecommendationTask):\n",
    "        equivalent_to = [\n",
    "        mtl.FeatureSelectionRecommendationTask &\n",
    "        dmop.specifiesInputClass.exactly(1, mtl.GRRelevantData)\n",
    "       &  dmop.specifiesOutputClass.exactly(1, mtl.GRRecommendation)\n",
    "    ]\n",
    "\n",
    "    #FCBF Task\n",
    "    class FCBFTask(mtl.FeatureSelectionRecommendationTask):\n",
    "        equivalent_to = [\n",
    "        mtl.FeatureSelectionRecommendationTask &\n",
    "        dmop.specifiesInputClass.exactly(1, mtl.FCBFRelevantData)\n",
    "       &  dmop.specifiesOutputClass.exactly(1, mtl.FCBFRecommendation)\n",
    "    ]\n",
    "\n",
    "    #Chisquare Task\n",
    "    class ChisquareTask(mtl.FeatureSelectionRecommendationTask):\n",
    "        equivalent_to = [\n",
    "        mtl.FeatureSelectionRecommendationTask &\n",
    "        dmop.specifiesInputClass.exactly(1, mtl.ChisquareRelevantData)\n",
    "       &  dmop.specifiesOutputClass.exactly(1, mtl.ChisquareRecommendation)\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "  #  mtl.Reliefask.specifiesInputClass.append(mtl.ReliefRelevantData)\n",
    "    mtl.GRRecommendation.recommends.append(mtl.GainRatio)\n",
    "  #  mtl.MITask.specifiesInputClass.append(mtl.MIRelevantData)\n",
    "    mtl.MIRecommendation.recommends.append(mtl.MutualInformation)\n",
    "    mtl.ReliefRecommendation.recommends.append(mtl.Relief)\n",
    "    mtl.ChisquareRecommendation.recommends.append(mtl.ChiSquare)\n",
    "    mtl.FCBFRecommendation.recommends.append(mtl.FCBF)\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)\n",
    "\n",
    "onto.save(\"MtL_Enriched.owl\",format = \"rdfxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To check each feature selection technique as recommendation, run corresponding feature selection technique cell followed by the last cell i.e output cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Running Pellet...\n",
      "    /usr/lib/jvm/java-17-openjdk-amd64/bin/java -Xmx2000M -cp /home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/xercesImpl-2.10.0.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jgrapht-jdk1.5.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jcl-over-slf4j-1.6.4.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/xml-apis-1.4.01.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/httpclient-4.2.3.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/commons-codec-1.6.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/antlr-3.2.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jena-core-2.10.0.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jena-arq-2.10.0.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/httpcore-4.2.2.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/slf4j-api-1.6.4.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/log4j-1.2.16.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jena-tdb-0.10.0.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/antlr-runtime-3.2.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jena-iri-0.9.5.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/owlapi-distribution-3.4.3-bin.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/pellet-2.3.1.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/aterm-java-1.6.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/slf4j-log4j12-1.6.4.jar pellet.Pellet realize --loader Jena --input-format N-Triples --infer-prop-values --infer-data-prop-values --ignore-imports /tmp/tmpc_dfg7e8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Owlready * Adding relation MtLv2_gitversion.labelNoise immediate-relation MtLv2_gitversion.mean14\n",
      "* Owlready * Adding relation MtLv2_gitversion.labelNoise q-location MtLv2_gitversion.mean14\n",
      "* Owlready * Adding relation MtLv2_gitversion.outDetection immediate-relation MtLv2_gitversion.mean6\n",
      "* Owlready * Adding relation MtLv2_gitversion.outDetection q-location MtLv2_gitversion.mean6\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.medAttr\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.labelNoise\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.outDetection\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.corr\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.classImb\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.nrOut\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.attrconc\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.ena\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.range1\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.instAttr\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.clasEntropy\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.instance1\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 immediate-relation-i MtLv2_gitversion.cov\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.medAttr\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.labelNoise\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.outDetection\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.corr\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.classImb\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.nrOut\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.attrconc\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.ena\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.range1\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.instAttr\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.clasEntropy\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.instance1\n",
      "* Owlready * Adding relation MtLv2_gitversion.dataset1 has-quality MtLv2_gitversion.cov\n",
      "* Owlready * Adding relation MtLv2_gitversion.corr immediate-relation MtLv2_gitversion.mean10\n",
      "* Owlready * Adding relation MtLv2_gitversion.corr q-location MtLv2_gitversion.mean10\n",
      "* Owlready * Adding relation MtLv2_gitversion.ena immediate-relation MtLv2_gitversion.mean13\n",
      "* Owlready * Adding relation MtLv2_gitversion.ena q-location MtLv2_gitversion.mean13\n",
      "* Owlready * Adding relation MtLv2_gitversion.instance1 immediate-relation MtLv2_gitversion.mean1\n",
      "* Owlready * Adding relation MtLv2_gitversion.instance1 q-location MtLv2_gitversion.mean1\n",
      "* Owlready * Adding relation MtLv2_gitversion.medAttr immediate-relation MtLv2_gitversion.mean11\n",
      "* Owlready * Adding relation MtLv2_gitversion.medAttr q-location MtLv2_gitversion.mean11\n",
      "* Owlready * Adding relation MtLv2_gitversion.classImb immediate-relation MtLv2_gitversion.mean12\n",
      "* Owlready * Adding relation MtLv2_gitversion.classImb q-location MtLv2_gitversion.mean12\n",
      "* Owlready * Adding relation MtLv2_gitversion.nrOut immediate-relation MtLv2_gitversion.mean9\n",
      "* Owlready * Adding relation MtLv2_gitversion.nrOut q-location MtLv2_gitversion.mean9\n",
      "* Owlready * Adding relation MtLv2_gitversion.attrconc immediate-relation MtLv2_gitversion.mean3\n",
      "* Owlready * Adding relation MtLv2_gitversion.attrconc q-location MtLv2_gitversion.mean3\n",
      "* Owlready * Adding relation MtLv2_gitversion.range1 immediate-relation MtLv2_gitversion.mean2\n",
      "* Owlready * Adding relation MtLv2_gitversion.range1 q-location MtLv2_gitversion.mean2\n",
      "* Owlready * Adding relation MtLv2_gitversion.clasEntropy immediate-relation MtLv2_gitversion.mean5\n",
      "* Owlready * Adding relation MtLv2_gitversion.clasEntropy q-location MtLv2_gitversion.mean5\n",
      "* Owlready * Adding relation MtLv2_gitversion.instAttr immediate-relation MtLv2_gitversion.mean8\n",
      "* Owlready * Adding relation MtLv2_gitversion.instAttr q-location MtLv2_gitversion.mean8\n",
      "* Owlready * Adding relation MtLv2_gitversion.cov immediate-relation MtLv2_gitversion.mean4\n",
      "* Owlready * Adding relation MtLv2_gitversion.cov q-location MtLv2_gitversion.mean4\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean4 hasDataValue 0.23\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean6 hasDataValue 0.23\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean1 hasDataValue 120.0\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean8 hasDataValue 0.23\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean13 hasDataValue 0.23\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean11 hasDataValue 0.23\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean2 hasDataValue 10.0\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean3 hasDataValue 0.23\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean5 hasDataValue 0.23\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean14 hasDataValue 0.23\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean12 hasDataValue 0.23\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean7 hasDataValue 0.23\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean9 hasDataValue 0.23\n",
      "* Owlready * Adding relation MtLv2_gitversion.mean10 hasDataValue 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Pellet took 1.7591595649719238 seconds\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ChisquareMean1 MtLv2_gitversion.FCBFMean7\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ChisquareMean1 MtLv2_gitversion.ReliefMean3\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.FCBFMean7 MtLv2_gitversion.ChisquareMean1\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.FCBFMean7 MtLv2_gitversion.ReliefMean3\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ReliefMean3 MtLv2_gitversion.ChisquareMean1\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ReliefMean3 MtLv2_gitversion.FCBFMean7\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.FCBFMean8 MtLv2_gitversion.GRMean3\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.FCBFMean8 MtLv2_gitversion.GRMean3\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.GRMean3 MtLv2_gitversion.FCBFMean8\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.GRMean3 MtLv2_gitversion.FCBFMean8\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ChisquareMean5 MtLv2_gitversion.ReliefMean4\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ChisquareMean5 MtLv2_gitversion.ReliefMean4\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ReliefMean4 MtLv2_gitversion.ChisquareMean5\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ReliefMean4 MtLv2_gitversion.ChisquareMean5\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.FCBFConstraintsCov MtLv2_gitversion.GRConstraintsCov\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.GRConstraintsCov MtLv2_gitversion.FCBFConstraintsCov\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ChisquareConstraintsInstances MtLv2_gitversion.FCBFConstraintsInstances\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ChisquareConstraintsInstances MtLv2_gitversion.ReliefConstraintsInstances\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.FCBFConstraintsInstances MtLv2_gitversion.ChisquareConstraintsInstances\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.FCBFConstraintsInstances MtLv2_gitversion.ReliefConstraintsInstances\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ReliefConstraintsInstances MtLv2_gitversion.ChisquareConstraintsInstances\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ReliefConstraintsInstances MtLv2_gitversion.FCBFConstraintsInstances\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ChisquareConstraintsCov MtLv2_gitversion.ReliefConstraintsCov\n",
      "* Owlready * Equivalenting: MtLv2_gitversion.ReliefConstraintsCov MtLv2_gitversion.ChisquareConstraintsCov\n",
      "* Owlready * Reparenting MtLv2_gitversion.instance1: {DMOP.NumberOfInstances} => {MtLv2_gitversion.MIMean1}\n",
      "* Owlready * Reparenting MtLv2_gitversion.instAttr: {DMOP.ProportionOfInstancesPerFeature} => {MtLv2_gitversion.FCBFMean3}\n",
      "* Owlready * Reparenting MtLv2_gitversion.attrconc: {MtLv2_gitversion.AttributeConcentration} => {MtLv2_gitversion.MIMean3}\n",
      "* Owlready * Reparenting MtLv2_gitversion.nrOut: {MtLv2_gitversion.AttributesEntropy, MtLv2_gitversion.NumberOfOutliers} => {MtLv2_gitversion.ChisquareMean4, MtLv2_gitversion.ReliefMean5}\n",
      "* Owlready * Reparenting MtLv2_gitversion.clasEntropy: {MtLv2_gitversion.ClassEntropy} => {MtLv2_gitversion.GRMean5, MtLv2_gitversion.ReliefMean6}\n",
      "* Owlready * Reparenting MtLv2_gitversion.corr: {MtLv2_gitversion.Correlation} => {MtLv2_gitversion.FCBFMean1}\n",
      "* Owlready * Reparenting MtLv2_gitversion.cov: {MtLv2_gitversion.Covariance} => {MtLv2_gitversion.ReliefMean4, MtLv2_gitversion.ChisquareMean5}\n",
      "* Owlready * Reparenting MtLv2_gitversion.classImb: {MtLv2_gitversion.ClassImbalance} => {MtLv2_gitversion.FCBFMean5}\n",
      "* Owlready * Reparenting MtLv2_gitversion.outDetection: {MtLv2_gitversion.OutlierDetection} => {MtLv2_gitversion.ReliefMean7}\n",
      "* Owlready * Reparenting MtLv2_gitversion.ena: {MtLv2_gitversion.EqNumberOfAttributes} => {MtLv2_gitversion.FCBFMean6, MtLv2_gitversion.ReliefMean1}\n",
      "* Owlready * Reparenting MtLv2_gitversion.medAttr: {MtLv2_gitversion.MedianOfAttributes} => {MtLv2_gitversion.FCBFMean4}\n",
      "* Owlready * Reparenting MtLv2_gitversion.range1: {MtLv2_gitversion.Range} => {MtLv2_gitversion.MIMean2}\n",
      "* Owlready * Reparenting MtLv2_gitversion.dataset1: {DMOP.LabeledDataSet} => {MtLv2_gitversion.MIRelevantData}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean3: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.FCBFConstraintsCorr, MtLv2_gitversion.ReliefConstraintsENA, MtLv2_gitversion.FCBFConstraintsClassImb}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean4: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.FCBFConstraintsCorr, MtLv2_gitversion.ReliefConstraintsENA, MtLv2_gitversion.FCBFConstraintsClassImb}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean5: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.FCBFConstraintsCorr, MtLv2_gitversion.ReliefConstraintsENA, MtLv2_gitversion.FCBFConstraintsClassImb}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean12: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.FCBFConstraintsCorr, MtLv2_gitversion.ReliefConstraintsENA, MtLv2_gitversion.FCBFConstraintsClassImb}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean14: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.FCBFConstraintsCorr, MtLv2_gitversion.ReliefConstraintsENA, MtLv2_gitversion.FCBFConstraintsClassImb}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean7: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.FCBFConstraintsCorr, MtLv2_gitversion.ReliefConstraintsENA, MtLv2_gitversion.FCBFConstraintsClassImb}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean6: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.FCBFConstraintsCorr, MtLv2_gitversion.ReliefConstraintsENA, MtLv2_gitversion.FCBFConstraintsClassImb}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean8: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.FCBFConstraintsCorr, MtLv2_gitversion.ReliefConstraintsENA, MtLv2_gitversion.FCBFConstraintsClassImb}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean13: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.FCBFConstraintsCorr, MtLv2_gitversion.ReliefConstraintsENA, MtLv2_gitversion.FCBFConstraintsClassImb}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean11: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.FCBFConstraintsCorr, MtLv2_gitversion.ReliefConstraintsENA, MtLv2_gitversion.FCBFConstraintsClassImb}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean9: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.FCBFConstraintsCorr, MtLv2_gitversion.ReliefConstraintsENA, MtLv2_gitversion.FCBFConstraintsClassImb}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean10: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.FCBFConstraintsCorr, MtLv2_gitversion.ReliefConstraintsENA, MtLv2_gitversion.FCBFConstraintsClassImb}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean2: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.ReliefConstraintsNrOut, MtLv2_gitversion.MIConstraintsRange}\n",
      "* Owlready * Reparenting MtLv2_gitversion.mean1: {MtLv2_gitversion.Mean} => {MtLv2_gitversion.MIConstraintsInstances}\n",
      "* Owlready * (NB: only changes on entities loaded in Python are shown, other changes are done but not listed)\n"
     ]
    }
   ],
   "source": [
    "#FOR MI - Run this and last cell \n",
    "mtla = mtl.LearningFromTaskProperties(\"task1\")\n",
    "mtlt = onto.FeatureSelectionRecommendationTask(\"mtask1\")\n",
    "mtla.addresses.append(mtlt)\n",
    "\n",
    "fileObject = dmop.LabeledDataSet(\"dataset1\", namespace=onto) \n",
    "fsr_output = onto.FeatureSelectionRecommendation(\"output1\")\n",
    "\n",
    "mtlt.specifiesInputClass = [fileObject]\n",
    "mtlt.specifiesOutputClass = [fsr_output]\n",
    "\n",
    "nInstance = dmop1.NumberOfInstances(\"instance1\", namespace=onto)\n",
    "fileObject.hasQuality.append(nInstance)\n",
    "q3 = mtl.Mean(\"mean1\")\n",
    "nInstance.qlocation =[q3]\n",
    "q3.hasDatavalue.append(120.0)\n",
    "\n",
    "rRange = mtl.Range(\"range1\", namespace=onto)\n",
    "fileObject.hasQuality.append(rRange)\n",
    "q2 = mtl.Mean(\"mean2\")\n",
    "rRange.qlocation = [q2]\n",
    "q2.hasDatavalue.append(10.0)\n",
    "\n",
    "attrConc = mtl.AttributeConcentration(\"attrconc\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrConc)\n",
    "q4 = mtl.Mean(\"mean3\")\n",
    "attrConc.qlocation = [q4]\n",
    "q4.hasDatavalue.append(0.23)\n",
    "\n",
    "covR = mtl.Covariance(\"cov\", namespace=onto)\n",
    "fileObject.hasQuality.append(covR)\n",
    "q5 = mtl.Mean(\"mean4\")\n",
    "covR.qlocation = [q5]\n",
    "q5.hasDatavalue.append(0.23)\n",
    "\n",
    "cEntr = mtl.ClassEntropy(\"clasEntropy\", namespace=onto)\n",
    "fileObject.hasQuality.append(cEntr)\n",
    "q6 = mtl.Mean(\"mean5\")\n",
    "cEntr.qlocation = [q6]\n",
    "q6.hasDatavalue.append(0.23)\n",
    "\n",
    "outDet = mtl.OutlierDetection(\"outDetection\", namespace=onto)\n",
    "fileObject.hasQuality.append(outDet)\n",
    "q7 = mtl.Mean(\"mean6\")\n",
    "outDet.qlocation = [q7]\n",
    "q7.hasDatavalue.append(0.23)\n",
    "\n",
    "nrOut = mtl.NumberOfOutliers(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(nrOut)\n",
    "q8 = mtl.Mean(\"mean7\")\n",
    "nrOut.qlocation = [q8]\n",
    "q8.hasDatavalue.append(0.23)\n",
    "\n",
    "instFeat = dmop1.ProportionOfInstancesPerFeature(\"instAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(instFeat)\n",
    "q12 = mtl.Mean(\"mean8\")\n",
    "instFeat.qlocation = [q12]\n",
    "q12.hasDatavalue.append(0.23)\n",
    "\n",
    "attrEntr = mtl.AttributesEntropy(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrEntr)\n",
    "q9 = mtl.Mean(\"mean9\")\n",
    "attrEntr.qlocation = [q9]\n",
    "q9.hasDatavalue.append(0.23)\n",
    "\n",
    "corr = mtl.Correlation(\"corr\", namespace=onto)\n",
    "fileObject.hasQuality.append(corr)\n",
    "q10 = mtl.Mean(\"mean10\")\n",
    "corr.qlocation = [q10]\n",
    "q10.hasDatavalue.append(0.23)\n",
    "\n",
    "medAttr = mtl.MedianOfAttributes(\"medAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(medAttr)\n",
    "q11 = mtl.Mean(\"mean11\")\n",
    "medAttr.qlocation = [q11]\n",
    "q11.hasDatavalue.append(0.23)\n",
    "\n",
    "classImb = mtl.ClassImbalance(\"classImb\", namespace=onto)\n",
    "fileObject.hasQuality.append(classImb)\n",
    "q13 = mtl.Mean(\"mean12\")\n",
    "classImb.qlocation = [q13]\n",
    "q13.hasDatavalue.append(0.23)\n",
    "\n",
    "ena = mtl.EqNumberOfAttributes(\"ena\", namespace=onto)\n",
    "fileObject.hasQuality.append(ena)\n",
    "q14 = mtl.Mean(\"mean13\")\n",
    "ena.qlocation = [q14]\n",
    "q14.hasDatavalue.append(0.23)\n",
    "\n",
    "labelNoise = mtl.LabelNoise(\"labelNoise\", namespace=onto)\n",
    "fileObject.hasQuality.append(labelNoise)\n",
    "q15 = mtl.Mean(\"mean14\")\n",
    "labelNoise.qlocation = [q15]\n",
    "q15.hasDatavalue.append(0.23)\n",
    "\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(nr_inst > 167.000) and (cov.mean <= 1.289) and (OutlierPerc > 0.012) and (cEntropy > 0.440) and \n",
    "# (nr_outliers <= 12.500) and (ena <= 2.249) and (range.mean > 0.740) and (ena > -38.058) \n",
    "#Relief\n",
    "\n",
    "mtla = mtl.LearningFromTaskProperties(\"task1\")\n",
    "mtlt = onto.FeatureSelectionRecommendationTask(\"mtask1\")\n",
    "mtla.addresses.append(mtlt)\n",
    "\n",
    "fileObject = dmop.LabeledDataSet(\"dataset1\", namespace=onto) \n",
    "fsr_output = onto.FeatureSelectionRecommendation(\"output1\")\n",
    "\n",
    "mtlt.specifiesInputClass = [fileObject]\n",
    "mtlt.specifiesOutputClass = [fsr_output]\n",
    "\n",
    "nInstance = dmop1.NumberOfInstances(\"instance1\", namespace=onto)\n",
    "fileObject.hasQuality.append(nInstance)\n",
    "q3 = mtl.Mean(\"mean1\")\n",
    "nInstance.qlocation =[q3]\n",
    "q3.hasDatavalue.append(190.0)\n",
    "\n",
    "rRange = mtl.Range(\"range1\", namespace=onto)\n",
    "fileObject.hasQuality.append(rRange)\n",
    "q2 = mtl.Mean(\"mean2\")\n",
    "rRange.qlocation = [q2]\n",
    "q2.hasDatavalue.append(2.1)\n",
    "\n",
    "attrConc = mtl.AttributeConcentration(\"attrconc\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrConc)\n",
    "q4 = mtl.Mean(\"mean3\")\n",
    "attrConc.qlocation = [q4]\n",
    "q4.hasDatavalue.append(0.23)\n",
    "\n",
    "covR = mtl.Covariance(\"cov\", namespace=onto)\n",
    "fileObject.hasQuality.append(covR)\n",
    "q5 = mtl.Mean(\"mean4\")\n",
    "covR.qlocation = [q5]\n",
    "q5.hasDatavalue.append(0.23)\n",
    "\n",
    "cEntr = mtl.ClassEntropy(\"clasEntropy\", namespace=onto)\n",
    "fileObject.hasQuality.append(cEntr)\n",
    "q6 = mtl.Mean(\"mean5\")\n",
    "cEntr.qlocation = [q6]\n",
    "q6.hasDatavalue.append(0.53)\n",
    "\n",
    "outDet = mtl.OutlierDetection(\"outDetection\", namespace=onto)\n",
    "fileObject.hasQuality.append(outDet)\n",
    "q7 = mtl.Mean(\"mean6\")\n",
    "outDet.qlocation = [q7]\n",
    "q7.hasDatavalue.append(0.13)\n",
    "\n",
    "nrOut = mtl.NumberOfOutliers(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(nrOut)\n",
    "q8 = mtl.Mean(\"mean7\")\n",
    "nrOut.qlocation = [q8]\n",
    "q8.hasDatavalue.append(8.2)\n",
    "\n",
    "instFeat = dmop1.ProportionOfInstancesPerFeature(\"instAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(instFeat)\n",
    "q12 = mtl.Mean(\"mean8\")\n",
    "instFeat.qlocation = [q12]\n",
    "q12.hasDatavalue.append(0.23)\n",
    "\n",
    "attrEntr = mtl.AttributesEntropy(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrEntr)\n",
    "q9 = mtl.Mean(\"mean9\")\n",
    "attrEntr.qlocation = [q9]\n",
    "q9.hasDatavalue.append(0.23)\n",
    "\n",
    "corr = mtl.Correlation(\"corr\", namespace=onto)\n",
    "fileObject.hasQuality.append(corr)\n",
    "q10 = mtl.Mean(\"mean10\")\n",
    "corr.qlocation = [q10]\n",
    "q10.hasDatavalue.append(0.23)\n",
    "\n",
    "medAttr = mtl.MedianOfAttributes(\"medAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(medAttr)\n",
    "q11 = mtl.Mean(\"mean11\")\n",
    "medAttr.qlocation = [q11]\n",
    "q11.hasDatavalue.append(0.23)\n",
    "\n",
    "classImb = mtl.ClassImbalance(\"classImb\", namespace=onto)\n",
    "fileObject.hasQuality.append(classImb)\n",
    "q13 = mtl.Mean(\"mean12\")\n",
    "classImb.qlocation = [q13]\n",
    "q13.hasDatavalue.append(0.23)\n",
    "\n",
    "ena = mtl.EqNumberOfAttributes(\"ena\", namespace=onto)\n",
    "fileObject.hasQuality.append(ena)\n",
    "q14 = mtl.Mean(\"mean13\")\n",
    "ena.qlocation = [q14]\n",
    "q14.hasDatavalue.append(0.12)\n",
    "\n",
    "labelNoise = mtl.LabelNoise(\"labelNoise\", namespace=onto)\n",
    "fileObject.hasQuality.append(labelNoise)\n",
    "q15 = mtl.Mean(\"mean14\")\n",
    "labelNoise.qlocation = [q15]\n",
    "q15.hasDatavalue.append(0.23)\n",
    "\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (cov.mean <= 1.289) and (OutlierPerc <= 0.012) and \n",
    "#(inst_to_attr <= 1614.176) and (attr_ent.mean <= 3.683) and (nr_inst > 413.000)\n",
    "#Chisquare\n",
    "mtla = mtl.LearningFromTaskProperties(\"task1\")\n",
    "mtlt = onto.FeatureSelectionRecommendationTask(\"mtask1\")\n",
    "mtla.addresses.append(mtlt)\n",
    "\n",
    "fileObject = dmop.LabeledDataSet(\"dataset1\", namespace=onto) \n",
    "fsr_output = onto.FeatureSelectionRecommendation(\"output1\")\n",
    "\n",
    "mtlt.specifiesInputClass = [fileObject]\n",
    "mtlt.specifiesOutputClass = [fsr_output]\n",
    "\n",
    "nInstance = dmop1.NumberOfInstances(\"instance1\", namespace=onto)\n",
    "fileObject.hasQuality.append(nInstance)\n",
    "q3 = mtl.Mean(\"mean1\")\n",
    "nInstance.qlocation =[q3]\n",
    "q3.hasDatavalue.append(490.0)\n",
    "\n",
    "rRange = mtl.Range(\"range1\", namespace=onto)\n",
    "fileObject.hasQuality.append(rRange)\n",
    "q2 = mtl.Mean(\"mean2\")\n",
    "rRange.qlocation = [q2]\n",
    "q2.hasDatavalue.append(2.1)\n",
    "\n",
    "attrConc = mtl.AttributeConcentration(\"attrconc\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrConc)\n",
    "q4 = mtl.Mean(\"mean3\")\n",
    "attrConc.qlocation = [q4]\n",
    "q4.hasDatavalue.append(0.23)\n",
    "\n",
    "covR = mtl.Covariance(\"cov\", namespace=onto)\n",
    "fileObject.hasQuality.append(covR)\n",
    "q5 = mtl.Mean(\"mean4\")\n",
    "covR.qlocation = [q5]\n",
    "q5.hasDatavalue.append(0.23)\n",
    "\n",
    "cEntr = mtl.ClassEntropy(\"clasEntropy\", namespace=onto)\n",
    "fileObject.hasQuality.append(cEntr)\n",
    "q6 = mtl.Mean(\"mean5\")\n",
    "cEntr.qlocation = [q6]\n",
    "q6.hasDatavalue.append(0.53)\n",
    "\n",
    "outDet = mtl.OutlierDetection(\"outDetection\", namespace=onto)\n",
    "fileObject.hasQuality.append(outDet)\n",
    "q7 = mtl.Mean(\"mean6\")\n",
    "outDet.qlocation = [q7]\n",
    "q7.hasDatavalue.append(0.0)\n",
    "\n",
    "nrOut = mtl.NumberOfOutliers(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(nrOut)\n",
    "q8 = mtl.Mean(\"mean7\")\n",
    "nrOut.qlocation = [q8]\n",
    "q8.hasDatavalue.append(8.2)\n",
    "\n",
    "instFeat = dmop1.ProportionOfInstancesPerFeature(\"instAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(instFeat)\n",
    "q12 = mtl.Mean(\"mean8\")\n",
    "instFeat.qlocation = [q12]\n",
    "q12.hasDatavalue.append(123.43)\n",
    "\n",
    "attrEntr = mtl.AttributesEntropy(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrEntr)\n",
    "q9 = mtl.Mean(\"mean9\")\n",
    "attrEntr.qlocation = [q9]\n",
    "q9.hasDatavalue.append(3.17)\n",
    "\n",
    "corr = mtl.Correlation(\"corr\", namespace=onto)\n",
    "fileObject.hasQuality.append(corr)\n",
    "q10 = mtl.Mean(\"mean10\")\n",
    "corr.qlocation = [q10]\n",
    "q10.hasDatavalue.append(0.23)\n",
    "\n",
    "medAttr = mtl.MedianOfAttributes(\"medAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(medAttr)\n",
    "q11 = mtl.Mean(\"mean11\")\n",
    "medAttr.qlocation = [q11]\n",
    "q11.hasDatavalue.append(0.23)\n",
    "\n",
    "classImb = mtl.ClassImbalance(\"classImb\", namespace=onto)\n",
    "fileObject.hasQuality.append(classImb)\n",
    "q13 = mtl.Mean(\"mean12\")\n",
    "classImb.qlocation = [q13]\n",
    "q13.hasDatavalue.append(0.23)\n",
    "\n",
    "ena = mtl.EqNumberOfAttributes(\"ena\", namespace=onto)\n",
    "fileObject.hasQuality.append(ena)\n",
    "q14 = mtl.Mean(\"mean13\")\n",
    "ena.qlocation = [q14]\n",
    "q14.hasDatavalue.append(0.12)\n",
    "\n",
    "labelNoise = mtl.LabelNoise(\"labelNoise\", namespace=onto)\n",
    "fileObject.hasQuality.append(labelNoise)\n",
    "q15 = mtl.Mean(\"mean14\")\n",
    "labelNoise.qlocation = [q15]\n",
    "q15.hasDatavalue.append(0.23)\n",
    "\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(nr_inst > 167.000) and (nr_inst <= 372.000) and (cov.mean > 1.289)  and (ena <= 13.853) and \n",
    "# (LabelIssuesPerc <= 0.068) and (cEntropy <= 0.990)\n",
    "#GR\n",
    "\n",
    "mtla = mtl.LearningFromTaskProperties(\"task1\")\n",
    "mtlt = onto.FeatureSelectionRecommendationTask(\"mtask1\")\n",
    "mtla.addresses.append(mtlt)\n",
    "\n",
    "fileObject = dmop.LabeledDataSet(\"dataset1\", namespace=onto) \n",
    "fsr_output = onto.FeatureSelectionRecommendation(\"output1\")\n",
    "\n",
    "mtlt.specifiesInputClass = [fileObject]\n",
    "mtlt.specifiesOutputClass = [fsr_output]\n",
    "\n",
    "nInstance = dmop1.NumberOfInstances(\"instance1\", namespace=onto)\n",
    "fileObject.hasQuality.append(nInstance)\n",
    "q3 = mtl.Mean(\"mean1\")\n",
    "nInstance.qlocation =[q3]\n",
    "q3.hasDatavalue.append(320.0)\n",
    "\n",
    "rRange = mtl.Range(\"range1\", namespace=onto)\n",
    "fileObject.hasQuality.append(rRange)\n",
    "q2 = mtl.Mean(\"mean2\")\n",
    "rRange.qlocation = [q2]\n",
    "q2.hasDatavalue.append(2.1)\n",
    "\n",
    "attrConc = mtl.AttributeConcentration(\"attrconc\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrConc)\n",
    "q4 = mtl.Mean(\"mean3\")\n",
    "attrConc.qlocation = [q4]\n",
    "q4.hasDatavalue.append(0.23)\n",
    "\n",
    "covR = mtl.Covariance(\"cov\", namespace=onto)\n",
    "fileObject.hasQuality.append(covR)\n",
    "q5 = mtl.Mean(\"mean4\")\n",
    "covR.qlocation = [q5]\n",
    "q5.hasDatavalue.append(1.3)\n",
    "\n",
    "cEntr = mtl.ClassEntropy(\"clasEntropy\", namespace=onto)\n",
    "fileObject.hasQuality.append(cEntr)\n",
    "q6 = mtl.Mean(\"mean5\")\n",
    "cEntr.qlocation = [q6]\n",
    "q6.hasDatavalue.append(0.53)\n",
    "\n",
    "outDet = mtl.OutlierDetection(\"outDetection\", namespace=onto)\n",
    "fileObject.hasQuality.append(outDet)\n",
    "q7 = mtl.Mean(\"mean6\")\n",
    "outDet.qlocation = [q7]\n",
    "q7.hasDatavalue.append(0.0)\n",
    "\n",
    "nrOut = mtl.NumberOfOutliers(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(nrOut)\n",
    "q8 = mtl.Mean(\"mean7\")\n",
    "nrOut.qlocation = [q8]\n",
    "q8.hasDatavalue.append(8.2)\n",
    "\n",
    "instFeat = dmop1.ProportionOfInstancesPerFeature(\"instAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(instFeat)\n",
    "q12 = mtl.Mean(\"mean8\")\n",
    "instFeat.qlocation = [q12]\n",
    "q12.hasDatavalue.append(123.43)\n",
    "\n",
    "attrEntr = mtl.AttributesEntropy(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrEntr)\n",
    "q9 = mtl.Mean(\"mean9\")\n",
    "attrEntr.qlocation = [q9]\n",
    "q9.hasDatavalue.append(3.6)\n",
    "\n",
    "corr = mtl.Correlation(\"corr\", namespace=onto)\n",
    "fileObject.hasQuality.append(corr)\n",
    "q10 = mtl.Mean(\"mean10\")\n",
    "corr.qlocation = [q10]\n",
    "q10.hasDatavalue.append(0.23)\n",
    "\n",
    "medAttr = mtl.MedianOfAttributes(\"medAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(medAttr)\n",
    "q11 = mtl.Mean(\"mean11\")\n",
    "medAttr.qlocation = [q11]\n",
    "q11.hasDatavalue.append(0.23)\n",
    "\n",
    "classImb = mtl.ClassImbalance(\"classImb\", namespace=onto)\n",
    "fileObject.hasQuality.append(classImb)\n",
    "q13 = mtl.Mean(\"mean12\")\n",
    "classImb.qlocation = [q13]\n",
    "q13.hasDatavalue.append(0.23)\n",
    "\n",
    "ena = mtl.EqNumberOfAttributes(\"ena\", namespace=onto)\n",
    "fileObject.hasQuality.append(ena)\n",
    "q14 = mtl.Mean(\"mean13\")\n",
    "ena.qlocation = [q14]\n",
    "q14.hasDatavalue.append(13.853)\n",
    "\n",
    "labelNoise = mtl.LabelNoise(\"labelNoise\", namespace=onto)\n",
    "fileObject.hasQuality.append(labelNoise)\n",
    "q15 = mtl.Mean(\"mean14\")\n",
    "labelNoise.qlocation = [q15]\n",
    "q15.hasDatavalue.append(0.068)\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FCBF\n",
    "# (cov.mean > 1.289) and (nr_inst > 372.000) and (cor.mean > 0.119) and (skewness.mean <= 4.130) \n",
    "#(inst_to_attr <= 267.375) and (median.mean <= 26234.938) and (ClassImbRatio <= 0.733) and (ena > -0.405)\n",
    "\n",
    "mtla = mtl.LearningFromTaskProperties(\"task1\")\n",
    "mtlt = onto.FeatureSelectionRecommendationTask(\"mtask1\")\n",
    "mtla.addresses.append(mtlt)\n",
    "\n",
    "fileObject = dmop.LabeledDataSet(\"dataset1\", namespace=onto) \n",
    "fsr_output = onto.FeatureSelectionRecommendation(\"output1\")\n",
    "\n",
    "mtlt.specifiesInputClass = [fileObject]\n",
    "mtlt.specifiesOutputClass = [fsr_output]\n",
    "\n",
    "nInstance = dmop1.NumberOfInstances(\"instance1\", namespace=onto)\n",
    "fileObject.hasQuality.append(nInstance)\n",
    "q3 = mtl.Mean(\"mean1\")\n",
    "nInstance.qlocation =[q3]\n",
    "q3.hasDatavalue.append(390.0)\n",
    "\n",
    "rRange = mtl.Range(\"range1\", namespace=onto)\n",
    "fileObject.hasQuality.append(rRange)\n",
    "q2 = mtl.Mean(\"mean2\")\n",
    "rRange.qlocation = [q2]\n",
    "q2.hasDatavalue.append(2.1)\n",
    "\n",
    "attrConc = mtl.AttributeConcentration(\"attrconc\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrConc)\n",
    "q4 = mtl.Mean(\"mean3\")\n",
    "attrConc.qlocation = [q4]\n",
    "q4.hasDatavalue.append(0.23)\n",
    "\n",
    "covR = mtl.Covariance(\"cov\", namespace=onto)\n",
    "fileObject.hasQuality.append(covR)\n",
    "q5 = mtl.Mean(\"mean4\")\n",
    "covR.qlocation = [q5]\n",
    "q5.hasDatavalue.append(1.33)\n",
    "\n",
    "cEntr = mtl.ClassEntropy(\"clasEntropy\", namespace=onto)\n",
    "fileObject.hasQuality.append(cEntr)\n",
    "q6 = mtl.Mean(\"mean5\")\n",
    "cEntr.qlocation = [q6]\n",
    "q6.hasDatavalue.append(0.53)\n",
    "\n",
    "outDet = mtl.OutlierDetection(\"outDetection\", namespace=onto)\n",
    "fileObject.hasQuality.append(outDet)\n",
    "q7 = mtl.Mean(\"mean6\")\n",
    "outDet.qlocation = [q7]\n",
    "q7.hasDatavalue.append(0.0)\n",
    "\n",
    "nrOut = mtl.NumberOfOutliers(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(nrOut)\n",
    "q8 = mtl.Mean(\"mean7\")\n",
    "nrOut.qlocation = [q8]\n",
    "q8.hasDatavalue.append(8.2)\n",
    "\n",
    "instFeat = dmop1.ProportionOfInstancesPerFeature(\"instAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(instFeat)\n",
    "q12 = mtl.Mean(\"mean8\")\n",
    "instFeat.qlocation = [q12]\n",
    "q12.hasDatavalue.append(123.43)\n",
    "\n",
    "attrEntr = mtl.AttributesEntropy(\"nrOut\", namespace=onto)\n",
    "fileObject.hasQuality.append(attrEntr)\n",
    "q9 = mtl.Mean(\"mean9\")\n",
    "attrEntr.qlocation = [q9]\n",
    "q9.hasDatavalue.append(3.6)\n",
    "\n",
    "corr = mtl.Correlation(\"corr\", namespace=onto)\n",
    "fileObject.hasQuality.append(corr)\n",
    "q10 = mtl.Mean(\"mean10\")\n",
    "corr.qlocation = [q10]\n",
    "q10.hasDatavalue.append(0.12)\n",
    "\n",
    "medAttr = mtl.MedianOfAttributes(\"medAttr\", namespace=onto)\n",
    "fileObject.hasQuality.append(medAttr)\n",
    "q11 = mtl.Mean(\"mean11\")\n",
    "medAttr.qlocation = [q11]\n",
    "q11.hasDatavalue.append(123.3)\n",
    "\n",
    "classImb = mtl.ClassImbalance(\"classImb\", namespace=onto)\n",
    "fileObject.hasQuality.append(classImb)\n",
    "q13 = mtl.Mean(\"mean12\")\n",
    "classImb.qlocation = [q13]\n",
    "q13.hasDatavalue.append(0.23)\n",
    "\n",
    "ena = mtl.EqNumberOfAttributes(\"ena\", namespace=onto)\n",
    "fileObject.hasQuality.append(ena)\n",
    "q14 = mtl.Mean(\"mean13\")\n",
    "ena.qlocation = [q14]\n",
    "q14.hasDatavalue.append(13.853)\n",
    "\n",
    "labelNoise = mtl.LabelNoise(\"labelNoise\", namespace=onto)\n",
    "fileObject.hasQuality.append(labelNoise)\n",
    "q15 = mtl.Mean(\"mean14\")\n",
    "labelNoise.qlocation = [q15]\n",
    "q15.hasDatavalue.append(0.068)\n",
    "\n",
    "skew = mtl.Skewness(\"skew\", namespace=onto)\n",
    "fileObject.hasQuality.append(skew)\n",
    "q16 = mtl.Mean(\"mean15\")\n",
    "skew.qlocation = [q16]\n",
    "q16.hasDatavalue.append(0.068)\n",
    "\n",
    "sync_reasoner_pellet([onto], infer_property_values=True, infer_data_property_values=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset1 satisfies MIRelevantData constraint\n",
      "Recommended feature selection technique is [MtLv2_gitversion.MutualInformation]\n"
     ]
    }
   ],
   "source": [
    "# Check classification again just to be safe\n",
    "if onto.MIRelevantData in fileObject.is_a:\n",
    "    print(f\"{fileObject.name} satisfies MIRelevantData constraint\")\n",
    "    output = onto.MITask.specifiesOutputClass\n",
    "    print(\"Recommended feature selection technique is\", output[0].recommends)\n",
    "elif onto.FCBFRelevantData in fileObject.is_a:\n",
    "    print(f\"{fileObject.name} satisfies FCBFRelevantData constraint\")\n",
    "    output = onto.FCBFTask.specifiesOutputClass\n",
    "    print(\"Recommended feature selection technique is\", output[0].recommends)\n",
    "elif onto.ChisquareRelevantData in fileObject.is_a:\n",
    "    print(f\"{fileObject.name} satisfies ChisquareRelevantData constraint\")\n",
    "    output = onto.ChisquareTask.specifiesOutputClass\n",
    "    print(\"Recommended feature selection technique is\", output[0].recommends)\n",
    "elif onto.GRRelevantData in fileObject.is_a:\n",
    "    print(f\"{fileObject.name} satisfies GRRelevantData constraint\")\n",
    "    output = onto.GRTask.specifiesOutputClass\n",
    "    print(\"Recommended feature selection technique is\", output[0].recommends)\n",
    "elif onto.ReliefRelevantData in fileObject.is_a:\n",
    "    print(f\"{fileObject.name} satisfies ReliefRelevantData constraint\")\n",
    "    output = onto.ReliefTask.specifiesOutputClass\n",
    "    print(\"Recommended feature selection technique is\", output[0].recommends)\n",
    "else:\n",
    "    print(f\"{fileObject.name} does NOT satisfy any constraints\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".deeplearningClass",
   "language": "python",
   "name": ".deeplearningclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
