{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jenkspy\n",
    "import numpy as np\n",
    "from owlready2 import *\n",
    "import ast\n",
    "import rdflib\n",
    "import re\n",
    "\n",
    "\n",
    "owlready2.JAVA_EXE =\"/usr/lib/jvm/java-17-openjdk-amd64/bin/java\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"KnowledgeBase.csv\")\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_round(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return value  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(convert_and_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>features</th>\n",
       "      <th>cor.mean</th>\n",
       "      <th>cor.sd</th>\n",
       "      <th>cov.mean</th>\n",
       "      <th>cov.sd</th>\n",
       "      <th>eigenvalues.mean</th>\n",
       "      <th>eigenvalues.sd</th>\n",
       "      <th>g_mean.mean</th>\n",
       "      <th>g_mean.sd</th>\n",
       "      <th>h_mean.mean</th>\n",
       "      <th>h_mean.sd</th>\n",
       "      <th>...</th>\n",
       "      <th>nr_num</th>\n",
       "      <th>nr_bin</th>\n",
       "      <th>nUnique</th>\n",
       "      <th>attr_conc.mean</th>\n",
       "      <th>attr_conc.sd</th>\n",
       "      <th>attr_ent.mean</th>\n",
       "      <th>attr_ent.sd</th>\n",
       "      <th>cEntropy</th>\n",
       "      <th>ena</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.934819e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.250000e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161121</td>\n",
       "      <td>-618.736391</td>\n",
       "      <td>chronic_kidney_disease_full.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.282243</td>\n",
       "      <td>0.154601</td>\n",
       "      <td>3.259958e+08</td>\n",
       "      <td>3.900849e+09</td>\n",
       "      <td>2.462089e+11</td>\n",
       "      <td>1.435632e+12</td>\n",
       "      <td>1.948261e+05</td>\n",
       "      <td>8.333778e+05</td>\n",
       "      <td>1.632278e+05</td>\n",
       "      <td>8.297795e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.034568e-01</td>\n",
       "      <td>0.102187</td>\n",
       "      <td>2.193176</td>\n",
       "      <td>0.697027</td>\n",
       "      <td>0.640944</td>\n",
       "      <td>-618.736391</td>\n",
       "      <td>Autism-Adolescent-Data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.282243</td>\n",
       "      <td>0.154601</td>\n",
       "      <td>3.259958e+08</td>\n",
       "      <td>3.900849e+09</td>\n",
       "      <td>2.462089e+11</td>\n",
       "      <td>1.435632e+12</td>\n",
       "      <td>1.948261e+05</td>\n",
       "      <td>8.333778e+05</td>\n",
       "      <td>1.632278e+05</td>\n",
       "      <td>8.297795e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.034568e-01</td>\n",
       "      <td>0.102187</td>\n",
       "      <td>2.193176</td>\n",
       "      <td>0.697027</td>\n",
       "      <td>0.640944</td>\n",
       "      <td>-618.736391</td>\n",
       "      <td>Autism-Adolescent-Data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.722547</td>\n",
       "      <td>0.383566</td>\n",
       "      <td>5.797629e+12</td>\n",
       "      <td>8.376166e+13</td>\n",
       "      <td>5.050378e+14</td>\n",
       "      <td>2.810000e+15</td>\n",
       "      <td>4.293926e+06</td>\n",
       "      <td>1.410736e+07</td>\n",
       "      <td>3.051064e+06</td>\n",
       "      <td>1.024667e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>241.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.256698e-01</td>\n",
       "      <td>0.366012</td>\n",
       "      <td>4.700437</td>\n",
       "      <td>1.815644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>87.038564</td>\n",
       "      <td>SouthGermanCredit.asc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "features  cor.mean    cor.sd      cov.mean        cov.sd  eigenvalues.mean  \\\n",
       "0         0.000000  0.000000  0.000000e+00  0.000000e+00      7.934819e-03   \n",
       "1         0.282243  0.154601  3.259958e+08  3.900849e+09      2.462089e+11   \n",
       "2         0.282243  0.154601  3.259958e+08  3.900849e+09      2.462089e+11   \n",
       "3         0.722547  0.383566  5.797629e+12  8.376166e+13      5.050378e+14   \n",
       "\n",
       "features  eigenvalues.sd   g_mean.mean     g_mean.sd   h_mean.mean  \\\n",
       "0           0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1           1.435632e+12  1.948261e+05  8.333778e+05  1.632278e+05   \n",
       "2           1.435632e+12  1.948261e+05  8.333778e+05  1.632278e+05   \n",
       "3           2.810000e+15  4.293926e+06  1.410736e+07  3.051064e+06   \n",
       "\n",
       "features     h_mean.sd  ...  nr_num  nr_bin  nUnique  attr_conc.mean  \\\n",
       "0         0.000000e+00  ...     3.0     0.0      2.0   -6.250000e-08   \n",
       "1         8.297795e+05  ...    44.0    35.0     10.0    1.034568e-01   \n",
       "2         8.297795e+05  ...    44.0    35.0     10.0    1.034568e-01   \n",
       "3         1.024667e+07  ...   241.0   199.0     28.0    3.256698e-01   \n",
       "\n",
       "features  attr_conc.sd  attr_ent.mean  attr_ent.sd  cEntropy         ena  \\\n",
       "0             0.000000       0.187406     0.000000  0.161121 -618.736391   \n",
       "1             0.102187       2.193176     0.697027  0.640944 -618.736391   \n",
       "2             0.102187       2.193176     0.697027  0.640944 -618.736391   \n",
       "3             0.366012       4.700437     1.815644  1.000000   87.038564   \n",
       "\n",
       "features                             file  \n",
       "0         chronic_kidney_disease_full.csv  \n",
       "1              Autism-Adolescent-Data.csv  \n",
       "2              Autism-Adolescent-Data.csv  \n",
       "3                   SouthGermanCredit.asc  \n",
       "\n",
       "[4 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limit = pd.read_csv(\"BinLimits.csv\")\n",
    "df_transposed = df_limit.T\n",
    "\n",
    "df_transposed.columns = df_transposed.iloc[0]\n",
    "df_transposed = df_transposed[1:]\n",
    "\n",
    "df_transposed.reset_index(drop=True, inplace=True)\n",
    "df_limit = df_transposed.copy()\n",
    "\n",
    "for col in df_limit.columns:\n",
    "    df_limit[col] = df_limit[col].apply(convert_and_round)\n",
    "\n",
    "df_limit.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Conciseness</th>\n",
       "      <th>cor.mean</th>\n",
       "      <th>cov.mean</th>\n",
       "      <th>eigenvalues.mean</th>\n",
       "      <th>g_mean.mean</th>\n",
       "      <th>h_mean.mean</th>\n",
       "      <th>iq_range.mean</th>\n",
       "      <th>kurtosis.mean</th>\n",
       "      <th>mad.mean</th>\n",
       "      <th>...</th>\n",
       "      <th>inst_to_attr</th>\n",
       "      <th>nr_attr</th>\n",
       "      <th>nr_bin</th>\n",
       "      <th>nr_inst</th>\n",
       "      <th>nr_num</th>\n",
       "      <th>attr_conc.mean</th>\n",
       "      <th>attr_ent.mean</th>\n",
       "      <th>ena</th>\n",
       "      <th>snr.mean</th>\n",
       "      <th>cEntropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008164</td>\n",
       "      <td>0.047814</td>\n",
       "      <td>0.212196</td>\n",
       "      <td>3.351657e+10</td>\n",
       "      <td>4.941447e+12</td>\n",
       "      <td>32760.393244</td>\n",
       "      <td>23321.141081</td>\n",
       "      <td>34216.554678</td>\n",
       "      <td>174.309984</td>\n",
       "      <td>26153.290570</td>\n",
       "      <td>...</td>\n",
       "      <td>143.463112</td>\n",
       "      <td>20.132948</td>\n",
       "      <td>4.682081</td>\n",
       "      <td>2247.745665</td>\n",
       "      <td>20.132948</td>\n",
       "      <td>0.074142</td>\n",
       "      <td>2.093026</td>\n",
       "      <td>-1.596274</td>\n",
       "      <td>7.428674</td>\n",
       "      <td>0.759968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046216</td>\n",
       "      <td>0.138593</td>\n",
       "      <td>0.157592</td>\n",
       "      <td>4.407852e+11</td>\n",
       "      <td>4.656405e+13</td>\n",
       "      <td>355612.287621</td>\n",
       "      <td>252776.543146</td>\n",
       "      <td>414704.012180</td>\n",
       "      <td>850.583438</td>\n",
       "      <td>333205.398178</td>\n",
       "      <td>...</td>\n",
       "      <td>378.764030</td>\n",
       "      <td>25.173346</td>\n",
       "      <td>17.380742</td>\n",
       "      <td>6902.012685</td>\n",
       "      <td>25.173346</td>\n",
       "      <td>0.064320</td>\n",
       "      <td>0.860680</td>\n",
       "      <td>56.943940</td>\n",
       "      <td>15.798356</td>\n",
       "      <td>0.252665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Column  Completeness  Conciseness  cor.mean      cov.mean  eigenvalues.mean  \\\n",
       "0           0.008164     0.047814  0.212196  3.351657e+10      4.941447e+12   \n",
       "1           0.046216     0.138593  0.157592  4.407852e+11      4.656405e+13   \n",
       "\n",
       "Column    g_mean.mean    h_mean.mean  iq_range.mean  kurtosis.mean  \\\n",
       "0        32760.393244   23321.141081   34216.554678     174.309984   \n",
       "1       355612.287621  252776.543146  414704.012180     850.583438   \n",
       "\n",
       "Column       mad.mean  ...  inst_to_attr    nr_attr     nr_bin      nr_inst  \\\n",
       "0        26153.290570  ...    143.463112  20.132948   4.682081  2247.745665   \n",
       "1       333205.398178  ...    378.764030  25.173346  17.380742  6902.012685   \n",
       "\n",
       "Column     nr_num  attr_conc.mean  attr_ent.mean        ena   snr.mean  \\\n",
       "0       20.132948        0.074142       2.093026  -1.596274   7.428674   \n",
       "1       25.173346        0.064320       0.860680  56.943940  15.798356   \n",
       "\n",
       "Column  cEntropy  \n",
       "0       0.759968  \n",
       "1       0.252665  \n",
       "\n",
       "[2 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalised  = pd.read_csv(\"NormalizationValues.csv\")\n",
    "df_transposed = df_normalised.T\n",
    "df_transposed.columns = df_transposed.iloc[0]\n",
    "df_transposed = df_transposed[1:]\n",
    "\n",
    "df_transposed.reset_index(drop=True, inplace=True)\n",
    "df_normalised = df_transposed.copy()\n",
    "\n",
    "\n",
    "for col in df_normalised.columns:\n",
    "    df_normalised[col] = df_normalised[col].apply(convert_and_round)\n",
    "df_normalised.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto = get_ontology(\"file:///home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS_git/MtLv2.owl\").load()\n",
    "dcat = get_namespace(\"http://www.w3.org/ns/dcat/\")\n",
    "dqv = get_namespace(\"http://www.w3.org/ns/dqv/\")\n",
    "mtl = get_ontology(\"https://purl.archive.org/domain/mtl#\")\n",
    "#onto.base_iri = \"https://purl.archive.org/domain/mtl#\"\n",
    "rdf=get_namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "dmop = get_ontology(\"http://www.e-lico.eu/ontologies/dmop/DMOP/DMOP.owl\")\n",
    "dmop.base_iri = \"http://www.e-lico.eu/ontologies/dmo/DMOP/DMOP.owl#\"\n",
    "dmop1 = get_ontology(\"http://www.e-LICO.eu/ontologies/dmo/DMOP/DMOP.owl\")\n",
    "dmop1.base_iri = \"http://www.e-LICO.eu/ontologies/dmo/DMOP/DMOP.owl#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'[^a-zA-Z0-9]') #removing non-alpha numeric characters from file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with onto:\n",
    "    mtla = mtl.MetaLearningAlgorithm()\n",
    "    featureSelectionTask = dmop.FeatureSelectionTask()\n",
    "    mtla.hasMetaObjective.append(featureSelectionTask)\n",
    "\n",
    "    corParameter = mtl.CorrelationParameter()\n",
    "    mtla.hasParameter.append(corParameter)\n",
    "    corParameter.hasLowerValue.append(float(df_limit['cor.mean'][1]))\n",
    "    corParameter.hasUpperValue.append(float(df_limit['cor.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    corParameter.hasQuality.append(m)\n",
    "    corParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['cor.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['cor.mean'][1]))\n",
    "\n",
    "    covParameter = mtl.CovarianceParameter()\n",
    "    mtla.hasParameter.append(covParameter)\n",
    "    covParameter.hasLowerValue.append(float(df_limit['cov.mean'][1]))\n",
    "    covParameter.hasUpperValue.append(float(df_limit['cov.mean'][1]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    covParameter.hasQuality.append(m)\n",
    "    covParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['cov.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['cov.mean'][1]))\n",
    "        \n",
    "    eValuesParameter = mtl.EigenValuesParameter()\n",
    "    mtla.hasParameter.append(eValuesParameter)\n",
    "    eValuesParameter.hasLowerValue.append(float(df_limit['eigenvalues.mean'][1]))\n",
    "    eValuesParameter.hasUpperValue.append(float(df_limit['eigenvalues.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    eValuesParameter.hasQuality.append(m)\n",
    "    eValuesParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['eigenvalues.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['eigenvalues.mean'][1]))\n",
    "\n",
    "    gMeanParameter = mtl.GeometricMeanParameter()\n",
    "    mtla.hasParameter.append(gMeanParameter)\n",
    "    gMeanParameter.hasLowerValue.append(float(df_limit['g_mean.mean'][1]))\n",
    "    gMeanParameter.hasUpperValue.append(float(df_limit['g_mean.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    gMeanParameter.hasQuality.append(m)\n",
    "    gMeanParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['g_mean.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['g_mean.mean'][1]))\n",
    "\n",
    "    hMeanParameter = mtl.HarmonicMeanParameter()\n",
    "    mtla.hasParameter.append(hMeanParameter)\n",
    "    hMeanParameter.hasLowerValue.append(float(df_limit['h_mean.mean'][1]))\n",
    "    hMeanParameter.hasUpperValue.append(float(df_limit['h_mean.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    hMeanParameter.hasQuality.append(m)\n",
    "    hMeanParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['h_mean.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['h_mean.mean'][1]))\n",
    "\n",
    "    iqRangeParameter = mtl.InterquartileRangeParameter()\n",
    "    mtla.hasParameter.append(iqRangeParameter)\n",
    "    iqRangeParameter.hasLowerValue.append(float(df_limit['iq_range.mean'][1]))\n",
    "    iqRangeParameter.hasUpperValue.append(float(df_limit['iq_range.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    iqRangeParameter.hasQuality.append(m)\n",
    "    iqRangeParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['iq_range.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['iq_range.mean'][1]))\n",
    "\n",
    "    kurtParameter = mtl.KurtosisParameter()\n",
    "    mtla.hasParameter.append(kurtParameter)\n",
    "    kurtParameter.hasLowerValue.append(float(df_limit['kurtosis.mean'][1]))\n",
    "    kurtParameter.hasUpperValue.append(float(df_limit['kurtosis.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    kurtParameter.hasQuality.append(m)\n",
    "    kurtParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['kurtosis.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['kurtosis.mean'][1]))\n",
    "\n",
    "    madParameter = mtl.MedianAbsoluteDeviationParameter()\n",
    "    mtla.hasParameter.append(madParameter)\n",
    "    madParameter.hasLowerValue.append(float(df_limit['mad.mean'][1]))\n",
    "    madParameter.hasUpperValue.append(float(df_limit['mad.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    madParameter.hasQuality.append(m)\n",
    "    madParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['mad.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['mad.mean'][1]))\n",
    "\n",
    "    maaxParameter = mtl.MaximumOfAttributesParameter()\n",
    "    mtla.hasParameter.append(maaxParameter)\n",
    "    maaxParameter.hasLowerValue.append(float(df_limit['max.mean'][1]))\n",
    "    maaxParameter.hasUpperValue.append(float(df_limit['max.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    maaxParameter.hasQuality.append(m)\n",
    "    maaxParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['max.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['max.mean'][1]))\n",
    "\n",
    "    miinParameter = mtl.MinimumOfAttributesParameter()\n",
    "    mtla.hasParameter.append(miinParameter)\n",
    "    miinParameter.hasLowerValue.append(float(df_limit['min.mean'][1]))\n",
    "    miinParameter.hasUpperValue.append(float(df_limit['min.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    miinParameter.hasQuality.append(m)\n",
    "    miinParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['min.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['min.mean'][1]))\n",
    "    \n",
    "    meanAttrParameter = mtl.MeanOfAttributesParameter()\n",
    "    mtla.hasParameter.append(meanAttrPanumberrameter)\n",
    "    meanAttrParameter.hasLowerValue.append(float(df_limit['mean.mean'][1]))\n",
    "    meanAttrParameter.hasUpperValue.append(float(df_limit['mean.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    meanAttrParameter.hasQuality.append(m)\n",
    "    meanAttrParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['mean.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['mean.mean'][1]))\n",
    "  \n",
    "    medianAttrParameter = mtl.MedianOfAttributesParameter()\n",
    "    mtla.hasParameter.append(medianAttrParameter)\n",
    "    medianAttrParameter.hasLowerValue.append(float(df_limit['median.mean'][1]))\n",
    "    medianAttrParameter.hasUpperValue.append(float(df_limit['median.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    medianAttrParameter.hasQuality.append(m)\n",
    "    medianAttrParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['median.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['median.mean'][1]))\n",
    "  \n",
    "    ranngeParameter = mtl.RangeParameter()\n",
    "    mtla.hasParameter.append(ranngeParameter)\n",
    "    ranngeParameter.hasLowerValue.append(float(df_limit['range.mean'][1]))\n",
    "    ranngeParameter.hasUpperValue.append(float(df_limit['range.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    ranngeParameter.hasQuality.append(m)\n",
    "    ranngeParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['range.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['range.mean'][1]))\n",
    "    \n",
    "    sdParameter = mtl.StdDevOfAttributesParameter()\n",
    "    mtla.hasParameter.append(sdParameter)\n",
    "    sdParameter.hasLowerValue.append(float(df_limit['sd.mean'][1]))\n",
    "    sdParameter.hasUpperValue.append(float(df_limit['sd.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    sdParameter.hasQuality.append(m)\n",
    "    sdParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['sd.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['sd.mean'][1]))\n",
    "\n",
    "    skewnessParameter = mtl.SkewnessParameter()\n",
    "    mtla.hasParameter.append(skewnessParameter)\n",
    "    skewnessParameter.hasLowerValue.append(float(df_limit['skewness.mean'][1]))\n",
    "    skewnessParameter.hasUpperValue.append(float(df_limit['skewness.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    skewnessParameter.hasQuality.append(m)\n",
    "    skewnessParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['skewness.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['skewness.mean'][1]))\n",
    "        \n",
    "    sparsityParameter = mtl.SparsityParameter()\n",
    "    mtla.hasParameter.append(sparsityParameter)\n",
    "    sparsityParameter.hasLowerValue.append(float(df_limit['sparsity.mean'][1]))\n",
    "    sparsityParameter.hasUpperValue.append(float(df_limit['sparsity.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    sparsityParameter.hasQuality.append(m)\n",
    "    sparsityParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['sparsity.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['sparsity.mean'][1]))\n",
    "      \n",
    "    tMeanParameter = mtl.TrimmedMeanParameter()\n",
    "    mtla.hasParameter.append(tMeanParameter)\n",
    "    tMeanParameter.hasLowerValue.append(float(df_limit['t_mean.mean'][1]))\n",
    "    tMeanParameter.hasUpperValue.append(float(df_limit['t_mean.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    tMeanParameter.hasQuality.append(m)\n",
    "    tMeanParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['t_mean.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['t_mean.mean'][1]))\n",
    "\n",
    "    varAttrParameter = mtl.VarianceParameter()\n",
    "    mtla.hasParameter.append(varAttrParameter)\n",
    "    varAttrParameter.hasLowerValue.append(float(df_limit['var.mean'][1]))\n",
    "    varAttrParameter.hasUpperValue.append(float(df_limit['var.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    varAttrParameter.hasQuality.append(m)\n",
    "    varAttrParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['var.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['var.mean'][1]))    \n",
    "\n",
    "    noCorAttrParameter = mtl.NumberOfHighlyCorrelatedAttributesParameters()\n",
    "    mtla.hasParameter.append(noCorAttrParameter)\n",
    "    noCorAttrParameter.hasLowerValue.append(float(df_limit['nr_cor_attr'][1]))\n",
    "    noCorAttrParameter.hasUpperValue.append(float(df_limit['nr_cor_attr'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    noCorAttrParameter.hasQuality.append(m)\n",
    "    noCorAttrParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['nr_cor_attr'][0]))\n",
    "    std.hasValue.append(float(df_normalised['nr_cor_attr'][1]))\n",
    "\n",
    "    noNorAttrParameter = mtl.NumberOfAttrwithNormalDistributionParameter()\n",
    "    mtla.hasParameter.append(noNorAttrParameter)\n",
    "    noNorAttrParameter.hasLowerValue.append(float(df_limit['nr_norm'][1]))\n",
    "    noNorAttrParameter.hasUpperValue.append(float(df_limit['nr_norm'][3]))\n",
    "\n",
    "    \n",
    "    noOutParameter = mtl.NumberOfOutliersParameter()\n",
    "    mtla.hasParameter.append(noOutParameter)\n",
    "    noOutParameter.hasLowerValue.append(float(df_limit['nr_outliers'][1]))\n",
    "    noOutParameter.hasUpperValue.append(float(df_limit['nr_outliers'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    noOutParameter.hasQuality.append(m)\n",
    "    noOutParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['nr_outliers'][0]))\n",
    "    std.hasValue.append(float(df_normalised['nr_outliers'][1]))    \n",
    "\n",
    "    attrConcParameter = mtl.AttributeConcentrationParameter()\n",
    "    mtla.hasParameter.append(attrConcParameter)\n",
    "    attrConcParameter.hasLowerValue.append(float(df_limit['attr_conc.mean'][1]))\n",
    "    attrConcParameter.hasUpperValue.append(float(df_limit['attr_conc.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    attrConcParameter.hasQuality.append(m)\n",
    "    attrConcParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['attr_conc.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['attr_conc.mean'][1]))\n",
    "\n",
    "    attrEntropyParameter = mtl.AttributesEntropyParameter()\n",
    "    mtla.hasParameter.append(attrEntropyParameter)\n",
    "    attrEntropyParameter.hasLowerValue.append(float(df_limit['attr_ent.mean'][1]))\n",
    "    attrEntropyParameter.hasUpperValue.append(float(df_limit['attr_ent.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    attrEntropyParameter.hasQuality.append(m)\n",
    "    attrEntropyParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['attr_ent.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['attr_ent.mean'][1]))\n",
    " \n",
    "    enaParameter = mtl.EqNumberOfAttributesParameter()\n",
    "    mtla.hasParameter.append(enaParameter)\n",
    "    enaParameter.hasLowerValue.append(float(df_limit['ena'][1]))\n",
    "    enaParameter.hasUpperValue.append(float(df_limit['ena'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    enaParameter.hasQuality.append(m)\n",
    "    enaParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['ena'][0]))\n",
    "    std.hasValue.append(float(df_normalised['ena'][1]))\n",
    "\n",
    "    snrParameter = mtl.NoiseSignalRatioParameter()\n",
    "    mtla.hasParameter.append(snrParameter)\n",
    "    snrParameter.hasLowerValue.append(float(df_limit['snr.mean'][1]))\n",
    "    snrParameter.hasUpperValue.append(float(df_limit['snr.mean'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    snrParameter.hasQuality.append(m)\n",
    "    snrParameter.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['snr.mean'][0]))\n",
    "    std.hasValue.append(float(df_normalised['snr.mean'][1]))\n",
    "\n",
    "    nFeatures = mtl.NumberOfFeaturesParameter()\n",
    "    mtla.hasParameter.append(nFeatures)\n",
    "    nFeatures.hasLowerValue.append(float(df_limit['nr_attr'][1]))\n",
    "    nFeatures.hasUpperValue.append(float(df_limit['nr_attr'][3]))    \n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    nFeatures.hasQuality.append(m)\n",
    "    nFeatures.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['nr_attr'][0]))\n",
    "    std.hasValue.append(float(df_normalised['nr_attr'][1]))\n",
    "\n",
    "    attrToInst = mtl.ProportionOfAttrToInstancesParameter()\n",
    "    mtla.hasParameter.append(attrToInst)\n",
    "    attrToInst.hasLowerValue.append(float(df_limit['attr_to_inst'][1]))\n",
    "    attrToInst.hasUpperValue.append(float(df_limit['attr_to_inst'][3]))\n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    attrToInst.hasQuality.append(m)\n",
    "    attrToInst.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['attr_to_inst'][0]))\n",
    "    std.hasValue.append(float(df_normalised['attr_to_inst'][1]))    \n",
    "\n",
    "    instToAttr = mtl.ProportionOfInstancesPerFeatureParameter()\n",
    "    mtla.hasParameter.append(instToAttr)\n",
    "    instToAttr.hasLowerValue.append(float(df_limit['inst_to_attr'][1]))\n",
    "    instToAttr.hasUpperValue.append(float(df_limit['inst_to_attr'][3]))  \n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    instToAttr.hasQuality.append(m)\n",
    "    instToAttr.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['inst_to_attr'][0]))\n",
    "    std.hasValue.append(float(df_normalised['inst_to_attr'][1]))  \n",
    "\n",
    "    nInstance = mtl.NumberOfInstancesParameter()\n",
    "    mtla.hasParameter.append(nInstance)\n",
    "    nInstance.hasLowerValue.append(float(df_limit['nr_inst'][1]))\n",
    "    nInstance.hasUpperValue.append(float(df_limit['nr_inst'][3]))    \n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    nInstance.hasQuality.append(m)\n",
    "    nInstance.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['nr_inst'][0]))\n",
    "    std.hasValue.append(float(df_normalised['nr_inst'][1]))\n",
    "\n",
    "    nNumeric = mtl.NumberOfNumericAttributesParameter()\n",
    "    mtla.hasParameter.append(nNumeric)\n",
    "    nNumeric.hasLowerValue.append(float(df_limit['nr_num'][1]))\n",
    "    nNumeric.hasUpperValue.append(float(df_limit['nr_num'][3]))    \n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    nNumeric.hasQuality.append(m)\n",
    "    nNumeric.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['nr_num'][0]))\n",
    "    std.hasValue.append(float(df_normalised['nr_num'][1]))\n",
    "\n",
    "    nBinary = mtl.NumberOfBinaryAttributesParameter()\n",
    "    mtla.hasParameter.append(nBinary)\n",
    "    nBinary.hasLowerValue.append(float(df_limit['nr_bin'][1]))\n",
    "    nBinary.hasUpperValue.append(float(df_limit['nr_bin'][3]))    \n",
    "    std = mtl.StdDev()\n",
    "    m = mtl.Mean()\n",
    "    nBinary.hasQuality.append(m)\n",
    "    nBinary.hasQuality.append(std)\n",
    "    m.hasValue.append(float(df_normalised['nr_bin'][0]))\n",
    "    std.hasValue.append(float(df_normalised['nr_bin'][1]))\n",
    "\n",
    "    nClasses = mtl.NumberOfClassesParameter()\n",
    "    mtla.hasParameter.append(nClasses)\n",
    "    nClasses.hasLowerValue.append(float(df_limit['nUnique'][1]))\n",
    "    nClasses.hasUpperValue.append(float(df_limit['nUnique'][3]))  \n",
    "\n",
    "    for i in range(len(df)):\n",
    "        featureSelectionTask = dmop.FeatureSelectionTask()\n",
    "        mtla = mtl.MetaLearningAlgorithm()\n",
    "        fileName = df['File'][i]\n",
    "        fileName = pattern.sub('', fileName)\n",
    "        fileObject = dmop.DataSetClass(fileName)\n",
    "        mtla.hasMetaObjective.append(featureSelectionTask)\n",
    "\n",
    "        featureSelectionTask.specifiesInputClass.append(fileObject)\n",
    "        \n",
    "        outClass =dmop.StructuredPredictionModelClass()\n",
    "        featureSelectionTask.specifiesOutputClass.append(outClass)\n",
    "        outClass.hasValue.append(df['FeatureAlgo'][i])\n",
    "        \n",
    "        #Simple features\n",
    "        nFeatures = dmop1.NumberOfFeatures()\n",
    "        fileObject.hasQuality.append(nFeatures)\n",
    "        nFeatures.hasValue.append(int(df['nr_attr'][i]))\n",
    "        nFeatures.hasBinValue.append(str(df['nr_attr_bins'][i]))\n",
    "\n",
    "        attrToInst = mtl.ProportionOfAttrToInstances()\n",
    "        fileObject.hasQuality.append(attrToInst)\n",
    "        attrToInst.hasValue.append(float(df['attr_to_inst'][i]))\n",
    "        attrToInst.hasBinValue.append(str(df['attr_to_inst_bins'][i]))\n",
    "\n",
    "        instToAttr = dmop1.ProportionOfInstancesPerFeature()\n",
    "        fileObject.hasQuality.append(instToAttr)\n",
    "        instToAttr.hasValue.append(float(df['inst_to_attr'][i]))\n",
    "        instToAttr.hasBinValue.append(str(df['inst_to_attr_bins'][i]))\n",
    "\n",
    "        nInstance = dmop1.NumberOfInstances()\n",
    "        fileObject.hasQuality.append(nInstance)\n",
    "        nInstance.hasValue.append(int(df['nr_inst'][i]))\n",
    "        nInstance.hasBinValue.append(str(df['nr_inst_bins'][i]))\n",
    "\n",
    "        nNumeric = mtl.NumberOfNumericAttributes()\n",
    "        fileObject.hasQuality.append(nNumeric)\n",
    "        nNumeric.hasValue.append(int(df['nr_num'][i]))\n",
    "        nNumeric.hasBinValue.append(str(df['nr_num_bins'][i]))\n",
    "\n",
    "        nBinary = mtl.NumberOfBinaryAttributes()\n",
    "        fileObject.hasQuality.append(nBinary)\n",
    "        nBinary.hasValue.append(int(df['nr_bin'][i]))\n",
    "        nBinary.hasBinValue.append(str(df['nr_bin_bins'][i]))\n",
    "        \n",
    "        nClasses = mtl.NumberOfClasses()\n",
    "        fileObject.hasQuality.append(nClasses)\n",
    "        nClasses.hasValue.append(int(df['nUnique'][i])) #Replace with nUnique\n",
    "        nClasses.hasBinValue.append(str(df['nUnique_bins'][i]))\n",
    "\n",
    "        #Statistical features\n",
    "        corr = mtl.Correlation()\n",
    "        fileObject.hasQuality.append(corr)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        corr.hasQuality.append(m)\n",
    "        corr.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['cor.mean'][i]))\n",
    "        std.hasValue.append(float(df['cor.sd'][i]))\n",
    "        corr.hasBinValue.append(str(df['cor.mean_bins'][i]))\n",
    "        \n",
    "        cov = mtl.Covariance()\n",
    "        fileObject.hasQuality.append(cov)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        cov.hasQuality.append(m)\n",
    "        cov.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['cov.mean'][i]))\n",
    "        std.hasValue.append(float(df['cov.sd'][i]))\n",
    "        cov.hasBinValue.append(str(df['cov.mean_bins'][i]))\n",
    "\n",
    "        eValues = mtl.EigenValues()\n",
    "        fileObject.hasQuality.append(eValues)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        eValues.hasQuality.append(m)\n",
    "        eValues.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['eigenvalues.mean'][i]))\n",
    "        std.hasValue.append(float(df['eigenvalues.sd'][i]))\n",
    "        eValues.hasBinValue.append(str(df['eigenvalues.mean_bins'][i]))\n",
    "\n",
    "        gMean = mtl.GeometricMean()\n",
    "        fileObject.hasQuality.append(gMean)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        gMean.hasQuality.append(m)\n",
    "        gMean.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['g_mean.mean'][i]))\n",
    "        std.hasValue.append(float(df['g_mean.sd'][i]))\n",
    "        gMean.hasBinValue.append(str(df['g_mean.mean_bins'][i]))\n",
    "\n",
    "        hMean = mtl.HarmonicMean()\n",
    "        fileObject.hasQuality.append(hMean)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        hMean.hasQuality.append(m)\n",
    "        hMean.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['h_mean.mean'][i]))\n",
    "        std.hasValue.append(float(df['h_mean.sd'][i]))\n",
    "        hMean.hasBinValue.append(str(df['h_mean.mean_bins'][i]))\n",
    "\n",
    "        iqRange = mtl.InterquartileRange()\n",
    "        fileObject.hasQuality.append(iqRange)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        iqRange.hasQuality.append(m)\n",
    "        iqRange.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['iq_range.mean'][i]))\n",
    "        std.hasValue.append(float(df['iq_range.sd'][i]))\n",
    "        iqRange.hasBinValue.append(str(df['iq_range.mean_bins'][i]))\n",
    "\n",
    "        kurt = mtl.Kurtosis()\n",
    "        fileObject.hasQuality.append(kurt)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        kurt.hasQuality.append(m)\n",
    "        kurt.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['kurtosis.mean'][i]))\n",
    "        std.hasValue.append(float(df['kurtosis.sd'][i]))\n",
    "        kurt.hasBinValue.append(str(df['kurtosis.mean_bins'][i]))\n",
    "\n",
    "        mad = mtl.MedianAbsoluteDeviation()\n",
    "        fileObject.hasQuality.append(mad)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        mad.hasQuality.append(m)\n",
    "        mad.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['mad.mean'][i]))\n",
    "        std.hasValue.append(float(df['mad.sd'][i]))\n",
    "        mad.hasBinValue.append(str(df['mad.mean_bins'][i]))\n",
    "\n",
    "        maax = mtl.MaximumOfAttributes()\n",
    "        fileObject.hasQuality.append(maax)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        maax.hasQuality.append(m)\n",
    "        maax.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['max.mean'][i]))\n",
    "        std.hasValue.append(float(df['max.sd'][i]))\n",
    "        maax.hasBinValue.append(str(df['max.mean_bins'][i]))\n",
    "\n",
    "        miin = mtl.MinimumOfAttributes()\n",
    "        fileObject.hasQuality.append(miin)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        miin.hasQuality.append(m)\n",
    "        miin.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['min.mean'][i]))\n",
    "        std.hasValue.append(float(df['min.sd'][i]))\n",
    "        miin.hasBinValue.append(str(df['min.mean_bins'][i]))\n",
    "\n",
    "        meanAttr = mtl.MeanOfAttributes()\n",
    "        fileObject.hasQuality.append(meanAttr)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        meanAttr.hasQuality.append(m)\n",
    "        meanAttr.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['mean.mean'][i]))\n",
    "        std.hasValue.append(float(df['mean.sd'][i]))\n",
    "        meanAttr.hasBinValue.append(str(df['mean.mean_bins'][i]))\n",
    "\n",
    "        medianAttr = mtl.MedianOfAttributes()\n",
    "        fileObject.hasQuality.append(medianAttr)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        medianAttr.hasQuality.append(m)\n",
    "        medianAttr.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['median.mean'][i]))\n",
    "        std.hasValue.append(float(df['median.sd'][i]))\n",
    "        medianAttr.hasBinValue.append(str(df['median.mean_bins'][i]))\n",
    "\n",
    "        rannge = mtl.Range()\n",
    "        fileObject.hasQuality.append(rannge)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        rannge.hasQuality.append(m)\n",
    "        rannge.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['range.mean'][i]))\n",
    "        std.hasValue.append(float(df['range.sd'][i]))\n",
    "        rannge.hasBinValue.append(str(df['range.mean_bins'][i]))\n",
    "\n",
    "        sd = mtl.StdDevOfAttributes()\n",
    "        fileObject.hasQuality.append(sd)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        sd.hasQuality.append(m)\n",
    "        sd.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['sd.mean'][i]))\n",
    "        std.hasValue.append(float(df['sd.sd'][i]))\n",
    "        sd.hasBinValue.append(str(df['sd.mean_bins'][i]))\n",
    "\n",
    "        skewness = mtl.Skewness()\n",
    "        fileObject.hasQuality.append(skewness)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        skewness.hasQuality.append(m)\n",
    "        skewness.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['skewness.mean'][i]))\n",
    "        std.hasValue.append(float(df['skewness.sd'][i]))\n",
    "        skewness.hasBinValue.append(str(df['skewness.mean_bins'][i]))\n",
    "\n",
    "        sparsity = mtl.Sparsity()\n",
    "        fileObject.hasQuality.append(sparsity)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        sparsity.hasQuality.append(m)\n",
    "        sparsity.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['sparsity.mean'][i]))\n",
    "        std.hasValue.append(float(df['sparsity.sd'][i]))\n",
    "        sparsity.hasBinValue.append(str(df['sparsity.mean_bins'][i]))\n",
    "\n",
    "        tMean = mtl.TrimmedMean()\n",
    "        fileObject.hasQuality.append(tMean)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        tMean.hasQuality.append(m)\n",
    "        tMean.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['t_mean.mean'][i]))\n",
    "        std.hasValue.append(float(df['t_mean.sd'][i]))\n",
    "        tMean.hasBinValue.append(str(df['t_mean.mean_bins'][i]))\n",
    "\n",
    "        varAttr = mtl.Variance()\n",
    "        fileObject.hasQuality.append(varAttr)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        varAttr.hasQuality.append(m)\n",
    "        varAttr.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['var.mean'][i]))\n",
    "        std.hasValue.append(float(df['var.sd'][i]))\n",
    "        varAttr.hasBinValue.append(str(df['var.mean_bins'][i]))\n",
    "\n",
    "        noCorAttr = mtl.NumberOfHighlyCorrelatedAttributes()\n",
    "        fileObject.hasQuality.append(noCorAttr)\n",
    "        noCorAttr.hasValue.append(float(df['nr_cor_attr'][i]))\n",
    "        noCorAttr.hasBinValue.append(str(df['nr_cor_attr_bins'][i]))\n",
    "\n",
    "        noNorAttr = mtl.NumberOfAttrwithNormalDistribution()\n",
    "        fileObject.hasQuality.append(noNorAttr)\n",
    "        noNorAttr.hasValue.append(float(df['nr_norm'][i]))\n",
    "        noNorAttr.hasBinValue.append(str(df['nr_norm_bins'][i]))\n",
    "\n",
    "        noOut = mtl.NumberOfOutliers()\n",
    "        fileObject.hasQuality.append(noOut)\n",
    "        noOut.hasValue.append(float(df['nr_outliers'][i]))\n",
    "        noOut.hasBinValue.append(str(df['nr_outliers_bins'][i]))\n",
    "\n",
    "        #Information-theoretic\n",
    "        attrConc = mtl.AttributeConcentration()\n",
    "        fileObject.hasQuality.append(attrConc)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        attrConc.hasQuality.append(m)\n",
    "        attrConc.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['attr_conc.mean'][i]))\n",
    "        std.hasValue.append(float(df['attr_conc.sd'][i]))\n",
    "        attrConc.hasBinValue.append(str(df['attr_conc.mean_bins'][i]))\n",
    "\n",
    "        attrEntropy = mtl.AttributesEntropy()\n",
    "        fileObject.hasQuality.append(attrEntropy)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        attrEntropy.hasQuality.append(m)\n",
    "        attrEntropy.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['attr_ent.mean'][i]))\n",
    "        std.hasValue.append(float(df['attr_ent.sd'][i]))\n",
    "        attrEntropy.hasBinValue.append(str(df['attr_ent.mean_bins'][i]))\n",
    "\n",
    "        ena = mtl.EqNumberOfAttributes()\n",
    "        fileObject.hasQuality.append(ena)\n",
    "        ena.hasValue.append(float(df['ena'][i]))\n",
    "        ena.hasBinValue.append(str(df['ena_bins'][i]))\n",
    "\n",
    "        cEntropy = mtl.ClassEntropy()\n",
    "        fileObject.hasQuality.append(cEntropy)\n",
    "        cEntropy.hasValue.append(float(df['cEntropy'][i]))\n",
    "        cEntropy.hasBinValue.append(str(df['cEntropy_bins'][i]))\n",
    "\n",
    "        snr = dmop1.NoiseSignalRatio()\n",
    "        fileObject.hasQuality.append(snr)\n",
    "        std = mtl.StdDev()\n",
    "        m = mtl.Mean()\n",
    "        snr.hasQuality.append(m)\n",
    "        snr.hasQuality.append(std)\n",
    "        m.hasValue.append(float(df['snr.mean'][i]))\n",
    "        std.hasValue.append(float(df['snr.sd'][i]))\n",
    "        snr.hasBinValue.append(str(df['snr.mean_bins'][i]))\n",
    "\n",
    "        #ML-metrics\n",
    "        classImbalance = mtl.ClassImbalance()\n",
    "        fileObject.hasQuality.append(classImbalance)\n",
    "        classImbalance.hasValue.append(float(df['ClassImbRatio'][i]))\n",
    "        classImbalance.hasBinValue.append(str(df['ClassImbRatio_bins'][i]))\n",
    "        allValues = ast.literal_eval(df['ClassImbPoints'][i])\n",
    "        if(len(allValues) >= 1):\n",
    "            rootCause = mtl.ClassImbalanceRootcause()\n",
    "            fileObject.hasRootCause.append(rootCause)\n",
    "            for item in allValues:\n",
    "                rootCause.hasValue.append(int(item))\n",
    "\n",
    "        classOverlap = mtl.ClassOverlap()\n",
    "        fileObject.hasQuality.append(classOverlap)\n",
    "        classOverlap.hasValue.append(float(df['ClassOverlapPerc'][i]))\n",
    "        classOverlap.hasBinValue.append(str(df['ClassOverlapPerc_bins'][i]))\n",
    "        allValues = ast.literal_eval(df['ClassOverlapPoints'][i])\n",
    "        if(len(allValues) >= 1):\n",
    "            rootCause = mtl.ClassOverlapRootcause()\n",
    "            fileObject.hasRootCause.append(rootCause)\n",
    "            for item in allValues:\n",
    "                rootCause.hasValue.append(int(item))\n",
    "\n",
    "        outliersPerc = mtl.OutlierDetection()\n",
    "        fileObject.hasQuality.append(outliersPerc)\n",
    "        outliersPerc.hasValue.append(float(df['OutlierPerc'][i]))\n",
    "        outliersPerc.hasBinValue.append(str(df['OutlierPerc_bins'][i]))\n",
    "        allValues = ast.literal_eval(df['OutlierPoints'][i])\n",
    "        if(len(allValues) >= 1):\n",
    "            rootCause = mtl.OutliersRootcause()\n",
    "            fileObject.hasRootCause.append(rootCause)\n",
    "            for item in allValues:\n",
    "                rootCause.hasValue.append(int(item))\n",
    "\n",
    "        labelIssues = mtl.LabelNoise()\n",
    "        fileObject.hasQuality.append(labelIssues)\n",
    "        labelIssues.hasValue.append(float(df['LabelIssuesPerc'][i]))\n",
    "        labelIssues.hasBinValue.append(str(df['LabelIssues_bins'][i]))\n",
    "        allValues = ast.literal_eval(df['LabelIssues'][i])\n",
    "        if(len(allValues) >= 1):\n",
    "            rootCause = mtl.LabelNoiseRootcause()\n",
    "            fileObject.hasRootCause.append(rootCause)\n",
    "            for item in allValues:\n",
    "                rootCause.hasValue.append(int(item))\n",
    "\n",
    "        #Intrinsic\n",
    "        completeness = mtl.Completeness()\n",
    "        fileObject.hasQuality.append(completeness)\n",
    "        completeness.hasValue.append(float(df['Completeness'][i]))\n",
    "        completeness.hasBinValue.append(str(df['Completeness_bins'][i]))\n",
    "        allValues = ast.literal_eval(df['MissColumns'][i])\n",
    "        if(len(allValues) >= 1):\n",
    "            rootCause = mtl.CompletenessRootcause()\n",
    "            fileObject.hasRootCause.append(rootCause)\n",
    "            for item in allValues:\n",
    "                if(type(item)==int):\n",
    "                    rootCause.hasValue.append(int(item))\n",
    "                else:\n",
    "                    rootCause.hasValue.append(str(item))\n",
    "\n",
    "        conciseness = mtl.Conciseness()\n",
    "        fileObject.hasQuality.append(conciseness)\n",
    "        conciseness.hasValue.append(float(df['Conciseness'][i]))\n",
    "        conciseness.hasBinValue.append(str(df['Conciseness_bins'][i]))\n",
    "       \n",
    "        sAccuracy = mtl.SyntaxAccuracy()\n",
    "        fileObject.hasQuality.append(sAccuracy)\n",
    "        sAccuracy.hasValue.append(float(df['SyntaxAccuracy'][i]))\n",
    "        allValues = ast.literal_eval(df['InvalidColumns'][i])\n",
    "        if(len(allValues) >= 1):\n",
    "            rootCause = mtl.SyntaxAccuracyRootcause()\n",
    "            fileObject.hasRootCause.append(rootCause)\n",
    "            for item in allValues:\n",
    "                rootCause.hasValue.append(int(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Running Pellet...\n",
      "    /usr/lib/jvm/java-17-openjdk-amd64/bin/java -Xmx2000M -cp /home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/xercesImpl-2.10.0.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jgrapht-jdk1.5.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jcl-over-slf4j-1.6.4.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/xml-apis-1.4.01.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/httpclient-4.2.3.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/commons-codec-1.6.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/antlr-3.2.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jena-core-2.10.0.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jena-arq-2.10.0.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/httpcore-4.2.2.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/slf4j-api-1.6.4.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/log4j-1.2.16.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jena-tdb-0.10.0.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/antlr-runtime-3.2.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/jena-iri-0.9.5.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/owlapi-distribution-3.4.3-bin.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/pellet-2.3.1.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/aterm-java-1.6.jar:/home/d19125691/.local/lib/python3.6/site-packages/owlready2/pellet/slf4j-log4j12-1.6.4.jar pellet.Pellet realize --loader Jena --input-format N-Triples --infer-data-prop-values --ignore-imports /tmp/tmppia2ahj4\n",
      "* Owlready2 * Pellet took 1.8614816665649414 seconds\n",
      "* Owlready * Reparenting DMOP.NoiseSignalRatio: {DMOP.DataSetCharacteristic} => {DMOP.DataCharacteristic}\n",
      "* Owlready * Reparenting MtLv2.noisesignalratio1: {DMOP.NoiseSignalRatio} => {DOLCE-Lite.region, DMOP.NoiseSignalRatio}\n",
      "* Owlready * Reparenting MtLv2.noisesignalratio2: {DMOP.NoiseSignalRatio} => {DOLCE-Lite.region, DMOP.NoiseSignalRatio}\n",
      "* Owlready * Reparenting DMOP.NumberOfFeatures: {DMOP.DataSetCharacteristic} => {DMOP.DataCharacteristic}\n",
      "* Owlready * Reparenting MtLv2.numberoffeatures1: {DMOP.NumberOfFeatures} => {DMOP.NumberOfFeatures, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.numberoffeatures2: {DMOP.NumberOfFeatures} => {DMOP.NumberOfFeatures, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting DMOP.NumberOfInstances: {DMOP.DataSetCharacteristic} => {DMOP.DataCharacteristic}\n",
      "* Owlready * Reparenting MtLv2.numberofinstances1: {DMOP.NumberOfInstances} => {DOLCE-Lite.region, DMOP.NumberOfInstances}\n",
      "* Owlready * Reparenting MtLv2.numberofinstances2: {DMOP.NumberOfInstances} => {DOLCE-Lite.region, DMOP.NumberOfInstances}\n",
      "* Owlready * Reparenting MtLv2.proportionofinstancesperfeature1: {DMOP.ProportionOfInstancesPerFeature} => {DOLCE-Lite.region, DMOP.ProportionOfInstancesPerFeature}\n",
      "* Owlready * Reparenting MtLv2.proportionofinstancesperfeature2: {DMOP.ProportionOfInstancesPerFeature} => {DOLCE-Lite.region, DMOP.ProportionOfInstancesPerFeature}\n",
      "* Owlready * Reparenting MtLv2.attributeconcentration1: {MtLv2.AttributeConcentration} => {DOLCE-Lite.region, MtLv2.AttributeConcentration}\n",
      "* Owlready * Reparenting MtLv2.attributeconcentration2: {MtLv2.AttributeConcentration} => {DOLCE-Lite.region, MtLv2.AttributeConcentration}\n",
      "* Owlready * Reparenting MtLv2.attributesentropy1: {MtLv2.AttributesEntropy} => {DOLCE-Lite.region, MtLv2.AttributesEntropy}\n",
      "* Owlready * Reparenting MtLv2.attributesentropy2: {MtLv2.AttributesEntropy} => {DOLCE-Lite.region, MtLv2.AttributesEntropy}\n",
      "* Owlready * Reparenting MtLv2.classentropy1: {MtLv2.ClassEntropy} => {MtLv2.ClassEntropy, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.classentropy2: {MtLv2.ClassEntropy} => {MtLv2.ClassEntropy, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.correlation1: {MtLv2.Correlation} => {DOLCE-Lite.region, MtLv2.Correlation}\n",
      "* Owlready * Reparenting MtLv2.correlation2: {MtLv2.Correlation} => {DOLCE-Lite.region, MtLv2.Correlation}\n",
      "* Owlready * Reparenting MtLv2.covariance1: {MtLv2.Covariance} => {DOLCE-Lite.region, MtLv2.Covariance}\n",
      "* Owlready * Reparenting MtLv2.covariance2: {MtLv2.Covariance} => {DOLCE-Lite.region, MtLv2.Covariance}\n",
      "* Owlready * Reparenting MtLv2.classimbalance1: {MtLv2.ClassImbalance} => {DOLCE-Lite.region, MtLv2.ClassImbalance}\n",
      "* Owlready * Reparenting MtLv2.classimbalance2: {MtLv2.ClassImbalance} => {DOLCE-Lite.region, MtLv2.ClassImbalance}\n",
      "* Owlready * Reparenting MtLv2.classoverlap1: {MtLv2.ClassOverlap} => {MtLv2.ClassOverlap, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.classoverlap2: {MtLv2.ClassOverlap} => {MtLv2.ClassOverlap, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.completeness2: {MtLv2.Completeness} => {DOLCE-Lite.region, MtLv2.Completeness}\n",
      "* Owlready * Reparenting MtLv2.completeness1: {MtLv2.Completeness} => {DOLCE-Lite.region, MtLv2.Completeness}\n",
      "* Owlready * Reparenting MtLv2.conciseness1: {MtLv2.Conciseness} => {MtLv2.Conciseness, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.conciseness2: {MtLv2.Conciseness} => {MtLv2.Conciseness, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.labelnoise2: {MtLv2.LabelNoise} => {MtLv2.LabelNoise, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.labelnoise1: {MtLv2.LabelNoise} => {MtLv2.LabelNoise, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.outlierdetection2: {MtLv2.OutlierDetection} => {DOLCE-Lite.region, MtLv2.OutlierDetection}\n",
      "* Owlready * Reparenting MtLv2.outlierdetection1: {MtLv2.OutlierDetection} => {DOLCE-Lite.region, MtLv2.OutlierDetection}\n",
      "* Owlready * Reparenting MtLv2.syntaxaccuracy1: {MtLv2.SyntaxAccuracy} => {DOLCE-Lite.region, MtLv2.SyntaxAccuracy}\n",
      "* Owlready * Reparenting MtLv2.syntaxaccuracy2: {MtLv2.SyntaxAccuracy} => {DOLCE-Lite.region, MtLv2.SyntaxAccuracy}\n",
      "* Owlready * Reparenting MtLv2.eigenvalues1: {MtLv2.EigenValues} => {DOLCE-Lite.region, MtLv2.EigenValues}\n",
      "* Owlready * Reparenting MtLv2.eigenvalues2: {MtLv2.EigenValues} => {DOLCE-Lite.region, MtLv2.EigenValues}\n",
      "* Owlready * Reparenting MtLv2.eqnumberofattributes2: {MtLv2.EqNumberOfAttributes} => {DOLCE-Lite.region, MtLv2.EqNumberOfAttributes}\n",
      "* Owlready * Reparenting MtLv2.eqnumberofattributes1: {MtLv2.EqNumberOfAttributes} => {DOLCE-Lite.region, MtLv2.EqNumberOfAttributes}\n",
      "* Owlready * Reparenting MtLv2.geometricmean1: {MtLv2.GeometricMean} => {DOLCE-Lite.region, MtLv2.GeometricMean}\n",
      "* Owlready * Reparenting MtLv2.geometricmean2: {MtLv2.GeometricMean} => {DOLCE-Lite.region, MtLv2.GeometricMean}\n",
      "* Owlready * Reparenting MtLv2.harmonicmean1: {MtLv2.HarmonicMean} => {DOLCE-Lite.region, MtLv2.HarmonicMean}\n",
      "* Owlready * Reparenting MtLv2.harmonicmean2: {MtLv2.HarmonicMean} => {DOLCE-Lite.region, MtLv2.HarmonicMean}\n",
      "* Owlready * Reparenting MtLv2.interquartilerange1: {MtLv2.InterquartileRange} => {DOLCE-Lite.region, MtLv2.InterquartileRange}\n",
      "* Owlready * Reparenting MtLv2.interquartilerange2: {MtLv2.InterquartileRange} => {DOLCE-Lite.region, MtLv2.InterquartileRange}\n",
      "* Owlready * Reparenting MtLv2.kurtosis1: {MtLv2.Kurtosis} => {DOLCE-Lite.region, MtLv2.Kurtosis}\n",
      "* Owlready * Reparenting MtLv2.kurtosis2: {MtLv2.Kurtosis} => {DOLCE-Lite.region, MtLv2.Kurtosis}\n",
      "* Owlready * Reparenting MtLv2.maximumofattributes1: {MtLv2.MaximumOfAttributes} => {DOLCE-Lite.region, MtLv2.MaximumOfAttributes}\n",
      "* Owlready * Reparenting MtLv2.maximumofattributes2: {MtLv2.MaximumOfAttributes} => {DOLCE-Lite.region, MtLv2.MaximumOfAttributes}\n",
      "* Owlready * Reparenting MtLv2.meanofattributes2: {MtLv2.MeanOfAttributes} => {DOLCE-Lite.region, MtLv2.MeanOfAttributes}\n",
      "* Owlready * Reparenting MtLv2.meanofattributes1: {MtLv2.MeanOfAttributes} => {DOLCE-Lite.region, MtLv2.MeanOfAttributes}\n",
      "* Owlready * Reparenting MtLv2.medianabsolutedeviation1: {MtLv2.MedianAbsoluteDeviation} => {DOLCE-Lite.region, MtLv2.MedianAbsoluteDeviation}\n",
      "* Owlready * Reparenting MtLv2.medianabsolutedeviation2: {MtLv2.MedianAbsoluteDeviation} => {DOLCE-Lite.region, MtLv2.MedianAbsoluteDeviation}\n",
      "* Owlready * Reparenting MtLv2.medianofattributes1: {MtLv2.MedianOfAttributes} => {DOLCE-Lite.region, MtLv2.MedianOfAttributes}\n",
      "* Owlready * Reparenting MtLv2.medianofattributes2: {MtLv2.MedianOfAttributes} => {DOLCE-Lite.region, MtLv2.MedianOfAttributes}\n",
      "* Owlready * Reparenting MtLv2.minimumofattributes2: {MtLv2.MinimumOfAttributes} => {DOLCE-Lite.region, MtLv2.MinimumOfAttributes}\n",
      "* Owlready * Reparenting MtLv2.minimumofattributes1: {MtLv2.MinimumOfAttributes} => {DOLCE-Lite.region, MtLv2.MinimumOfAttributes}\n",
      "* Owlready * Reparenting MtLv2.numberofattrwithnormaldistribution1: {MtLv2.NumberOfAttrwithNormalDistribution} => {DOLCE-Lite.region, MtLv2.NumberOfAttrwithNormalDistribution}\n",
      "* Owlready * Reparenting MtLv2.numberofattrwithnormaldistribution2: {MtLv2.NumberOfAttrwithNormalDistribution} => {DOLCE-Lite.region, MtLv2.NumberOfAttrwithNormalDistribution}\n",
      "* Owlready * Reparenting MtLv2.numberofbinaryattributes1: {MtLv2.NumberOfBinaryAttributes} => {DOLCE-Lite.region, MtLv2.NumberOfBinaryAttributes}\n",
      "* Owlready * Reparenting MtLv2.numberofbinaryattributes2: {MtLv2.NumberOfBinaryAttributes} => {DOLCE-Lite.region, MtLv2.NumberOfBinaryAttributes}\n",
      "* Owlready * Reparenting MtLv2.numberofclasses2: {MtLv2.NumberOfClasses} => {DOLCE-Lite.region, MtLv2.NumberOfClasses}\n",
      "* Owlready * Reparenting MtLv2.numberofclasses1: {MtLv2.NumberOfClasses} => {DOLCE-Lite.region, MtLv2.NumberOfClasses}\n",
      "* Owlready * Reparenting MtLv2.numberofhighlycorrelatedattributes2: {MtLv2.NumberOfHighlyCorrelatedAttributes} => {DOLCE-Lite.region, MtLv2.NumberOfHighlyCorrelatedAttributes}\n",
      "* Owlready * Reparenting MtLv2.numberofhighlycorrelatedattributes1: {MtLv2.NumberOfHighlyCorrelatedAttributes} => {DOLCE-Lite.region, MtLv2.NumberOfHighlyCorrelatedAttributes}\n",
      "* Owlready * Reparenting MtLv2.numberofnumericattributes1: {MtLv2.NumberOfNumericAttributes} => {MtLv2.NumberOfNumericAttributes, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.numberofnumericattributes2: {MtLv2.NumberOfNumericAttributes} => {MtLv2.NumberOfNumericAttributes, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.numberofoutliers1: {MtLv2.NumberOfOutliers} => {MtLv2.NumberOfOutliers, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.numberofoutliers2: {MtLv2.NumberOfOutliers} => {MtLv2.NumberOfOutliers, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.proportionofattrtoinstances1: {MtLv2.ProportionOfAttrToInstances} => {DOLCE-Lite.region, MtLv2.ProportionOfAttrToInstances}\n",
      "* Owlready * Reparenting MtLv2.proportionofattrtoinstances2: {MtLv2.ProportionOfAttrToInstances} => {DOLCE-Lite.region, MtLv2.ProportionOfAttrToInstances}\n",
      "* Owlready * Reparenting MtLv2.range1: {MtLv2.Range} => {DOLCE-Lite.region, MtLv2.Range}\n",
      "* Owlready * Reparenting MtLv2.range2: {MtLv2.Range} => {DOLCE-Lite.region, MtLv2.Range}\n",
      "* Owlready * Reparenting MtLv2.skewness1: {MtLv2.Skewness} => {MtLv2.Skewness, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.skewness2: {MtLv2.Skewness} => {MtLv2.Skewness, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.sparsity2: {MtLv2.Sparsity} => {DOLCE-Lite.region, MtLv2.Sparsity}\n",
      "* Owlready * Reparenting MtLv2.sparsity1: {MtLv2.Sparsity} => {DOLCE-Lite.region, MtLv2.Sparsity}\n",
      "* Owlready * Reparenting MtLv2.stddevofattributes2: {MtLv2.StdDevOfAttributes} => {DOLCE-Lite.region, MtLv2.StdDevOfAttributes}\n",
      "* Owlready * Reparenting MtLv2.stddevofattributes1: {MtLv2.StdDevOfAttributes} => {DOLCE-Lite.region, MtLv2.StdDevOfAttributes}\n",
      "* Owlready * Reparenting MtLv2.trimmedmean2: {MtLv2.TrimmedMean} => {DOLCE-Lite.region, MtLv2.TrimmedMean}\n",
      "* Owlready * Reparenting MtLv2.trimmedmean1: {MtLv2.TrimmedMean} => {DOLCE-Lite.region, MtLv2.TrimmedMean}\n",
      "* Owlready * Reparenting MtLv2.variance1: {MtLv2.Variance} => {DOLCE-Lite.region, MtLv2.Variance}\n",
      "* Owlready * Reparenting MtLv2.variance2: {MtLv2.Variance} => {DOLCE-Lite.region, MtLv2.Variance}\n",
      "* Owlready * Reparenting MtLv2.attributeconcentrationparameter1: {MtLv2.AttributeConcentrationParameter} => {DOLCE-Lite.region, MtLv2.AttributeConcentrationParameter}\n",
      "* Owlready * Reparenting MtLv2.attributesentropyparameter1: {MtLv2.AttributesEntropyParameter} => {DOLCE-Lite.region, MtLv2.AttributesEntropyParameter}\n",
      "* Owlready * Reparenting MtLv2.correlationparameter1: {MtLv2.CorrelationParameter} => {DOLCE-Lite.region, MtLv2.CorrelationParameter}\n",
      "* Owlready * Reparenting MtLv2.covarianceparameter1: {MtLv2.CovarianceParameter} => {DOLCE-Lite.region, MtLv2.CovarianceParameter}\n",
      "* Owlready * Reparenting MtLv2.eigenvaluesparameter1: {MtLv2.EigenValuesParameter} => {MtLv2.EigenValuesParameter, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.eqnumberofattributesparameter1: {MtLv2.EqNumberOfAttributesParameter} => {MtLv2.EqNumberOfAttributesParameter, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.geometricmeanparameter1: {MtLv2.GeometricMeanParameter} => {MtLv2.GeometricMeanParameter, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.harmonicmeanparameter1: {MtLv2.HarmonicMeanParameter} => {DOLCE-Lite.region, MtLv2.HarmonicMeanParameter}\n",
      "* Owlready * Reparenting MtLv2.interquartilerangeparameter1: {MtLv2.InterquartileRangeParameter} => {DOLCE-Lite.region, MtLv2.InterquartileRangeParameter}\n",
      "* Owlready * Reparenting MtLv2.kurtosisparameter1: {MtLv2.KurtosisParameter} => {DOLCE-Lite.region, MtLv2.KurtosisParameter}\n",
      "* Owlready * Reparenting MtLv2.maximumofattributesparameter1: {MtLv2.MaximumOfAttributesParameter} => {MtLv2.MaximumOfAttributesParameter, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.meanofattributesparameter1: {MtLv2.MeanOfAttributesParameter} => {DOLCE-Lite.region, MtLv2.MeanOfAttributesParameter}\n",
      "* Owlready * Reparenting MtLv2.medianabsolutedeviationparameter1: {MtLv2.MedianAbsoluteDeviationParameter} => {DOLCE-Lite.region, MtLv2.MedianAbsoluteDeviationParameter}\n",
      "* Owlready * Reparenting MtLv2.medianofattributesparameter1: {MtLv2.MedianOfAttributesParameter} => {MtLv2.MedianOfAttributesParameter, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.minimumofattributesparameter1: {MtLv2.MinimumOfAttributesParameter} => {DOLCE-Lite.region, MtLv2.MinimumOfAttributesParameter}\n",
      "* Owlready * Reparenting MtLv2.noisesignalratioparameter1: {MtLv2.NoiseSignalRatioParameter} => {DOLCE-Lite.region, MtLv2.NoiseSignalRatioParameter}\n",
      "* Owlready * Reparenting MtLv2.numberofattrwithnormaldistributionparameter1: {MtLv2.NumberOfAttrwithNormalDistributionParameter} => {DOLCE-Lite.region, MtLv2.NumberOfAttrwithNormalDistributionParameter}\n",
      "* Owlready * Reparenting MtLv2.numberofbinaryattributesparameter1: {MtLv2.NumberOfBinaryAttributesParameter} => {DOLCE-Lite.region, MtLv2.NumberOfBinaryAttributesParameter}\n",
      "* Owlready * Reparenting MtLv2.numberofclassesparameter1: {MtLv2.NumberOfClassesParameter} => {MtLv2.NumberOfClassesParameter, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.numberoffeaturesparameter1: {MtLv2.NumberOfFeaturesParameter} => {MtLv2.NumberOfFeaturesParameter, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.numberofhighlycorrelatedattributesparameters1: {MtLv2.NumberOfHighlyCorrelatedAttributesParameters} => {DOLCE-Lite.region, MtLv2.NumberOfHighlyCorrelatedAttributesParameters}\n",
      "* Owlready * Reparenting MtLv2.numberofinstancesparameter1: {MtLv2.NumberOfInstancesParameter} => {DOLCE-Lite.region, MtLv2.NumberOfInstancesParameter}\n",
      "* Owlready * Reparenting MtLv2.numberofnumericattributesparameter1: {MtLv2.NumberOfNumericAttributesParameter} => {DOLCE-Lite.region, MtLv2.NumberOfNumericAttributesParameter}\n",
      "* Owlready * Reparenting MtLv2.numberofoutliersparameter1: {MtLv2.NumberOfOutliersParameter} => {MtLv2.NumberOfOutliersParameter, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.proportionofattrtoinstancesparameter1: {MtLv2.ProportionOfAttrToInstancesParameter} => {DOLCE-Lite.region, MtLv2.ProportionOfAttrToInstancesParameter}\n",
      "* Owlready * Reparenting MtLv2.proportionofinstancesperfeatureparameter1: {MtLv2.ProportionOfInstancesPerFeatureParameter} => {DOLCE-Lite.region, MtLv2.ProportionOfInstancesPerFeatureParameter}\n",
      "* Owlready * Reparenting MtLv2.rangeparameter1: {MtLv2.RangeParameter} => {MtLv2.RangeParameter, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.skewnessparameter1: {MtLv2.SkewnessParameter} => {DOLCE-Lite.region, MtLv2.SkewnessParameter}\n",
      "* Owlready * Reparenting MtLv2.sparsityparameter1: {MtLv2.SparsityParameter} => {DOLCE-Lite.region, MtLv2.SparsityParameter}\n",
      "* Owlready * Reparenting MtLv2.stddevofattributesparameter1: {MtLv2.StdDevOfAttributesParameter} => {DOLCE-Lite.region, MtLv2.StdDevOfAttributesParameter}\n",
      "* Owlready * Reparenting MtLv2.trimmedmeanparameter1: {MtLv2.TrimmedMeanParameter} => {MtLv2.TrimmedMeanParameter, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.varianceparameter1: {MtLv2.VarianceParameter} => {DOLCE-Lite.region, MtLv2.VarianceParameter}\n",
      "* Owlready * Reparenting MtLv2.structuredpredictionmodelclass1: {DMOP.StructuredPredictionModelClass} => {DMOP.StructuredPredictionModelClass, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.structuredpredictionmodelclass2: {DMOP.StructuredPredictionModelClass} => {DMOP.StructuredPredictionModelClass, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.classimbalancerootcause1: {MtLv2.ClassImbalanceRootcause} => {DOLCE-Lite.region, MtLv2.ClassImbalanceRootcause}\n",
      "* Owlready * Reparenting MtLv2.classoverlaprootcause1: {MtLv2.ClassOverlapRootcause} => {DOLCE-Lite.region, MtLv2.ClassOverlapRootcause}\n",
      "* Owlready * Reparenting MtLv2.completenessrootcause2: {MtLv2.CompletenessRootcause} => {MtLv2.CompletenessRootcause, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.completenessrootcause1: {MtLv2.CompletenessRootcause} => {MtLv2.CompletenessRootcause, DOLCE-Lite.region}\n",
      "* Owlready * Reparenting MtLv2.outliersrootcause1: {MtLv2.OutliersRootcause} => {MtLv2.OutliersRootcause, DOLCE-Lite.region}\n",
      "* Owlready * (NB: only changes on entities loaded in Python are shown, other changes are done but not listed)\n"
     ]
    }
   ],
   "source": [
    "sync_reasoner_pellet([onto], infer_data_property_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with onto:\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50),  InterquartileRange(?iqr), Mean(?m2), hasQuality(?fileObject, ?iqr), hasQuality(?m2, ?iqr), hasValue(?m2, ?iqrvalue), lessThanOrEqual (?iqrvalue, 310.88), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.41), Correlation(?corr), Mean(?m1), hasQuality(?fileObject, ?corr), hasQuality(?m1, ?corr), hasValue(?m1, ?corvalue),   lessThanOrEqual(?corvalue, 0.24)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50),  InterquartileRange(?iqr), Mean(?m2), hasQuality(?fileObject, ?iqr), hasQuality(?m2, ?iqr), hasValue(?m2, ?iqrvalue), lessThanOrEqual (?iqrvalue, 310.88), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.41), Correlation(?corr), Mean(?m1), hasQuality(?fileObject, ?corr), hasQuality(?m1, ?corr), hasValue(?m1, ?corvalue),   greaterThan(?corvalue, 0.24)  -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50),  InterquartileRange(?iqr), Mean(?m2), hasQuality(?fileObject, ?iqr), hasQuality(?m2, ?iqr), hasValue(?m2, ?iqrvalue), lessThanOrEqual (?iqrvalue, 310.88), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.95), greaterThan(?ce, 0.41), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), lessThanOrEqual (?pifvalue, 0.36), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), lessThanOrEqual (?paivalue, 8.72), LabelNoise(?lNoise), hasQuality(?fileObject, ?lNoise), hasValue(?lNoise, ?lNoisevalue), lessThanOrEqual (?lNoisevalue, 0.02)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50),  InterquartileRange(?iqr), Mean(?m2), hasQuality(?fileObject, ?iqr), hasQuality(?m2, ?iqr), hasValue(?m2, ?iqrvalue), lessThanOrEqual (?iqrvalue, 310.88), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.95), greaterThan(?ce, 0.41), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), lessThanOrEqual (?pifvalue, 0.36), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), lessThanOrEqual (?paivalue, 8.72), LabelNoise(?lNoise), hasQuality(?fileObject, ?lNoise), hasValue(?lNoise, ?lNoisevalue), greaterThan (?lNoisevalue, 0.02)  -> hasValue(?outClass, 'GR')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50),  InterquartileRange(?iqr), Mean(?m2), hasQuality(?fileObject, ?iqr), hasQuality(?m2, ?iqr), hasValue(?m2, ?iqrvalue), lessThanOrEqual (?iqrvalue, 310.88), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.95), greaterThan(?ce, 0.41), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), lessThanOrEqual (?pifvalue, 0.01), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), greaterThan (?paivalue, 8.72)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50),  InterquartileRange(?iqr), Mean(?m2), hasQuality(?fileObject, ?iqr), hasQuality(?m2, ?iqr), hasValue(?m2, ?iqrvalue), lessThanOrEqual (?iqrvalue, 310.88), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.95), greaterThan(?ce, 0.41), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), greaterThan (?pifvalue, 0.01), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), greaterThan (?paivalue, 8.72), EqNumberOfAttributesParameter(?ena), hasQuality(?fileObject, ?ena), hasValue(?ena, ?enavalue), lessThanOrEqual(?enavalue, -40.54)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50),  InterquartileRange(?iqr), Mean(?m2), hasQuality(?fileObject, ?iqr), hasQuality(?m2, ?iqr), hasValue(?m2, ?iqrvalue), lessThanOrEqual (?iqrvalue, 310.88), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.95), greaterThan(?ce, 0.41), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), greaterThan (?pifvalue, 0.01), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), greaterThan (?paivalue, 8.72), EqNumberOfAttributesParameter(?ena), hasQuality(?fileObject, ?ena), hasValue(?ena, ?enavalue), greaterThan(?enavalue, -40.54), OutlierDetection(?out), hasQuality(?fileObject, ?out), hasValue(?out, ?outvalue), lessThanOrEqual(?outvalue, 0.03), Kurtosis(?kurt), hasQuality(?fileObject, ?kurt), Mean(?m3), hasQuality(?kurt, ?m3), hasValue(?m3, ?kurtvalue), lessThanOrEqual(?kurtvalue, 33.11)  -> hasValue(?outClass, 'GR')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50),  InterquartileRange(?iqr), Mean(?m2), hasQuality(?fileObject, ?iqr), hasQuality(?m2, ?iqr), hasValue(?m2, ?iqrvalue), lessThanOrEqual (?iqrvalue, 310.88), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.95), greaterThan(?ce, 0.41), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), greaterThan (?pifvalue, 0.01), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), greaterThan (?paivalue, 8.72), EqNumberOfAttributesParameter(?ena), hasQuality(?fileObject, ?ena), hasValue(?ena, ?enavalue), greaterThan(?enavalue, -40.54), OutlierDetection(?out), hasQuality(?fileObject, ?out), hasValue(?out, ?outvalue), lessThanOrEqual(?outvalue, 0.00), Kurtosis(?kurt), hasQuality(?fileObject, ?kurt), Mean(?m3), hasQuality(?kurt, ?m3), hasValue(?m3, ?kurtvalue), greaterThan(?kurtvalue, 33.11)  -> hasValue(?outClass, 'GR')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50),  InterquartileRange(?iqr), Mean(?m2), hasQuality(?fileObject, ?iqr), hasQuality(?m2, ?iqr), hasValue(?m2, ?iqrvalue), lessThanOrEqual (?iqrvalue, 310.88), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.95), greaterThan(?ce, 0.41), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), greaterThan (?pifvalue, 0.01), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), greaterThan (?paivalue, 8.72), EqNumberOfAttributesParameter(?ena), hasQuality(?fileObject, ?ena), hasValue(?ena, ?enavalue), greaterThan(?enavalue, -40.54), OutlierDetection(?out), hasQuality(?fileObject, ?out), hasValue(?out, ?outvalue), greaterThan(?outvalue, 0.00), Kurtosis(?kurt), hasQuality(?fileObject, ?kurt), Mean(?m3), hasQuality(?kurt, ?m3), hasValue(?m3, ?kurtvalue), greaterThan(?kurtvalue, 33.11)  -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50),  InterquartileRange(?iqr), Mean(?m2), hasQuality(?fileObject, ?iqr), hasQuality(?m2, ?iqr), hasValue(?m2, ?iqrvalue), lessThanOrEqual (?iqrvalue, 310.88), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.95), greaterThan(?ce, 0.41), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), greaterThan (?pifvalue, 0.01), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), greaterThan (?paivalue, 8.72), EqNumberOfAttributesParameter(?ena), hasQuality(?fileObject, ?ena), hasValue(?ena, ?enavalue), greaterThan(?enavalue, -40.54), OutlierDetection(?out), hasQuality(?fileObject, ?out), hasValue(?out, ?outvalue), greaterThan(?outvalue, 0.03)  -> hasValue(?outClass, 'GR')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50),  InterquartileRange(?iqr), Mean(?m2), hasQuality(?fileObject, ?iqr), hasQuality(?m2, ?iqr), hasValue(?m2, ?iqrvalue), lessThanOrEqual (?iqrvalue, 310.88), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.95), greaterThan(?ce, 0.41), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), greaterThan (?pifvalue, 0.36)  -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50),  InterquartileRange(?iqr), Mean(?m2), hasQuality(?fileObject, ?iqr), hasQuality(?m2, ?iqr), hasValue(?m2, ?iqrvalue), greaterThan (?iqrvalue, 310.88), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.95)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.98), greaterThan(?ce, 0.95), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), lessThanOrEqual(?nhighCorrvalue, 0.01), GeometricMean(?gmean), hasQuality(?fileObject, ?gmean), Mean(?m4), hasQuality(?gmean, ?m4), hasValue(?m4, ?gmeanvalue), lessThanOrEqual(?gmeanvalue, 1.79), NumberOfNumericAttributes(?nNum), hasQuality(?fileObject, ?nNum), hasValue(?nNum, ?nNumvalue), lessThanOrEqual(?nNumvalue, 29.50)  -> hasValue(?outClass, 'GR')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.98), greaterThan(?ce, 0.95), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), lessThanOrEqual(?nhighCorrvalue, 0.01), GeometricMean(?gmean), hasQuality(?fileObject, ?gmean), Mean(?m4), hasQuality(?gmean, ?m4), hasValue(?m4, ?gmeanvalue), lessThanOrEqual(?gmeanvalue, 1.79), NumberOfNumericAttributes(?nNum), hasQuality(?fileObject, ?nNum), hasValue(?nNum, ?nNumvalue), greaterThan(?nNumvalue, 29.50)  -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.98), greaterThan(?ce, 0.95), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), lessThanOrEqual(?nhighCorrvalue, 0.01), GeometricMean(?gmean), hasQuality(?fileObject, ?gmean), Mean(?m4), hasQuality(?gmean, ?m4), hasValue(?m4, ?gmeanvalue), greaterThan(?gmeanvalue, 1.79)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), greaterThan(?ce, 0.98), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), lessThanOrEqual(?nhighCorrvalue, 0.01)  -> hasValue(?outClass, 'fcbf')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), greaterThan(?ce, 0.95), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), greaterThan(?nhighCorrvalue, 0.01), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), lessThanOrEqual(?attrconcvalue, 0.08), Range(?rangee), hasQuality(?fileObject, ?rangee), Mean(?m6), hasQuality(?rangee, ?m6), hasValue(?m6, ?rangeevalue), lessThanOrEqual(?rangeevalue, 0.82)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), greaterThan(?ce, 0.95), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), greaterThan(?nhighCorrvalue, 0.01), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), lessThanOrEqual(?attrconcvalue, 0.08), Range(?rangee), hasQuality(?fileObject, ?rangee), Mean(?m6), hasQuality(?rangee, ?m6), hasValue(?m6, ?rangeevalue), greaterThan(?rangeevalue, 0.82)  -> hasValue(?outClass, 'GR')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), greaterThan(?ce, 0.95), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), greaterThan(?nhighCorrvalue, 0.01), lessThanOrEqual (?nhighCorrvalue, 0.76), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), greaterThan(?attrconcvalue, 0.08), GeometricMean(?gmean), hasQuality(?fileObject, ?gmean), Mean(?m4), hasQuality(?gmean, ?m4), hasValue(?m4, ?gmeanvalue), lessThanOrEqual (?gmeanvalue, 35.44), Skewness(?skew),  hasQuality(?fileObject, ?skew), Mean(?m7), hasQuality(?skew, ?m7), hasValue(?m7, ?skewvalue), lessThanOrEqual (?skewvalue, 0.06), Range(?rangee), hasQuality(?fileObject, ?rangee), Mean(?m6), hasQuality(?rangee, ?m6), hasValue(?m6, ?rangeevalue), lessThanOrEqual (?rangeevalue, 3.54)  -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), greaterThan(?ce, 0.95), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), greaterThan(?nhighCorrvalue, 0.01), lessThanOrEqual (?nhighCorrvalue, 0.76), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), greaterThan(?attrconcvalue, 0.08), GeometricMean(?gmean), hasQuality(?fileObject, ?gmean), Mean(?m4), hasQuality(?gmean, ?m4), hasValue(?m4, ?gmeanvalue), lessThanOrEqual (?gmeanvalue, 35.44), Skewness(?skew),  hasQuality(?fileObject, ?skew), Mean(?m7), hasQuality(?skew, ?m7), hasValue(?m7, ?skewvalue), lessThanOrEqual (?skewvalue, 0.06), Range(?rangee), hasQuality(?fileObject, ?rangee), Mean(?m6), hasQuality(?rangee, ?m6), hasValue(?m6, ?rangeevalue), greaterThan (?rangeevalue, 3.54)  -> hasValue(?outClass, 'GR')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), greaterThan(?ce, 0.95), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), greaterThan(?nhighCorrvalue, 0.01), lessThanOrEqual (?nhighCorrvalue, 0.76), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), greaterThan(?attrconcvalue, 0.08), GeometricMean(?gmean), hasQuality(?fileObject, ?gmean), Mean(?m4), hasQuality(?gmean, ?m4), hasValue(?m4, ?gmeanvalue), lessThanOrEqual (?gmeanvalue, 35.44), Skewness(?skew),  hasQuality(?fileObject, ?skew), Mean(?m7), hasQuality(?skew, ?m7), hasValue(?m7, ?skewvalue), greaterThan (?skewvalue, 0.06)  -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), greaterThan(?ce, 0.95), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), greaterThan(?nhighCorrvalue, 0.01), lessThanOrEqual (?nhighCorrvalue, 0.76), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), greaterThan(?attrconcvalue, 0.08), GeometricMean(?gmean), hasQuality(?fileObject, ?gmean), Mean(?m4), hasQuality(?gmean, ?m4), hasValue(?m4, ?gmeanvalue), greaterThan (?gmeanvalue, 35.44)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), lessThanOrEqual(?ni, 335.50), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), greaterThan(?ce, 0.95), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), greaterThan(?nhighCorrvalue, 0.76), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), greaterThan(?attrconcvalue, 0.08)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), lessThanOrEqual(?madvalue, 1.00), LabelNoise(?lNoise), hasQuality(?fileObject, ?lNoise), hasValue(?lNoise, ?lNoisevalue), lessThanOrEqual(?lNoisevalue, 0.00), NoiseSignalRatio(?nsr), hasQuality(?fileObject, ?nsr), Mean(?m8), hasQuality(?nsr, ?m8), hasValue(?m8, ?nsrvalue), lessThanOrEqual(?nsrvalue, 1.24)  -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), lessThanOrEqual(?madvalue, 1.00), LabelNoise(?lNoise), hasQuality(?fileObject, ?lNoise), hasValue(?lNoise, ?lNoisevalue), lessThanOrEqual(?lNoisevalue, 0.00), NoiseSignalRatio(?nsr), hasQuality(?fileObject, ?nsr), Mean(?m8), hasQuality(?nsr, ?m8), hasValue(?m8, ?nsrvalue), greaterThan(?nsrvalue, 1.24), Correlation(?corr), Mean(?m1), hasQuality(?fileObject, ?corr), hasQuality(?m1, ?corr), hasValue(?m1, ?corvalue), lessThanOrEqual(?corvalue, 0.05)  -> hasValue(?outClass, 'fcbf')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), lessThanOrEqual(?madvalue, 1.00), LabelNoise(?lNoise), hasQuality(?fileObject, ?lNoise), hasValue(?lNoise, ?lNoisevalue), lessThanOrEqual(?lNoisevalue, 0.00), NoiseSignalRatio(?nsr), hasQuality(?fileObject, ?nsr), Mean(?m8), hasQuality(?nsr, ?m8), hasValue(?m8, ?nsrvalue), greaterThan(?nsrvalue, 1.24), Correlation(?corr), Mean(?m1), hasQuality(?fileObject, ?corr), hasQuality(?m1, ?corr), hasValue(?m1, ?corvalue), greaterThan(?corvalue, 0.05), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), lessThanOrEqual(?attrconcvalue, 0.00)   -> hasValue(?outClass, 'fcbf')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), lessThanOrEqual(?madvalue, 1.00), LabelNoise(?lNoise), hasQuality(?fileObject, ?lNoise), hasValue(?lNoise, ?lNoisevalue), lessThanOrEqual(?lNoisevalue, 0.00), NoiseSignalRatio(?nsr), hasQuality(?fileObject, ?nsr), Mean(?m8), hasQuality(?nsr, ?m8), hasValue(?m8, ?nsrvalue), greaterThan(?nsrvalue, 1.24), Correlation(?corr), Mean(?m1), hasQuality(?fileObject, ?corr), hasQuality(?m1, ?corr), hasValue(?m1, ?corvalue), greaterThan(?corvalue, 0.05), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), greaterThan(?attrconcvalue, 0.00)   -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), lessThanOrEqual(?madvalue, 1.00), LabelNoise(?lNoise), hasQuality(?fileObject, ?lNoise), hasValue(?lNoise, ?lNoisevalue), greaterThan(?lNoisevalue, 0.00), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), lessThanOrEqual (?nhighCorrvalue, 0.12), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), lessThanOrEqual (?attrconcvalue, 0.01)   -> hasValue(?outClass, 'GR')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), lessThanOrEqual(?madvalue, 1.00), LabelNoise(?lNoise), hasQuality(?fileObject, ?lNoise), hasValue(?lNoise, ?lNoisevalue), greaterThan(?lNoisevalue, 0.00), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), lessThanOrEqual (?nhighCorrvalue, 0.12), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), greaterThan (?attrconcvalue, 0.01), NumberOfNumericAttributes(?nNum), hasQuality(?fileObject, ?nNum), hasValue(?nNum, ?nNumvalue), lessThanOrEqual(?nNumvalue, 7.50), NoiseSignalRatio(?nsr), hasQuality(?fileObject, ?nsr), Mean(?m8), hasQuality(?nsr, ?m8), hasValue(?m8, ?nsrvalue), lessThanOrEqual(?nsrvalue, 4.88)  -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), lessThanOrEqual(?madvalue, 1.00), LabelNoise(?lNoise), hasQuality(?fileObject, ?lNoise), hasValue(?lNoise, ?lNoisevalue), greaterThan(?lNoisevalue, 0.00), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), lessThanOrEqual (?nhighCorrvalue, 0.12), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), greaterThan (?attrconcvalue, 0.01), NumberOfNumericAttributes(?nNum), hasQuality(?fileObject, ?nNum), hasValue(?nNum, ?nNumvalue), lessThanOrEqual(?nNumvalue, 7.50), NoiseSignalRatio(?nsr), hasQuality(?fileObject, ?nsr), Mean(?m8), hasQuality(?nsr, ?m8), hasValue(?m8, ?nsrvalue), greaterThan(?nsrvalue, 4.88)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), lessThanOrEqual(?madvalue, 1.00), LabelNoise(?lNoise), hasQuality(?fileObject, ?lNoise), hasValue(?lNoise, ?lNoisevalue), greaterThan(?lNoisevalue, 0.00), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), lessThanOrEqual (?nhighCorrvalue, 0.12), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), greaterThan (?attrconcvalue, 0.01), NumberOfNumericAttributes(?nNum), hasQuality(?fileObject, ?nNum), hasValue(?nNum, ?nNumvalue), greaterThan(?nNumvalue, 7.50)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), lessThanOrEqual(?madvalue, 1.00), LabelNoise(?lNoise), hasQuality(?fileObject, ?lNoise), hasValue(?lNoise, ?lNoisevalue), greaterThan(?lNoisevalue, 0.00), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), greaterThan (?nhighCorrvalue, 0.12), MinimumOfAttributes(?minAttr), hasQuality(?fileObject, ?minAttr), Mean(?m9), hasQuality(?minAttr, ?m9), hasValue(?m9, ?minAttrvalue), lessThanOrEqual(?minAttrvalue, 0.81)   -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), lessThanOrEqual(?madvalue, 1.00), LabelNoise(?lNoise), hasQuality(?fileObject, ?lNoise), hasValue(?lNoise, ?lNoisevalue), greaterThan(?lNoisevalue, 0.00), NumberOfHighlyCorrelatedAttributes(?nhighCorr), hasQuality(?fileObject, ?nhighCorr), hasValue(?nhighCorr, ?nhighCorrvalue), greaterThan (?nhighCorrvalue, 0.12), MinimumOfAttributes(?minAttr), hasQuality(?fileObject, ?minAttr), Mean(?m9), hasQuality(?minAttr, ?m9), hasValue(?m9, ?minAttrvalue), greaterThan(?minAttrvalue, 0.81)   -> hasValue(?outClass, 'GR')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), lessThanOrEqual(?maxvalue, 177.98), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), lessThanOrEqual(?compvalue, 0.00), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.88), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), lessThanOrEqual(?pifvalue, 0.00)  -> hasValue(?outClass, 'fcbf')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), lessThanOrEqual(?maxvalue, 177.98), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), lessThanOrEqual(?compvalue, 0.00), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.88), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), greaterThan(?pifvalue, 0.00), Sparsity(?spars), hasQuality(?fileObject, ?spars), Mean(?m12), hasQuality(?spars, ?m12), hasValue(?m12, ?sparsvalue), lessThanOrEqual(?sparsvalue, 0.20), NumberOfBinaryAttributes(?nbin), hasQuality(?fileObject, ?nbin), hasValue(?nbin, ?nbinvalue), lessThanOrEqual(?nbinvalue, 0.50)   -> hasValue(?outClass, 'GR')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), lessThanOrEqual(?maxvalue, 177.98), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), lessThanOrEqual(?compvalue, 0.00), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.88), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), greaterThan(?pifvalue, 0.00), Sparsity(?spars), hasQuality(?fileObject, ?spars), Mean(?m12), hasQuality(?spars, ?m12), hasValue(?m12, ?sparsvalue), lessThanOrEqual(?sparsvalue, 0.20), NumberOfBinaryAttributes(?nbin), hasQuality(?fileObject, ?nbin), hasValue(?nbin, ?nbinvalue), greaterThan(?nbinvalue, 0.50), Skewness(?skew),  hasQuality(?fileObject, ?skew), Mean(?m7), hasQuality(?skew, ?m7), hasValue(?m7, ?skewvalue), lessThanOrEqual(?skewvalue, -0.82)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), lessThanOrEqual(?maxvalue, 177.98), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), lessThanOrEqual(?compvalue, 0.00), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.88), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), greaterThan(?pifvalue, 0.00), Sparsity(?spars), hasQuality(?fileObject, ?spars), Mean(?m12), hasQuality(?spars, ?m12), hasValue(?m12, ?sparsvalue), lessThanOrEqual(?sparsvalue, 0.20), NumberOfBinaryAttributes(?nbin), hasQuality(?fileObject, ?nbin), hasValue(?nbin, ?nbinvalue), greaterThan(?nbinvalue, 0.50), Skewness(?skew),  hasQuality(?fileObject, ?skew), Mean(?m7), hasQuality(?skew, ?m7), hasValue(?m7, ?skewvalue), greaterThan(?skewvalue, -0.82)  -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), lessThanOrEqual(?maxvalue, 177.98), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), lessThanOrEqual(?compvalue, 0.00), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.88), ProportionOfInstancesPerFeature(?pif), hasQuality(?fileObject, ?pif), hasValue(?pif, ?pifvalue), greaterThan(?pifvalue, 0.00), Sparsity(?spars), hasQuality(?fileObject, ?spars), Mean(?m12), hasQuality(?spars, ?m12), hasValue(?m12, ?sparsvalue), greaterThan(?sparsvalue, 0.20)  -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), lessThanOrEqual(?maxvalue, 177.98), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), lessThanOrEqual(?compvalue, 0.00), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.97), greaterThan(?ce, 0.88), NoiseSignalRatio(?nsr), hasQuality(?fileObject, ?nsr), Mean(?m8), hasQuality(?nsr, ?m8), hasValue(?m8, ?nsrvalue), lessThanOrEqual(?nsrvalue, 1.18)  -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), lessThanOrEqual(?maxvalue, 177.98), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), lessThanOrEqual(?compvalue, 0.00), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), lessThanOrEqual(?ce, 0.97), greaterThan(?ce, 0.88), NoiseSignalRatio(?nsr), hasQuality(?fileObject, ?nsr), Mean(?m8), hasQuality(?nsr, ?m8), hasValue(?m8, ?nsrvalue), greaterThan(?nsrvalue, 1.18)  -> hasValue(?outClass, 'fcbf')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), lessThanOrEqual(?maxvalue, 177.98), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), lessThanOrEqual(?compvalue, 0.00), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), greaterThan(?ce, 0.97), Variance(?var), hasQuality(?fileObject, ?var), Mean(?m13), hasQuality(?var, ?m13), hasValue(?m13, ?varvalue), lessThanOrEqual(?varvalue, 6.94)   -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), lessThanOrEqual(?maxvalue, 177.98), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), lessThanOrEqual(?compvalue, 0.00), ClassEntropy(?cEntropy), hasQuality(?fileObject, ?cEntropy), hasValue(?cEntropy, ?ce), greaterThan(?ce, 0.97), Variance(?var), hasQuality(?fileObject, ?var), Mean(?m13), hasQuality(?var, ?m13), hasValue(?m13, ?varvalue), greaterThan(?varvalue, 6.94)   -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), lessThanOrEqual(?maxvalue, 177.98), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), greaterThan(?compvalue, 0.00), Kurtosis(?kurt), hasQuality(?fileObject, ?kurt), Mean(?m3), hasQuality(?kurt, ?m3), hasValue(?m3, ?kurtvalue), lessThanOrEqual(?kurtvalue, -0.42)   -> hasValue(?outClass, 'GR')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), lessThanOrEqual(?maxvalue, 177.98), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), greaterThan(?compvalue, 0.00), Kurtosis(?kurt), hasQuality(?fileObject, ?kurt), Mean(?m3), hasQuality(?kurt, ?m3), hasValue(?m3, ?kurtvalue), greaterThan(?kurtvalue, -0.42), Sparsity(?spars), hasQuality(?fileObject, ?spars), Mean(?m12), hasQuality(?spars, ?m12), hasValue(?m12, ?sparsvalue), lessThanOrEqual(?sparsvalue, 0.41)   -> hasValue(?outClass, 'fcbf')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), lessThanOrEqual(?maxvalue, 177.98), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), greaterThan(?compvalue, 0.00), Kurtosis(?kurt), hasQuality(?fileObject, ?kurt), Mean(?m3), hasQuality(?kurt, ?m3), hasValue(?m3, ?kurtvalue), greaterThan(?kurtvalue, -0.42), Sparsity(?spars), hasQuality(?fileObject, ?spars), Mean(?m12), hasQuality(?spars, ?m12), hasValue(?m12, ?sparsvalue), greaterThan(?sparsvalue, 0.41)   -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), greaterThan(?maxvalue, 177.98), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), lessThanOrEqual(?paivalue, 634.88), AttributesEntropy(?attrent), hasQuality(?fileObject, ?attrent), Mean(?m15), hasQuality(?attrent, ?m15), hasValue(?m15, ?attentvalue), lessThanOrEqual(?attentvalue, 1.70), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), lessThanOrEqual(?compvalue, 0.00)   -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), greaterThan(?maxvalue, 177.98), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), lessThanOrEqual(?paivalue, 634.88), AttributesEntropy(?attrent), hasQuality(?fileObject, ?attrent), Mean(?m15), hasQuality(?attrent, ?m15), hasValue(?m15, ?attentvalue), lessThanOrEqual(?attentvalue, 1.70), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), greaterThan(?compvalue, 0.00), EigenValues(?egv), hasQuality(?fileObject, ?egv), Mean(?m14), hasQuality(?egv, ?m14), hasValue(?m14, ?egvvalue), lessThanOrEqual(?egvvalue, 2572799.41), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), lessThanOrEqual(?attrconcvalue, 0.13)   -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), greaterThan(?maxvalue, 177.98), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), lessThanOrEqual(?paivalue, 634.88), AttributesEntropy(?attrent), hasQuality(?fileObject, ?attrent), Mean(?m15), hasQuality(?attrent, ?m15), hasValue(?m15, ?attentvalue), lessThanOrEqual(?attentvalue, 1.70), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), greaterThan(?compvalue, 0.00), EigenValues(?egv), hasQuality(?fileObject, ?egv), Mean(?m14), hasQuality(?egv, ?m14), hasValue(?m14, ?egvvalue), lessThanOrEqual(?egvvalue, 2572799.41), AttributeConcentration(?attrconc), hasQuality(?fileObject, ?attrconc), Mean(?m5), hasQuality(?attrconc, ?m5), hasValue(?m5, ?attrconcvalue), greaterThan(?attrconcvalue, 0.13)   -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), greaterThan(?maxvalue, 177.98), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), lessThanOrEqual(?paivalue, 634.88), AttributesEntropy(?attrent), hasQuality(?fileObject, ?attrent), Mean(?m15), hasQuality(?attrent, ?m15), hasValue(?m15, ?attentvalue), lessThanOrEqual(?attentvalue, 1.70), Completeness(?completeness), hasQuality(?fileObject, ?completeness), hasValue(?completeness, ?compvalue), greaterThan(?compvalue, 0.00), EigenValues(?egv), hasQuality(?fileObject, ?egv), Mean(?m14), hasQuality(?egv, ?m14), hasValue(?m14, ?egvvalue), greaterThan(?egvvalue, 2572799.41)   -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), greaterThan(?maxvalue, 177.98), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), lessThanOrEqual(?paivalue, 634.88), AttributesEntropy(?attrent), hasQuality(?fileObject, ?attrent), Mean(?m15), hasQuality(?attrent, ?m15), hasValue(?m15, ?attentvalue), greaterThan(?attentvalue, 1.70)   -> hasValue(?outClass, 'chisquare')\", namespaces = [mtl, dmop, dmop1])\n",
    "    Imp().set_as_rule(\"FeatureSelectionTask(?featureSelectionTask), MetaLearningAlgorithm(?mtl), DataSetClass(?fileObject), hasMetaObjective(?mtl, ?featureSelectionTask), specifiesInputClass(?featureSelectionTask, ?fileObject), StructuredPredictionModelClass(?outClass), specifiesOutputClass(?featureSelectionTask, ?outClass), NumberOfInstances(?nInstances), hasQuality(?fileObject, ?nInstances), hasValue(?nInstances, ?ni), greaterThan(?ni, 335.50), MedianAbsoluteDeviation(?mad), hasQuality(?fileObject, ?mad), Mean(?m11), hasQuality(?mad, ?m11), hasValue(?m11, ?madvalue), greaterThan(?madvalue, 1.00), MaximumOfAttributes(?maxAttr), hasQuality(?fileObject, ?maxAttr), Mean(?m10), hasQuality(?maxAttr, ?m10), hasValue(?m10, ?maxvalue), greaterThan(?maxvalue, 177.98), ProportionOfAttrToInstances(?pai), hasQuality(?fileObject, ?pai), hasValue(?pai, ?paivalue), greaterThan(?paivalue, 634.88)   -> hasValue(?outClass, 'relief')\", namespaces = [mtl, dmop, dmop1])\n",
    "    onto.save(file=\"PopulatedOntowithRules.rdf\", format=\"rdfxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload triples to Fuseki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "fuseki_url = \"http://localhost:3030/KB/data\" #URL of the Fuseki dataset\n",
    "\n",
    "rdf_file = \"PopulatedOntology.rdf\"\n",
    "\n",
    "with open(rdf_file, 'rb') as file:\n",
    "    rdf_data = file.read()\n",
    "\n",
    "response = requests.post(fuseki_url, data=rdf_data, headers={'Content-Type': 'application/rdf+xml'})\n",
    "\n",
    "if response.status_code == 200 or response.status_code == 204:\n",
    "    print(\"Data uploaded successfully\")\n",
    "else:\n",
    "    print(f\"Failed to upload data. Status code: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query to extract limits of correlation metric - simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'upperValue': {'type': 'literal', 'datatype': 'http://www.w3.org/2001/XMLSchema#decimal', 'value': '0.722546950365172'}, 'lowerValue': {'type': 'literal', 'datatype': 'http://www.w3.org/2001/XMLSchema#decimal', 'value': '0.282243283520706'}, 'mean': {'type': 'literal', 'datatype': 'http://www.w3.org/2001/XMLSchema#decimal', 'value': '0.21219574167444272'}, 'stdDev': {'type': 'literal', 'datatype': 'http://www.w3.org/2001/XMLSchema#decimal', 'value': '0.15759223896725938'}}\n",
      "Feature Selection Algorithm: 0.722546950365172, Feature Count: 0.282243283520706\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"http://localhost:3030/KB/sparql\" \n",
    "\n",
    "sparql = SPARQLWrapper(endpoint_url)\n",
    "query = \"\"\"\n",
    "    PREFIX dmop: <http://www.e-lico.eu/ontologies/dmo/DMOP/DMOP.owl#>\n",
    "    PREFIX dmop1: <http://www.e-LICO.eu/ontologies/dmo/DMOP/DMOP.owl#>\n",
    "    PREFIX mtl: <https://purl.archive.org/domain/mtl#>  \n",
    "    SELECT ?upperValue ?lowerValue ?mean ?stdDev\n",
    "    WHERE {  \n",
    "        ?metal a mtl:MetaLearningAlgorithm . \n",
    "        ?featureSelectionTask a dmop:FeatureSelectionTask .\n",
    "        ?metal mtl:hasMetaObjective ?featureSelectionTask .\n",
    "        ?cor a mtl:CorrelationParameter .\n",
    "        ?metal dmop:hasParameter ?cor .\n",
    "        ?cor mtl:hasLowerValue ?lowerValue .\n",
    "        ?cor mtl:hasUpperValue ?upperValue .\n",
    "        ?m a mtl:Mean .\n",
    "        ?std a mtl:StdDev .\n",
    "        ?cor mtl:hasQuality ?m .\n",
    "        ?cor mtl:hasQuality ?std .\n",
    "        ?m dmop:hasValue ?mean .\n",
    "  ?std dmop:hasValue ?stdDev . \n",
    "} \"\"\"\n",
    "\n",
    "sparql.setQuery(query)\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "results = sparql.query().convert()\n",
    "\n",
    "if \"results\" in results and \"bindings\" in results[\"results\"]:\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        print(result)\n",
    "        upperValue = result[\"upperValue\"][\"value\"]\n",
    "        lowerValue = result[\"lowerValue\"][\"value\"]\n",
    "        print(f\"Feature Selection Algorithm: {upperValue}, Feature Count: {lowerValue}\")\n",
    "else:\n",
    "    print(\"Unexpected response format. Please check the SPARQL query and endpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query to extract datasets and associated feature selection techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#chronickidneydiseasefullcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#AutismAdolescentDatacsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#SouthGermanCreditasc\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#ZAlizadehsanidatasetxlsx\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#DataUserModelingDatasetHamdiTolgaKAHRAMANcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#nonverbaltouristdatacsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#1yearcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#2yearcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#3yearcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#4yearcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#5yearcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#abalonedata\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#abalone918csv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#adultcsv\n",
      "Feature Selection Algorithm: fcbf, Dataset: https://purl.archive.org/domain/mtl#agaricuslepiotadata\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#AlgerianforestfiresdatasetUPDATEcsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#appendicitiscsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#auditriskcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#audittrialcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#AutismAdultDatacsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#AutismChildDatacsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#Automobiledatacsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#automobileimbalancecsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#balancescaledata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#balancescaleimbalancedcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#bloodtransfusiondata\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#bonemarrowcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#BreastCancerWisconsinDiagnosticdataset5cn10nccsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#breastcancerwisconsindata\n",
      "Feature Selection Algorithm: MI, Dataset: https://purl.archive.org/domain/mtl#breastcancercoimbracsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#breastcancerimbalancecsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#breastcancerwdbcdata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#brestcancerwpbcdata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#bupadata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#burstheadercsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#caesariancsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#cardata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#cargo2000datacommacsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#cervicalbehaviourcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#cervicalriskfactorscervicalcancercsv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#ChemicalComposionofCeramiccsv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#chesskrvskpdata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#ckddatasetv2csv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#climatepopfailuresdat\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#column2Cwekacsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#column3Cwekacsv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#congresshousevotes84data\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#connect4data\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#connectionistbenchdata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#contraceptivedata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#contraceptive5cn02csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#contraceptivemulticlasscsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#creditapprovallimitsdata\n",
      "Feature Selection Algorithm: fcbf, Dataset: https://purl.archive.org/domain/mtl#Cryotherapyxlsx\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#databanknoteauthenticationcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#dermatologydata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#divorcecsv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#DryBeanDatasetcsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#ecoli0vs1csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#ecoli5cn01nccsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#ecolidata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#ecoli1csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#ecoli2csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#ecoli3csv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#ecoli4csv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#Electicalstabilitycsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#extentionofZAlizadehsanidatasetxlsx\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#fertilityDiagnosisdata\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#glassidentificationimbalancecsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#glass0123vs456csv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#glass016vs2csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#glass016vs5csv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#glassdata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#glass0csv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#glass1csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#glass2csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#glass4csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#glass5csv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#glass5cn10csv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#glass6csv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#Habermanimbalancecsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#habermandata\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#Hayesrothimbalancecsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#hayesrothdata\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#hccdatadata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#HCVEgyDatacsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#hcvdat0csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#heartfailureclinicalrecordsdatasetcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#highereducationcsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#horsecsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#HTRU2csv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#Immunotherapyxlsx\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#IndianLiverPatientDatasetILPDcsv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#insurancedata2000data\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#ionosphere5cn01ncsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#ionospheredata\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#irisdata\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#iris0csv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#Iris5cn01nccsv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#letterrecognitiondata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#LymphographyMulticlassImbalanceddatasetcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#lymphographydata\n",
      "Feature Selection Algorithm: fcbf, Dataset: https://purl.archive.org/domain/mtl#mammographicmassesdata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#monks1csv\n",
      "Feature Selection Algorithm: fcbf, Dataset: https://purl.archive.org/domain/mtl#monks2csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#monks3csv\n",
      "Feature Selection Algorithm: fcbf, Dataset: https://purl.archive.org/domain/mtl#myocardicaldata\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#newthyroid1csv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#newthyroidcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#newthyroid2csv\n",
      "Feature Selection Algorithm: fcbf, Dataset: https://purl.archive.org/domain/mtl#nurserydata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#ObesityDataSetrawanddatasintheticcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#pageblocks13vs4csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#pageblocksimbalancedcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#pageblocks5cn01nccsv\n",
      "Feature Selection Algorithm: MI, Dataset: https://purl.archive.org/domain/mtl#parkinsonsdata\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#PhishingWebsitesDataSetcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#PhishingDatacsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#Pima5cn01nccsv\n",
      "Feature Selection Algorithm: fcbf, Dataset: https://purl.archive.org/domain/mtl#pimacsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#pimaimbalancedcsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#postoperativecsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#primarytumordata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#QSARbiodegcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#RaisinDatasetcsv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#seedsdatasetdata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#seismicbumpscsv\n",
      "Feature Selection Algorithm: fcbf, Dataset: https://purl.archive.org/domain/mtl#SomervilleHappinessSurvey2015csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#sonar5cn19csv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#soybeansmalldata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#spambasedata\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#SPECTcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#SPECTFcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#starlogshuttleimbalancedcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#starlogvehiclesikhouettesdat\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#starlogaustraliandat\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#statlogheartcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#studentmatcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#studentporcsv\n",
      "Feature Selection Algorithm: fcbf, Dataset: https://purl.archive.org/domain/mtl#taedata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#ThoraricSurgerycsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#ThyroidDiseaseNewThyroidMulticlassImbalanceddatasetcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#thyroidmulticlassimbalancecsv\n",
      "Feature Selection Algorithm: fcbf, Dataset: https://purl.archive.org/domain/mtl#thyroidcsv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#thyroid5cn21csv\n",
      "Feature Selection Algorithm: fcbf, Dataset: https://purl.archive.org/domain/mtl#tictactoedata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#titaniccsv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#trialcsv\n",
      "Feature Selection Algorithm: relief, Dataset: https://purl.archive.org/domain/mtl#TUANDROMDcsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#Turkishmusiccsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#vehicle0csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#vehicle1csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#vehicle2csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#vehicle3csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#Wholesalecustomersdatacsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#wineimbalancecsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#winedata\n",
      "Feature Selection Algorithm: MI, Dataset: https://purl.archive.org/domain/mtl#wine5cn10nccsv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#winequalityredcsv\n",
      "Feature Selection Algorithm: fcbf, Dataset: https://purl.archive.org/domain/mtl#winequalitywhitecsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#yeast05679vs4csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#yeast1vs7csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#yeast2vs4csv\n",
      "Feature Selection Algorithm: MI, Dataset: https://purl.archive.org/domain/mtl#yeast2vs8csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#yeastdata\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#yeast1csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#yeast3csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#yeast4csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#yeast5csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#yeast5cn21csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#yeast6csv\n",
      "Feature Selection Algorithm: chisquare, Dataset: https://purl.archive.org/domain/mtl#yeastimbalancecsv\n",
      "Feature Selection Algorithm: GR, Dataset: https://purl.archive.org/domain/mtl#zoodata\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"http://localhost:3030/KB/sparql\" \n",
    "\n",
    "sparql = SPARQLWrapper(endpoint_url)\n",
    "query = \"\"\"\n",
    "    PREFIX dmop: <http://www.e-lico.eu/ontologies/dmo/DMOP/DMOP.owl#>\n",
    "    PREFIX dmop1: <http://www.e-LICO.eu/ontologies/dmo/DMOP/DMOP.owl#>\n",
    "    PREFIX mtl: <https://purl.archive.org/domain/mtl#>  \n",
    "    SELECT ?featureAlgo ?dataset\n",
    "    WHERE {  \n",
    "        ?metal a mtl:MetaLearningAlgorithm . \n",
    "        ?featureSelectionTask a dmop:FeatureSelectionTask .\n",
    "        ?metal mtl:hasMetaObjective ?featureSelectionTask .\n",
    "  \t\t?dataset a dmop:DataSetClass .   \n",
    "\t\t?featureSelectionTask dmop:specifiesInputClass ?dataset .\n",
    "  \t\t?featureAlgoOutput a dmop:StructuredPredictionModelClass .\n",
    "  \t\t?featureSelectionTask dmop:specifiesOutputClass ?featureAlgoOutput .\n",
    "  \t\t?featureAlgoOutput dmop:hasValue ?featureAlgo .\n",
    "} \"\"\"\n",
    "\n",
    "sparql.setQuery(query)\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "results = sparql.query().convert()\n",
    "\n",
    "if \"results\" in results and \"bindings\" in results[\"results\"]:\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        featureAlgo = result[\"featureAlgo\"][\"value\"]\n",
    "        dataset = result[\"dataset\"][\"value\"]\n",
    "        print(f\"Feature Selection Algorithm: {featureAlgo}, Dataset: {dataset}\")\n",
    "else:\n",
    "    print(\"Unexpected response format. Please check the SPARQL query and endpoint.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".deeplearningClass",
   "language": "python",
   "name": ".deeplearningclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
