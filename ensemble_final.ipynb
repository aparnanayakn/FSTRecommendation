{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import math\n",
    "import itertools\n",
    "import csv\n",
    "import json\n",
    "\n",
    "from statistics import mean, stdev\n",
    "\n",
    "#sklearn\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, roc_auc_score,precision_score, accuracy_score\n",
    "\n",
    "#feature selection\n",
    "\n",
    "from mrmr import mrmr_classif\n",
    "from info_gain import info_gain\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#external files\n",
    "import file_operations\n",
    "import pre_processing\n",
    "import simple_characteristics\n",
    "import arfftocsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CFS\n",
    "import fc\n",
    "import multisurf\n",
    "import chiSquare\n",
    "import testrelief\n",
    "import relieff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X, impFeatures, threshold):\n",
    "    X_new = pd.DataFrame()\n",
    "    for idx, value in enumerate(impFeatures):\n",
    "        if(float(value) >= threshold):\n",
    "            X_new = pd.concat((X_new, X.iloc[:, idx]), axis=1)\n",
    "    return X_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcbf_features(X,Y):\n",
    "    return fc.fcbf(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relief_feature(X, Y):\n",
    "    X=np.array(X)\n",
    "    X = X.astype(np.float)\n",
    "    r = testrelief.Relief(n_features=(X.shape[1]-1) ) # Will run by default on all processors concurrently\n",
    "    my_transformed_matrix = r.fit_transform(X,Y.values)\n",
    "    return r.w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_ratio(X,Y):\n",
    "    info_gain_ratio_values = []\n",
    "    for idx, col in X.iteritems():\n",
    "        info_gain_ratio_values.append(info_gain.info_gain_ratio(col.values, Y.values.tolist()))\n",
    "    return info_gain_ratio_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables(df):\n",
    "    Y = simple_characteristics.get_labels(df)\n",
    "    X = df.drop(df.columns[simple_characteristics.class_index], axis=1)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info(X,Y):\n",
    "    return mutual_info_classif(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_non_negative(X):\n",
    "    df_transformed = X.copy()\n",
    "    for col_index in range(df_transformed.shape[1]):\n",
    "        min_value = df_transformed.iloc[:, col_index].min()\n",
    "        if min_value < 0:\n",
    "            df_transformed.iloc[:, col_index] += abs(min_value)\n",
    "    return df_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relief_F_feature(X, Y):\n",
    "    r = relieff.ReliefF()\n",
    "    return (r.fit(X.values, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_fs(fs, X, Y, X_new): #to drop column that has sequence number\n",
    "    X = X.drop(X_new.columns[0], axis=1)\n",
    "    if(fs == \"GR\"):\n",
    "        impF = gain_ratio(X,Y)\n",
    "    elif(fs==\"MI\"):\n",
    "        impF = mutual_info(X,Y)\n",
    "    elif(fs == \"relief\"):\n",
    "        impF =  relief_feature(X,Y)\n",
    "    elif(fs == \"mrmr\"):\n",
    "        impF = mrmr_classif(X, Y, K=X.shape[1]-1, return_scores = True)\n",
    "        X_new = select_features(X, impF[1], np.mean(impF[1]))\n",
    "    elif(fs == \"chisquare\"):\n",
    "        impF = chiSquare.chi_square_feature_importance(X, Y)\n",
    "    elif(fs == \"fcbf\"):\n",
    "        impF = fcbf_features(X,Y)\n",
    "    elif(fs == \"cfs\"):\n",
    "        impF =  CFS.cfs(X,Y)\n",
    "    elif(fs == \"relieff\"):\n",
    "        impF = relief_F_feature(X,Y)\n",
    "    elif(fs == \"multisurf\"):\n",
    "        impF = multisurf.multisurf(X,Y)\n",
    "    if(fs != 'mrmr'):\n",
    "        X_new = select_features(X, impF, np.mean(impF)) \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(fileName, X,Y):\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    featureAlgo = [\"GR\", \"fcbf\",\"relieff\",\"chisquare\",\"cfs\",\"multisurf\", \"MI\",\"mrmr\",\"relief\"]\n",
    "    importance = []\n",
    "    estimators = []\n",
    "    model11 = LogisticRegression(penalty = 'l2', random_state = 0)\n",
    "    estimators.append(('lr',model11))\n",
    "    model16 = DecisionTreeClassifier(max_depth = 3)\n",
    "    estimators.append(('dt',model16))\n",
    "    model26 = KNeighborsClassifier(n_neighbors = 6, metric = 'minkowski', p = 2)\n",
    "    estimators.append(('knn1', model26))\n",
    "    model31 = GaussianNB()\n",
    "    estimators.append(('nbs1', model31))\n",
    "\n",
    "    ensemble = VotingClassifier(estimators, voting='soft')    \n",
    "\n",
    "    for fs in featureAlgo:  \n",
    "        temp = []\n",
    "        start = timeit.default_timer()\n",
    "        if(fs == \"GR\"):\n",
    "            impF = gain_ratio(X,Y)\n",
    "        elif(fs==\"MI\"):\n",
    "            impF = mutual_info(X,Y)\n",
    "        elif(fs == \"relief\"):\n",
    "            impF =  relief_feature(X,Y)\n",
    "        elif(fs == \"mrmr\"):\n",
    "            impF = mrmr_classif(X, Y, K=X.shape[1]-1, return_scores = True)\n",
    "            X_new = select_features(X, impF[1], np.mean(impF[1]))\n",
    "        elif(fs == \"chisquare\"):\n",
    "            impF = chiSquare.chi_square_feature_importance(X, Y)\n",
    "        elif(fs == \"fcbf\"):\n",
    "            impF = fcbf_features(X,Y)\n",
    "        elif(fs == \"cfs\"):\n",
    "            impF =  CFS.cfs(X,Y)\n",
    "        elif(fs == \"relieff\"):\n",
    "            impF = relief_F_feature(X,Y)\n",
    "        elif(fs == \"multisurf\"):\n",
    "            impF = multisurf.multisurf(X,Y)\n",
    "        stop = timeit.default_timer()\n",
    "        print(fs)\n",
    "        if(fs != 'mrmr'):\n",
    "            X_new = select_features(X, impF, np.mean(impF)) \n",
    "\n",
    "        print(X_new.shape,X.shape)\n",
    "        if(X_new.shape[1]==1):\n",
    "            print(\"DROPPED\")\n",
    "            X_new = drop_fs(fs, X, Y, X_new)\n",
    "        \n",
    "        if(X_new.shape[0] == 0 or X_new.shape[1] == 0):\n",
    "            print(\"CHANGE\")\n",
    "            X_new = select_features(X, impF, np.mean(impF) ) \n",
    "\n",
    "        print(X_new.shape)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_new, Y, test_size=0.20, random_state=42)\n",
    "        print(fs)\n",
    "        start1 = timeit.default_timer()\n",
    "        ensemble.fit(X_train, y_train)\n",
    "        y_pred = ensemble.predict(X_test)\n",
    "        stop1 = timeit.default_timer()\n",
    "        pre_sc_macro = precision_score(y_test, y_pred, average='macro')\n",
    "        recal_sc_macro = recall_score(y_test, y_pred, average='macro')  \n",
    "        pre_sc_weigh = precision_score(y_test, y_pred, average='weighted')\n",
    "        recal_sc_weigh = recall_score(y_test, y_pred, average='macro')\n",
    "        recal_sc_macro = recall_score(y_test, y_pred, average='macro')  \n",
    "        pre_sc_weigh = precision_score(y_test, y_pred, average='weighted')\n",
    "        recal_sc_weigh = recall_score(y_test,y_pred, average='weighted')  \n",
    "        print(\"Calcu\")\n",
    "        temp.append(fileName)\n",
    "        temp.append(fs)\n",
    "        temp.append(ensemble.score(X_test,y_test))\n",
    "        temp.append(pre_sc_macro)\n",
    "        temp.append(recal_sc_macro)\n",
    "        temp.append(pre_sc_weigh)\n",
    "        temp.append(recal_sc_weigh)\n",
    "        temp.append(stop-start)\n",
    "        temp.append(X_new.shape[1])\n",
    "        temp.append(stop1-start1)\n",
    "        temp.append(simple_characteristics.class_index)\n",
    "        result.append(temp)\n",
    "    return result #returns mean accuracy\n",
    "\n",
    "       # print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-verbal tourist data.csv\n",
      "***************************TOTAL FILES********************************* 0\n",
      "----------------------\n",
      "GR\n",
      "(73, 9) (73, 22)\n",
      "(73, 9)\n",
      "GR\n",
      "Calcu\n",
      "fcbf\n",
      "(73, 10) (73, 22)\n",
      "(73, 10)\n",
      "fcbf\n",
      "Calcu\n",
      "relieff\n",
      "(73, 12) (73, 22)\n",
      "(73, 12)\n",
      "relieff\n",
      "Calcu\n",
      "chisquare\n",
      "(73, 10) (73, 22)\n",
      "(73, 10)\n",
      "chisquare\n",
      "Calcu\n",
      "[0.010451220175439022, 0.11859341971115665, 0.12751753240007702, 0.12079826404608915, 0.15521993227702152, 0.1464362454194634, 0.18146538182064106, 0.044358197431603116, 0.0, 0.1741388420921757, 0.13063100207212847, 0.025462312925564428, 0.12918020937627417, 0.06746032527080427, 0.06364322523459935, 0.13868980472144832, 0.04802422987917405, 0.059228100689386574, 0.08877372471468441, 0.10716898648566205, 0.030490650231474643, 0.048341081880885414]\n",
      "cfs\n",
      "(73, 11) (73, 22)\n",
      "(73, 11)\n",
      "cfs\n",
      "Calcu\n",
      "0\n",
      "multisurf\n",
      "(73, 10) (73, 22)\n",
      "(73, 10)\n",
      "multisurf\n",
      "Calcu\n",
      "MI\n",
      "(73, 11) (73, 22)\n",
      "(73, 11)\n",
      "MI\n",
      "Calcu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:03<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrmr\n",
      "(73, 8) (73, 22)\n",
      "(73, 8)\n",
      "mrmr\n",
      "Calcu\n",
      "relief\n",
      "(73, 5) (73, 22)\n",
      "(73, 5)\n",
      "relief\n",
      "Calcu\n"
     ]
    }
   ],
   "source": [
    "timeRequired = []\n",
    "listofFiles={}\n",
    "classification_perfomance=[[]]\n",
    "#featureAlgo = [\"MI\"]\n",
    "\n",
    "listofFiles={}\n",
    "abs_path = os.getcwd()+'/datasets/MFEAI/AdditionalError/Working/'\n",
    "file_operations.un_zip_files(abs_path) #extracted zipped files\n",
    "arfftocsv.arffTocsv(abs_path)\n",
    "test = 'test'\n",
    "train = 'train'\n",
    "valid = 'valid'\n",
    "flag=0\n",
    "count = 0\n",
    "duplicate_files = []\n",
    "for path, subdirs, files in os.walk(abs_path):\n",
    "    \n",
    "    duplicate_files = []\n",
    "    test_datasets = [s for s in files if test in s]\n",
    "    train_datasets = [s for s in files if train in s]\n",
    "    valid_datasets = [s for s in files if valid in s]\n",
    "    if train_datasets:\n",
    "        for td in train_datasets:\n",
    "            pre_train = (td).split(\"_\")[0]\n",
    "            for ted in test_datasets:\n",
    "                pre_test = (ted).split(\"_\")[0]\n",
    "                if(pre_train in ted) and (pre_test==pre_train):\n",
    "                    table1 = pd.read_csv(path+\"/\"+td)\n",
    "                    table2 = pd.read_csv(path+\"/\"+ted)\n",
    "                    table1.columns = table2.columns\n",
    "                    data = table1.append(table2)\n",
    "                    data.to_csv(path+\"/\"+pre_train+\".csv\")\n",
    "                    if flag:\n",
    "                        files.append(pre_train+\".csv\")\n",
    "                    else:\n",
    "                        flag=1\n",
    "                        files=[pre_train+\".csv\"]\n",
    "    base = [os.path.splitext(f) for f in files]\n",
    "    if(base):\n",
    "        for a, b in itertools.combinations(base, 2):\n",
    "            if(a[0]==b[0]):\n",
    "                if((a[1]==\".csv\" and b[1]==\".xlsx\") or\n",
    "                   (b[1]==\".csv\" and a[1]==\".xlsx\") or\n",
    "                   (a[1]==\".arff\" and b[1]==\".xlsx\") or\n",
    "                   (b[1]==\".arff\" and a[1]==\".xlsx\") or \n",
    "                   (a[1]==\".arff\" and b[1]==\".csv\") or\n",
    "                   (b[1]==\".arff\" and a[1]==\".csv\") or \n",
    "                   (a[1]==\".data\" and b[1]==\".csv\") or\n",
    "                   (b[1]==\".data\" and a[1]==\".csv\")):\n",
    "                   duplicate_files.append(a[0]+\".csv\")\n",
    "\n",
    "    if(duplicate_files):\n",
    "        files = duplicate_files\n",
    "\n",
    "    for name in files:\n",
    "        if name.endswith((\".data\", \".csv\", \".xlsx\",\".xls\", \".asc\",\".dat\",\".trn\")):\n",
    "            listofFiles[name]=os.path.join(path, name)\n",
    "           # print(listofFiles[name])\n",
    "\n",
    "# create the inputs and outputs\n",
    "featureAlgo = [\"GR\",\"mrmr\",\"fcbf\",\"relief\",\"relieff\", \"MI\"]\n",
    "classification_perfomance = []\n",
    "for eachFile in listofFiles:\n",
    "    print(eachFile)\n",
    "    print(\"***************************TOTAL FILES*********************************\", count)\n",
    "    count+=1\n",
    "    print(\"----------------------\")\n",
    "    dataset = file_operations.custom_csv(listofFiles[eachFile])\n",
    "    all_Label = simple_characteristics.get_labels(dataset)\n",
    "\n",
    "    dataset = pre_processing.drop_rows(dataset)\n",
    "    dataset = pre_processing.drop_columns(dataset)\n",
    "    dataset = pre_processing.convert_NAs(dataset)\n",
    "    dataset = pre_processing.convert_str_int_categorical(dataset)\n",
    "    dataset = pre_processing.convert_str_int_nominal(dataset)\n",
    "    X,y = simple_characteristics.get_XY(dataset)\n",
    "    classification_output = classify(eachFile, X,y)\n",
    "    for item in classification_output:\n",
    "        classification_perfomance.append(item)\n",
    "    df=pd.DataFrame(classification_perfomance)\n",
    "    #df.columns = ['File', 'FeatureAlgo', 'Features']\n",
    "    df.columns =['File', 'FeatureAlgo', 'Accuracy','Precision macro' ,'Recall macro', 'Precision weight', 'Recall weight', 'Time FS', 'Features','Time ensemble','class index']\n",
    "#sorted_df = df.sort_values(by = [\"Accuracy\",'Time FS'],ascending=[False,True]).groupby(\"File\", as_index=False).first()\n",
    "    df.to_csv(\"df_ensemble\"+ eachFile+\"s.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".deeplearningClass",
   "language": "python",
   "name": ".deeplearningclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
