{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"KnowledgeBase.csv\")\n",
    "df2 = pd.read_csv(\"KnowledgeBase_majorityvotecluster.csv\")\n",
    "df1.fillna(0,inplace=True)\n",
    "df2.fillna(0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_char_raw1 = df1[[ 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "df_quality_raw1 = df1[['Completeness', 'Conciseness', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'LabelIssuesPerc', 'FeatureAlgo']]\n",
    "\n",
    "df_raw1 = df1[['Completeness', 'Conciseness', 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'LabelIssuesPerc','nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "\n",
    "df_char_bin1 = df1[['cor.mean_bins', 'cov.mean_bins',\n",
    "       'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins',\n",
    "       'iq_range.mean_bins', 'kurtosis.mean_bins', 'mad.mean_bins',\n",
    "       'max.mean_bins', 'mean.mean_bins', 'median.mean_bins', 'min.mean_bins',\n",
    "       'nr_cor_attr_bins', 'nr_norm_bins', 'nr_outliers_bins',\n",
    "       'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "       'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins',\n",
    "       'attr_to_inst_bins', 'inst_to_attr_bins',\n",
    "       'nr_attr_bins', 'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins',\n",
    "       'attr_conc.mean_bins', 'attr_ent.mean_bins', 'ena_bins',\n",
    "       'snr.mean_bins', 'cEntropy_bins','FeatureAlgo']]\n",
    "\n",
    "df_quality_bin1 = df1[['Completeness_bins',\n",
    "       'Conciseness_bins', 'LabelIssues_bins', 'ClassImbRatio_bins', 'OutlierPerc_bins',\n",
    "       'ClassOverlapPerc_bins','FeatureAlgo']]\n",
    "\n",
    "df_bin1 = df1[['Completeness_bins',\n",
    "       'Conciseness_bins', 'cor.mean_bins', 'cov.mean_bins',\n",
    "       'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins',\n",
    "       'iq_range.mean_bins', 'kurtosis.mean_bins', 'mad.mean_bins',\n",
    "       'max.mean_bins', 'mean.mean_bins', 'median.mean_bins', 'min.mean_bins',\n",
    "       'nr_cor_attr_bins', 'nr_norm_bins', 'nr_outliers_bins',\n",
    "       'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "       'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins',\n",
    "       'LabelIssues_bins', 'ClassImbRatio_bins', 'OutlierPerc_bins',\n",
    "       'ClassOverlapPerc_bins', 'attr_to_inst_bins', 'inst_to_attr_bins',\n",
    "       'nr_attr_bins', 'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins',\n",
    "       'attr_conc.mean_bins', 'attr_ent.mean_bins', 'ena_bins',\n",
    "       'snr.mean_bins', 'cEntropy_bins', 'FeatureAlgo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_char_raw2 = df2[[ 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "df_quality_raw2 = df2[['Completeness', 'Conciseness', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'LabelIssuesPerc', 'FeatureAlgo']]\n",
    "\n",
    "df_raw2 = df2[['Completeness', 'Conciseness', 'cor.mean', 'cov.mean', 'eigenvalues.mean', 'g_mean.mean', 'h_mean.mean', 'iq_range.mean', \n",
    " 'kurtosis.mean', 'mad.mean', 'max.mean', 'mean.mean', 'median.mean', 'min.mean', 'nr_cor_attr', 'nr_norm', 'nr_outliers', 'range.mean', 'sd.mean', 'skewness.mean', 'sparsity.mean',\n",
    " 't_mean.mean', 'var.mean', 'ClassImbRatio', 'ClassOverlapPerc', 'OutlierPerc', 'attr_to_inst', 'inst_to_attr', 'nr_attr', 'nr_bin', 'nr_inst', 'nr_num','attr_conc.mean', \n",
    " 'attr_ent.mean', 'LabelIssuesPerc','nUnique', 'ena', 'snr.mean', 'cEntropy', 'FeatureAlgo']]\n",
    "\n",
    "\n",
    "df_char_bin2 = df2[['cor.mean_bins', 'cov.mean_bins',\n",
    "       'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins',\n",
    "       'iq_range.mean_bins', 'kurtosis.mean_bins', 'mad.mean_bins',\n",
    "       'max.mean_bins', 'mean.mean_bins', 'median.mean_bins', 'min.mean_bins',\n",
    "       'nr_cor_attr_bins', 'nr_norm_bins', 'nr_outliers_bins',\n",
    "       'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "       'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins',\n",
    "       'attr_to_inst_bins', 'inst_to_attr_bins',\n",
    "       'nr_attr_bins', 'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins',\n",
    "       'attr_conc.mean_bins', 'attr_ent.mean_bins', 'ena_bins',\n",
    "       'snr.mean_bins', 'cEntropy_bins','FeatureAlgo']]\n",
    "\n",
    "df_quality_bin2 = df2[['Completeness_bins',\n",
    "       'Conciseness_bins', 'LabelIssues_bins', 'ClassImbRatio_bins', 'OutlierPerc_bins',\n",
    "       'ClassOverlapPerc_bins','FeatureAlgo']]\n",
    "\n",
    "df_bin2 = df2[['Completeness_bins',\n",
    "       'Conciseness_bins', 'cor.mean_bins', 'cov.mean_bins',\n",
    "       'eigenvalues.mean_bins', 'g_mean.mean_bins', 'h_mean.mean_bins',\n",
    "       'iq_range.mean_bins', 'kurtosis.mean_bins', 'mad.mean_bins',\n",
    "       'max.mean_bins', 'mean.mean_bins', 'median.mean_bins', 'min.mean_bins',\n",
    "       'nr_cor_attr_bins', 'nr_norm_bins', 'nr_outliers_bins',\n",
    "       'range.mean_bins', 'sd.mean_bins', 'skewness.mean_bins',\n",
    "       'sparsity.mean_bins', 't_mean.mean_bins', 'var.mean_bins',\n",
    "       'LabelIssues_bins', 'ClassImbRatio_bins', 'OutlierPerc_bins',\n",
    "       'ClassOverlapPerc_bins', 'attr_to_inst_bins', 'inst_to_attr_bins',\n",
    "       'nr_attr_bins', 'nr_inst_bins', 'nr_num_bins', 'nr_bin_bins',\n",
    "       'attr_conc.mean_bins', 'attr_ent.mean_bins', 'ena_bins',\n",
    "       'snr.mean_bins', 'cEntropy_bins', 'FeatureAlgo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chisquare    92\n",
      "GR           51\n",
      "fcbf         16\n",
      "relief        8\n",
      "MI            6\n",
      "Name: FeatureAlgo, dtype: int64\n",
      "chisquare    86\n",
      "GR           54\n",
      "fcbf         17\n",
      "MI            8\n",
      "relief        8\n",
      "Name: FeatureAlgo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1['FeatureAlgo'].value_counts())\n",
    "print(df2['FeatureAlgo'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************KNN - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.766346                    0.233654   \n",
      "df_char_raw                     0.766346                    0.233654   \n",
      "df_quality_raw                  0.728397                    0.271603   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.793478        0.206522  0.851789  0.793478  0.779117   \n",
      "df_char_raw         0.793478        0.206522  0.851789  0.793478  0.779117   \n",
      "df_quality_raw      0.706522        0.293478  0.686563  0.706522  0.658954   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[12, 0, 0, 3, 0], [0, 16, 0, 0, 0], [8, 0, 6,...  \n",
      "df_char_raw     [[12, 0, 0, 3, 0], [0, 16, 0, 0, 0], [8, 0, 6,...  \n",
      "df_quality_raw  [[12, 1, 0, 2, 0], [0, 16, 0, 0, 0], [9, 2, 2,...  \n",
      "\n",
      "\n",
      "**************KNN - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.694501                    0.305499   \n",
      "df_char_raw                     0.694501                    0.305499   \n",
      "df_quality_raw                  0.627792                    0.372208   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.802326        0.197674  0.786296  0.802326  0.786978   \n",
      "df_char_raw         0.802326        0.197674  0.786296  0.802326  0.786978   \n",
      "df_quality_raw       0.77907         0.22093  0.726529   0.77907   0.74314   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[6, 4, 6, 0, 0], [0, 14, 0, 0, 0], [3, 0, 6, ...  \n",
      "df_char_raw     [[6, 4, 6, 0, 0], [0, 14, 0, 0, 0], [3, 0, 6, ...  \n",
      "df_quality_raw  [[10, 1, 2, 2, 1], [0, 14, 0, 0, 0], [6, 2, 1,...  \n"
     ]
    }
   ],
   "source": [
    "def evaluate_knn(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y) \n",
    "\n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    pipeline = Pipeline([('ros', ros), ('smote', smote)])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(knn_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "\n",
    "datasets1 = {\n",
    "    'df_raw': df_raw1,\n",
    "    'df_char_raw': df_char_raw1,\n",
    "    'df_quality_raw': df_quality_raw1\n",
    "}\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************KNN - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "datasets2 = {\n",
    "    'df_raw': df_raw2,\n",
    "    'df_char_raw': df_char_raw2,\n",
    "    'df_quality_raw': df_quality_raw2\n",
    "}\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************KNN - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************DT - 0.1_0.06**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.793558                    0.206442   \n",
      "df_normalised_char                     0.725583                    0.274417   \n",
      "df_normalised_quality                  0.467494                    0.532506   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.836957        0.163043  0.834574  0.836957   \n",
      "df_normalised_char         0.728261        0.271739  0.727093  0.728261   \n",
      "df_normalised_quality      0.586957        0.413043  0.684569  0.586957   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.826884   \n",
      "df_normalised_char     0.707443   \n",
      "df_normalised_quality  0.542362   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[13, 0, 1, 1, 0], [0, 16, 0, 0, 0], [6, 1, 9,...  \n",
      "df_normalised_char     [[8, 3, 1, 1, 2], [0, 16, 0, 0, 0], [8, 2, 6, ...  \n",
      "df_normalised_quality  [[10, 4, 0, 1, 0], [0, 16, 0, 0, 0], [4, 4, 2,...  \n",
      "\n",
      "\n",
      "**************DT - Majority clustering**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.772975                    0.227025   \n",
      "df_normalised_char                     0.723572                    0.276428   \n",
      "df_normalised_quality                  0.453367                    0.546633   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.860465        0.139535  0.861404  0.860465   \n",
      "df_normalised_char         0.755814        0.244186  0.743317  0.755814   \n",
      "df_normalised_quality      0.581395        0.418605  0.619657  0.581395   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.856757   \n",
      "df_normalised_char     0.738372   \n",
      "df_normalised_quality  0.568049   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[10, 0, 4, 0, 2], [0, 14, 0, 0, 0], [2, 0, 8,...  \n",
      "df_normalised_char     [[7, 1, 3, 2, 3], [0, 14, 0, 0, 0], [4, 1, 5, ...  \n",
      "df_normalised_quality  [[9, 5, 1, 0, 1], [2, 10, 0, 2, 0], [4, 2, 2, ...  \n"
     ]
    }
   ],
   "source": [
    "#decision\n",
    "\n",
    "tree_classifier = None\n",
    "X_train = X_test = y_train =y_test = None\n",
    "def evaluate_decision_tree(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  \n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    pipeline = Pipeline([('ros', ros), ('smote', smote)])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y)\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)    \n",
    "    global tree_classifier\n",
    "    tree_classifier = DecisionTreeClassifier(random_state=random_state)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(tree_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "    y_pred = tree_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************DT - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************DT - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, _tree\n",
    "\n",
    "\n",
    "def get_rules_with_support_confidence(tree_model, feature_names, X, y, label_encoder):\n",
    "    tree_ = tree_model.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    \n",
    "    rules = []\n",
    "\n",
    "    def recurse(node, path):\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            left_path = path.copy()\n",
    "            left_path.append(f\"({name} <= {threshold:.3f})\")\n",
    "            recurse(tree_.children_left[node], left_path)\n",
    "\n",
    "            right_path = path.copy()\n",
    "            right_path.append(f\"({name} > {threshold:.3f})\")\n",
    "            recurse(tree_.children_right[node], right_path)\n",
    "        else:\n",
    "            path_str = \" and \".join(path)\n",
    "            support = tree_.n_node_samples[node] / tree_.n_node_samples[0]\n",
    "            value = tree_.value[node][0]\n",
    "            predicted_class_index = np.argmax(value)\n",
    "            predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "            confidence = value[predicted_class_index] / np.sum(value)\n",
    "            rules.append((path_str, predicted_class_label, support, confidence))\n",
    "\n",
    "    recurse(0, [])\n",
    "\n",
    "    return pd.DataFrame(rules, columns=[\"Rule\", \"Predicted_Class\", \"Support\", \"Confidence\"])\n",
    "\n",
    "\n",
    "def train_model_with_label_names(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    # Encode target labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # Set up resampling\n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "    smote = SMOTE(random_state=33)\n",
    "    pipeline = Pipeline([('ros', ros), ('smote', smote)])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y_encoded)\n",
    "\n",
    "    # Train/test split and cross-validation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "    tree_classifier = DecisionTreeClassifier(random_state=random_state)\n",
    "    cross_val_scores = cross_val_score(tree_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "\n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Optional: store the label encoder for decoding predictions later\n",
    "    return tree_classifier, label_encoder\n",
    "\n",
    "\n",
    "tree_classifier,label_encoder = train_model_with_label_names(df_raw2)\n",
    "\n",
    "rule_df = get_rules_with_support_confidence(tree_classifier, feature_names=X_train.columns.tolist(), X=X_train, y=y_train, label_encoder=label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_df.to_csv(\"rulesfrommajorityclustering.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************Distance based - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.880435                    0.119565   \n",
      "df_char_raw                     0.880435                    0.119565   \n",
      "df_quality_raw                  0.815217                    0.184783   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.880435        0.119565   0.90952  0.880435  0.864405   \n",
      "df_char_raw         0.880435        0.119565   0.90952  0.880435  0.864405   \n",
      "df_quality_raw      0.836957        0.163043  0.839751  0.836957  0.819701   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[15, 0, 0, 0, 0], [0, 16, 0, 0, 0], [6, 0, 8,...  \n",
      "df_char_raw     [[15, 0, 0, 0, 0], [0, 16, 0, 0, 0], [6, 0, 8,...  \n",
      "df_quality_raw  [[12, 0, 2, 1, 0], [0, 16, 0, 0, 0], [8, 1, 7,...  \n",
      "\n",
      "\n",
      "**************Distance based - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.862791                    0.137209   \n",
      "df_char_raw                     0.862791                    0.137209   \n",
      "df_quality_raw                  0.818605                    0.181395   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.918605       0.0813953  0.915786  0.918605  0.914564   \n",
      "df_char_raw         0.918605       0.0813953  0.915786  0.918605  0.914564   \n",
      "df_quality_raw      0.860465        0.139535  0.850252  0.860465   0.85168   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[15, 0, 1, 0, 0], [0, 14, 0, 0, 0], [3, 0, 7,...  \n",
      "df_char_raw     [[15, 0, 1, 0, 0], [0, 14, 0, 0, 0], [3, 0, 7,...  \n",
      "df_quality_raw  [[12, 0, 2, 2, 0], [0, 14, 0, 0, 0], [5, 1, 5,...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "metric_name = 'Euclidean'\n",
    "metric_func = lambda X_train, X_test: np.sqrt(((X_train.values[:, np.newaxis] - X_test.values) ** 2).sum(axis=2))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=33)\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "\n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "    smote = SMOTE(random_state=33)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('ros', ros),\n",
    "        ('smote', smote)\n",
    "    ])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y_encoded)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    \n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predicted_labels = y_train[nearest_indices]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    results1[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "\n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "    smote = SMOTE(random_state=33)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('ros', ros),\n",
    "        ('smote', smote)\n",
    "    ])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y_encoded)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    \n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predicted_labels = y_train[nearest_indices]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    results2[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"**************Distance based - 0.1_0.06**************\\n\")\n",
    "print(results_df1)\n",
    "\n",
    "print(\"\\n\\n**************Distance based - Majority clustering**************\\n\")\n",
    "print(results_df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************Unification - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.950276                   0.0497236   \n",
      "df_char_raw                     0.950276                   0.0497236   \n",
      "df_quality_raw                  0.692415                    0.307585   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.671642        0.328358  0.614126  0.671642  0.640547   \n",
      "df_char_raw         0.671642        0.328358  0.614126  0.671642  0.640547   \n",
      "df_quality_raw      0.126582        0.873418   0.12294  0.126582  0.122327   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[5, 1, 0, 0, 1], [0, 9, 0, 2, 1], [1, 2, 0, 3...  \n",
      "df_char_raw     [[5, 1, 0, 0, 1], [0, 9, 0, 2, 1], [1, 2, 0, 3...  \n",
      "df_quality_raw  [[2, 1, 1, 3, 6], [2, 1, 3, 4, 4], [5, 5, 1, 4...  \n",
      "\n",
      "\n",
      "**************Unification - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_raw                          0.969074                   0.0309263   \n",
      "df_char_raw                     0.969074                   0.0309263   \n",
      "df_quality_raw                   0.72722                     0.27278   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_raw              0.492537        0.507463   0.47457  0.492537  0.481181   \n",
      "df_char_raw         0.492537        0.507463   0.47457  0.492537  0.481181   \n",
      "df_quality_raw      0.295775        0.704225  0.295713  0.295775  0.294916   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_raw          [[4, 2, 0, 0, 5], [1, 8, 0, 2, 3], [0, 0, 0, 2...  \n",
      "df_char_raw     [[4, 2, 0, 0, 5], [1, 8, 0, 2, 3], [0, 0, 0, 2...  \n",
      "df_quality_raw  [[1, 2, 1, 3, 6], [4, 3, 0, 2, 2], [1, 2, 2, 2...  \n"
     ]
    }
   ],
   "source": [
    "def unify_features(test_sample, train_data, train_labels):\n",
    "    test_features = test_sample.values\n",
    "    matching_indices = np.all(train_data == test_features, axis=1)\n",
    "    if matching_indices.any():\n",
    "        matching_labels = train_labels[matching_indices]\n",
    "        return np.unique(matching_labels)\n",
    "    return [\"unknown\"]\n",
    "\n",
    "def evaluate_unification(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    pipeline = Pipeline([('ros', ros), ('smote', smote)])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y_encoded)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        predicted_labels = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "            predicted_labels.append(label)\n",
    "        \n",
    "        predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "        valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        if not valid_indices:\n",
    "            continue\n",
    "        \n",
    "        valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "\n",
    "        valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "        cv_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "       \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    predicted_labels = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "        predicted_labels.append(label)\n",
    "    predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "    valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        \n",
    "    valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "    valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "    precision = precision_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(valid_truth, valid_predictions)    \n",
    "    test_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "\n",
    "    return {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_unification(df)\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_unification(df)\n",
    "\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"**************Unification - 0.1_0.06**************\\n\")\n",
    "print(results_df1)\n",
    "\n",
    "print(\"\\n\\n**************Unification - Majority clustering**************\\n\")\n",
    "print(results_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIN data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************KNN - 0.1_0.06**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.646649                    0.353351   \n",
      "df_char_bin                      0.41555                     0.58445   \n",
      "df_quality_bin                  0.456312                    0.543688   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.619565        0.380435  0.688844  0.619565  0.604658   \n",
      "df_char_bin         0.380435        0.619565  0.611985  0.380435   0.40481   \n",
      "df_quality_bin      0.445652        0.554348  0.558818  0.445652  0.462111   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[10, 0, 1, 4, 0], [0, 16, 0, 0, 0], [11, 0, 4...  \n",
      "df_char_bin     [[9, 4, 0, 2, 0], [6, 9, 0, 1, 0], [11, 1, 6, ...  \n",
      "df_quality_bin  [[9, 0, 3, 2, 1], [3, 13, 0, 0, 0], [10, 0, 4,...  \n",
      "\n",
      "\n",
      "**************KNN - Majority clustering**************\n",
      "\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.630733                    0.369267   \n",
      "df_char_bin                      0.45341                     0.54659   \n",
      "df_quality_bin                  0.386658                    0.613342   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.616279        0.383721  0.609984  0.616279   0.59338   \n",
      "df_char_bin         0.406977        0.593023  0.450363  0.406977  0.392889   \n",
      "df_quality_bin      0.523256        0.476744  0.647251  0.523256  0.505924   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[4, 0, 2, 8, 2], [0, 14, 0, 0, 0], [4, 1, 3, ...  \n",
      "df_char_bin     [[3, 2, 3, 7, 1], [2, 10, 0, 2, 0], [4, 2, 2, ...  \n",
      "df_quality_bin  [[11, 0, 0, 5, 0], [4, 8, 0, 2, 0], [6, 1, 2, ...  \n"
     ]
    }
   ],
   "source": [
    "def evaluate_knn(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "\n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    pipeline = Pipeline([('ros', ros), ('smote', smote)])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y_encoded)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(knn_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "datasets1 = {\n",
    "    'df_bin': df_bin1,\n",
    "    'df_char_bin': df_char_bin1,\n",
    "    'df_quality_bin': df_quality_bin1\n",
    "}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************KNN - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "datasets2 = {\n",
    "    'df_bin': df_bin2,\n",
    "    'df_char_bin': df_char_bin2,\n",
    "    'df_quality_bin': df_quality_bin2\n",
    "}\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************KNN - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.733728                    0.266272   \n",
      "df_char_bin                     0.483895                    0.516105   \n",
      "df_quality_bin                  0.546168                    0.453832   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin               0.73913         0.26087  0.824438   0.73913  0.694898   \n",
      "df_char_bin         0.467391        0.532609  0.577575  0.467391  0.416005   \n",
      "df_quality_bin      0.565217        0.434783   0.64084  0.565217  0.530072   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[12, 0, 0, 1, 2], [0, 16, 0, 0, 0], [13, 1, 2...  \n",
      "df_char_bin     [[5, 4, 0, 2, 4], [0, 9, 0, 1, 6], [8, 1, 2, 2...  \n",
      "df_quality_bin  [[8, 1, 0, 1, 5], [0, 16, 0, 0, 0], [8, 1, 5, ...  \n"
     ]
    }
   ],
   "source": [
    "def evaluate_decision_tree(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "\n",
    "    # SMOTE\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    pipeline = Pipeline([('ros', ros), ('smote', smote)])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)    \n",
    "    tree_classifier = DecisionTreeClassifier(random_state=random_state)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(tree_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "    y_pred = tree_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "datasets1 = {\n",
    "    'df_bin': df_bin1,\n",
    "    'df_char_bin': df_char_bin1,\n",
    "    'df_quality_bin': df_quality_bin1\n",
    "}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************DT - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "datasets2 = {\n",
    "    'df_bin': df_bin2,\n",
    "    'df_char_bin': df_char_bin2,\n",
    "    'df_quality_bin': df_quality_bin2\n",
    "}\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************DT - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Distance based - 0.1_0.06*************\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.602174                    0.397826   \n",
      "df_char_bin                     0.345652                    0.654348   \n",
      "df_quality_bin                  0.341304                    0.658696   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.717391        0.282609  0.742325  0.717391   0.68343   \n",
      "df_char_bin         0.445652        0.554348  0.551751  0.445652  0.442387   \n",
      "df_quality_bin       0.51087         0.48913   0.63242   0.51087  0.504913   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[11, 0, 1, 1, 2], [0, 16, 0, 0, 0], [11, 0, 3...  \n",
      "df_char_bin     [[6, 4, 0, 2, 3], [0, 9, 0, 7, 0], [9, 1, 4, 4...  \n",
      "df_quality_bin  [[12, 0, 0, 2, 1], [0, 16, 0, 0, 0], [10, 0, 4...  \n",
      "\n",
      "\n",
      "***************Distance based - Majority cluster*************\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.595349                    0.404651   \n",
      "df_char_bin                      0.32093                     0.67907   \n",
      "df_quality_bin                  0.311628                    0.688372   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin               0.77907         0.22093  0.772697   0.77907   0.75598   \n",
      "df_char_bin          0.44186         0.55814  0.475264   0.44186  0.415368   \n",
      "df_quality_bin      0.488372        0.511628  0.512778  0.488372  0.493471   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[10, 0, 0, 4, 2], [0, 14, 0, 0, 0], [6, 0, 3,...  \n",
      "df_char_bin     [[5, 1, 1, 3, 6], [2, 4, 0, 0, 8], [4, 0, 3, 1...  \n",
      "df_quality_bin  [[7, 0, 0, 4, 5], [2, 8, 2, 0, 2], [2, 1, 7, 1...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "datasets1 = {\n",
    "    'df_bin': df_bin1,\n",
    "    'df_char_bin': df_char_bin1,\n",
    "    'df_quality_bin': df_quality_bin1\n",
    "}\n",
    "datasets2 = {\n",
    "    'df_bin': df_bin2,\n",
    "    'df_char_bin': df_char_bin2,\n",
    "    'df_quality_bin': df_quality_bin2\n",
    "}\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "\n",
    "metric_name = 'Euclidean'\n",
    "metric_func = lambda X_train, X_test: np.sqrt(((X_train.values[:, np.newaxis] - X_test.values) ** 2).sum(axis=2))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=33)\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "    \n",
    "    cv_accuracies = []\n",
    "\n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "    smote = SMOTE(random_state=33)\n",
    "    pipeline = Pipeline([('ros', ros), ('smote', smote)])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y_encoded)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    \n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predicted_labels = y_train[nearest_indices]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    results1[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "    \n",
    "    cv_accuracies = []\n",
    "\n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "    smote = SMOTE(random_state=33)\n",
    "    pipeline = Pipeline([('ros', ros), ('smote', smote)])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y_encoded)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    \n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predicted_labels = y_train[nearest_indices]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    results2[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"***************Distance based - 0.1_0.06*************\")\n",
    "print(results_df1)\n",
    "print(\"\\n\\n***************Distance based - Majority cluster*************\")\n",
    "print(results_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Unification - 0.1_0.06**********************\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.192134                    0.807866   \n",
      "df_char_bin                     0.215135                    0.784865   \n",
      "df_quality_bin                  0.204831                    0.795169   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.174419        0.825581  0.191445  0.174419  0.175969   \n",
      "df_char_bin         0.197802        0.802198  0.192338  0.197802   0.19015   \n",
      "df_quality_bin      0.230769        0.769231  0.221813  0.230769  0.217865   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[3, 0, 4, 4, 1], [0, 2, 4, 9, 1], [6, 2, 2, 4...  \n",
      "df_char_bin     [[5, 2, 2, 2, 4], [4, 2, 4, 3, 3], [3, 3, 6, 5...  \n",
      "df_quality_bin  [[7, 2, 4, 2, 0], [2, 1, 7, 2, 4], [2, 3, 5, 4...  \n",
      "***************Unification - majority voting**********************\n",
      "               Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_bin                          0.208377                    0.791623   \n",
      "df_char_bin                     0.211609                    0.788391   \n",
      "df_quality_bin                  0.186968                    0.813032   \n",
      "\n",
      "               Test Accuracy Test Error Rate Precision    Recall  F1 Score  \\\n",
      "df_bin              0.265823        0.734177  0.294821  0.265823  0.272599   \n",
      "df_char_bin         0.197674        0.802326  0.235168  0.197674  0.206941   \n",
      "df_quality_bin      0.127907        0.872093  0.172903  0.127907  0.136473   \n",
      "\n",
      "                                                 Confusion Matrix  \n",
      "df_bin          [[4, 2, 3, 4, 2], [1, 4, 3, 2, 4], [4, 1, 3, 1...  \n",
      "df_char_bin     [[4, 4, 3, 4, 1], [3, 2, 5, 3, 1], [3, 1, 2, 5...  \n",
      "df_quality_bin  [[2, 0, 6, 4, 4], [4, 2, 2, 6, 0], [4, 1, 1, 2...  \n"
     ]
    }
   ],
   "source": [
    "def unify_features(test_sample, train_data, train_labels):\n",
    "    test_features = test_sample.values\n",
    "    matching_indices = np.all(train_data == test_features, axis=1)\n",
    "    if matching_indices.any():\n",
    "        matching_labels = train_labels[matching_indices]\n",
    "        return np.unique(matching_labels)\n",
    "    return [\"unknown\"]\n",
    "\n",
    "def evaluate_unification(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X:\n",
    "        X[col] = label_encoder.fit_transform(X[col])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "    \n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    pipeline = Pipeline([('ros', ros), ('smote', smote)])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y_encoded)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        predicted_labels = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "            predicted_labels.append(label)\n",
    "        \n",
    "        predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "        valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        if not valid_indices:\n",
    "            continue\n",
    "        \n",
    "        valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "\n",
    "        valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "        cv_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "       \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    predicted_labels = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "        predicted_labels.append(label)\n",
    "    predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "    valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        \n",
    "    valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "    valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "    precision = precision_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(valid_truth, valid_predictions)    \n",
    "    test_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "\n",
    "    return {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "datasets1 = {\n",
    "    'df_bin': df_bin1,\n",
    "    'df_char_bin': df_char_bin1,\n",
    "    'df_quality_bin': df_quality_bin1\n",
    "}\n",
    "datasets2 = {\n",
    "    'df_bin': df_bin2,\n",
    "    'df_char_bin': df_char_bin2,\n",
    "    'df_quality_bin': df_quality_bin2\n",
    "}\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_unification(df)\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_unification(df)\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"***************Unification - 0.1_0.06**********************\")\n",
    "print(results_df1)\n",
    "print(\"***************Unification - majority voting**********************\")\n",
    "print(results_df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_normalised1 = pd.read_csv(\"NormalisedDataset_01006.csv\")\n",
    "df_normalised2 = pd.read_csv(\"NormalisedDataset_majoritycluster.csv\")\n",
    "\n",
    "df_normalised_quality1 = df_normalised1[['Completeness_normalized', 'Conciseness_normalized',  'ClassImbRatio_normalized', 'ClassOverlapPerc_normalized',\n",
    "       'OutlierPerc_normalized',  'LabelIssuesPerc_normalized', 'FeatureAlgo_normalized']]\n",
    "df_normalised_char1 = df_normalised1[[ 'cor.mean_normalized', 'cov.mean_normalized',\n",
    "       'eigenvalues.mean_normalized', 'g_mean.mean_normalized',\n",
    "       'h_mean.mean_normalized', 'iq_range.mean_normalized',\n",
    "       'kurtosis.mean_normalized', 'mad.mean_normalized',\n",
    "       'max.mean_normalized', 'mean.mean_normalized', 'median.mean_normalized',\n",
    "       'min.mean_normalized', 'nr_cor_attr_normalized', 'nr_norm_normalized',\n",
    "       'nr_outliers_normalized', 'range.mean_normalized', 'sd.mean_normalized',\n",
    "       'skewness.mean_normalized', 'sparsity.mean_normalized',\n",
    "       't_mean.mean_normalized', 'var.mean_normalized',\n",
    "        'attr_to_inst_normalized',\n",
    "       'inst_to_attr_normalized', 'nr_attr_normalized', 'nr_bin_normalized',\n",
    "       'nr_inst_normalized', 'nr_num_normalized', 'attr_conc.mean_normalized',\n",
    "       'attr_ent.mean_normalized', 'nUnique_normalized', 'ena_normalized', 'snr.mean_normalized',\n",
    "       'cEntropy_normalized', 'FeatureAlgo_normalized']]\n",
    "df_normalised_quality2 = df_normalised2[['Completeness_normalized', 'Conciseness_normalized',  'ClassImbRatio_normalized', 'ClassOverlapPerc_normalized',\n",
    "       'OutlierPerc_normalized',  'LabelIssuesPerc_normalized', 'FeatureAlgo_normalized']]\n",
    "df_normalised_char2 = df_normalised2[[ 'cor.mean_normalized', 'cov.mean_normalized',\n",
    "       'eigenvalues.mean_normalized', 'g_mean.mean_normalized',\n",
    "       'h_mean.mean_normalized', 'iq_range.mean_normalized',\n",
    "       'kurtosis.mean_normalized', 'mad.mean_normalized',\n",
    "       'max.mean_normalized', 'mean.mean_normalized', 'median.mean_normalized',\n",
    "       'min.mean_normalized', 'nr_cor_attr_normalized', 'nr_norm_normalized',\n",
    "       'nr_outliers_normalized', 'range.mean_normalized', 'sd.mean_normalized',\n",
    "       'skewness.mean_normalized', 'sparsity.mean_normalized',\n",
    "       't_mean.mean_normalized', 'var.mean_normalized',\n",
    "        'attr_to_inst_normalized',\n",
    "       'inst_to_attr_normalized', 'nr_attr_normalized', 'nr_bin_normalized',\n",
    "       'nr_inst_normalized', 'nr_num_normalized', 'attr_conc.mean_normalized',\n",
    "       'attr_ent.mean_normalized', 'nUnique_normalized', 'ena_normalized', 'snr.mean_normalized',\n",
    "       'cEntropy_normalized', 'FeatureAlgo_normalized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************KNN - 0.1_0.06**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                           0.69304                     0.30696   \n",
      "df_normalised_char                     0.654795                    0.345205   \n",
      "df_normalised_quality                  0.432099                    0.567901   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised               0.76087         0.23913  0.750695   0.76087   \n",
      "df_normalised_char         0.684783        0.315217  0.689701  0.684783   \n",
      "df_normalised_quality      0.423913        0.576087   0.40209  0.423913   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.739388   \n",
      "df_normalised_char     0.656033   \n",
      "df_normalised_quality   0.37494   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[9, 0, 3, 2, 1], [0, 16, 0, 0, 0], [4, 1, 7, ...  \n",
      "df_normalised_char     [[5, 0, 3, 5, 2], [0, 9, 0, 7, 0], [5, 2, 7, 2...  \n",
      "df_normalised_quality  [[9, 1, 0, 4, 1], [0, 3, 0, 13, 0], [7, 1, 0, ...  \n",
      "\n",
      "\n",
      "**************KNN - Majority clustering**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.688704                    0.311296   \n",
      "df_normalised_char                     0.653836                    0.346164   \n",
      "df_normalised_quality                  0.409506                    0.590494   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.790698        0.209302  0.829312  0.790698   \n",
      "df_normalised_char         0.755814        0.244186  0.752807  0.755814   \n",
      "df_normalised_quality      0.627907        0.372093  0.707972  0.627907   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.770884   \n",
      "df_normalised_char     0.735443   \n",
      "df_normalised_quality  0.614595   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[5, 1, 7, 0, 3], [0, 14, 0, 0, 0], [0, 1, 7, ...  \n",
      "df_normalised_char     [[6, 1, 4, 1, 4], [0, 14, 0, 0, 0], [3, 2, 5, ...  \n",
      "df_normalised_quality  [[10, 4, 0, 1, 1], [0, 12, 0, 2, 0], [3, 1, 2,...  \n"
     ]
    }
   ],
   "source": [
    "def evaluate_knn(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "\n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    pipeline = Pipeline([('ros', ros), ('smote', smote)])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y_encoded)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(knn_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "datasets1 = {\n",
    "    'df_normalised': df_normalised1,\n",
    "    'df_normalised_char': df_normalised_char1,\n",
    "    'df_normalised_quality': df_normalised_quality1\n",
    "}\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************KNN - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "datasets2 = {\n",
    "    'df_normalised': df_normalised2,\n",
    "    'df_normalised_char': df_normalised_char2,\n",
    "    'df_normalised_quality': df_normalised_quality2\n",
    "}\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_knn(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************KNN - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************DT - 0.1_0.06**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.793558                    0.206442   \n",
      "df_normalised_char                     0.725583                    0.274417   \n",
      "df_normalised_quality                  0.467494                    0.532506   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.836957        0.163043  0.834574  0.836957   \n",
      "df_normalised_char         0.728261        0.271739  0.727093  0.728261   \n",
      "df_normalised_quality      0.586957        0.413043  0.684569  0.586957   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.826884   \n",
      "df_normalised_char     0.707443   \n",
      "df_normalised_quality  0.542362   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[13, 0, 1, 1, 0], [0, 16, 0, 0, 0], [6, 1, 9,...  \n",
      "df_normalised_char     [[8, 3, 1, 1, 2], [0, 16, 0, 0, 0], [8, 2, 6, ...  \n",
      "df_normalised_quality  [[10, 4, 0, 1, 0], [0, 16, 0, 0, 0], [4, 4, 2,...  \n",
      "\n",
      "\n",
      "**************DT - Majority clustering**************\n",
      "\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.772975                    0.227025   \n",
      "df_normalised_char                     0.723572                    0.276428   \n",
      "df_normalised_quality                  0.453367                    0.546633   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.860465        0.139535  0.861404  0.860465   \n",
      "df_normalised_char         0.755814        0.244186  0.743317  0.755814   \n",
      "df_normalised_quality      0.581395        0.418605  0.619657  0.581395   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.856757   \n",
      "df_normalised_char     0.738372   \n",
      "df_normalised_quality  0.568049   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[10, 0, 4, 0, 2], [0, 14, 0, 0, 0], [2, 0, 8,...  \n",
      "df_normalised_char     [[7, 1, 3, 2, 3], [0, 14, 0, 0, 0], [4, 1, 5, ...  \n",
      "df_normalised_quality  [[9, 5, 1, 0, 1], [2, 10, 0, 2, 0], [4, 2, 2, ...  \n"
     ]
    }
   ],
   "source": [
    "#df_normalised decision\n",
    "def evaluate_decision_tree(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    pipeline = Pipeline([('ros', ros), ('smote', smote)])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)    \n",
    "    tree_classifier = DecisionTreeClassifier(random_state=random_state)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(tree_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    error_rates = 1 - cross_val_scores\n",
    "    \n",
    "    tree_classifier.fit(X_train, y_train)\n",
    "    y_pred = tree_classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Cross-Validation Accuracy': cross_val_scores.mean(),\n",
    "        'Cross-Validation Error Rate': error_rates.mean(),\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Error Rate': 1 - accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "\n",
    "results1 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df1 = pd.DataFrame(results1).transpose()\n",
    "print(\"**************DT - 0.1_0.06**************\\n\")\n",
    "print(comparison_df1)\n",
    "\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_decision_tree(df)\n",
    "\n",
    "comparison_df2 = pd.DataFrame(results2).transpose()\n",
    "print(\"\\n\\n**************DT - Majority clustering**************\\n\")\n",
    "print(comparison_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/d19125691/.local/lib/python3.6/site-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                           0.71087                     0.28913   \n",
      "df_normalised_char                      0.66087                     0.33913   \n",
      "df_normalised_quality                  0.378261                    0.621739   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised                  0.75            0.25   0.75865      0.75   \n",
      "df_normalised_char         0.717391        0.282609  0.732776  0.717391   \n",
      "df_normalised_quality      0.445652        0.554348  0.564696  0.445652   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.734839   \n",
      "df_normalised_char     0.705728   \n",
      "df_normalised_quality  0.475935   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[13, 0, 1, 1, 0], [0, 10, 0, 6, 0], [3, 1, 7,...  \n",
      "df_normalised_char     [[8, 0, 1, 4, 2], [0, 9, 0, 7, 0], [5, 2, 9, 2...  \n",
      "df_normalised_quality  [[4, 0, 9, 2, 0], [6, 6, 1, 3, 0], [5, 0, 7, 6...  \n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                           0.71087                     0.28913   \n",
      "df_normalised_char                      0.66087                     0.33913   \n",
      "df_normalised_quality                  0.378261                    0.621739   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised                  0.75            0.25   0.75865      0.75   \n",
      "df_normalised_char         0.717391        0.282609  0.732776  0.717391   \n",
      "df_normalised_quality      0.445652        0.554348  0.564696  0.445652   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.734839   \n",
      "df_normalised_char     0.705728   \n",
      "df_normalised_quality  0.475935   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[13, 0, 1, 1, 0], [0, 10, 0, 6, 0], [3, 1, 7,...  \n",
      "df_normalised_char     [[8, 0, 1, 4, 2], [0, 9, 0, 7, 0], [5, 2, 9, 2...  \n",
      "df_normalised_quality  [[4, 0, 9, 2, 0], [6, 6, 1, 3, 0], [5, 0, 7, 6...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "datasets1 = {\n",
    "    'df_normalised': df_normalised1,\n",
    "    'df_normalised_char': df_normalised_char1,\n",
    "    'df_normalised_quality': df_normalised_quality1\n",
    "}\n",
    "\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "datasets2 = {\n",
    "    'df_normalised': df_normalised2,\n",
    "    'df_normalised_char': df_normalised_char2,\n",
    "    'df_normalised_quality': df_normalised_quality2\n",
    "}\n",
    "\n",
    "metric_name = 'Euclidean'\n",
    "metric_func = lambda X_train, X_test: np.sqrt(((X_train.values[:, np.newaxis] - X_test.values) ** 2).sum(axis=2))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=33)\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "    \n",
    "    cv_accuracies = []\n",
    "\n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "    smote = SMOTE(random_state=33)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('ros', ros),\n",
    "        ('smote', smote)\n",
    "    ])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y_encoded)\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    \n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predicted_labels = y_train[nearest_indices]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    results1[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "    \n",
    "    cv_accuracies = []\n",
    "\n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "    smote = SMOTE(random_state=33)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('ros', ros),\n",
    "        ('smote', smote)\n",
    "    ])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y_encoded)\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        distances = metric_func(X_train, X_test)\n",
    "        \n",
    "        nearest_indices = np.argmin(distances, axis=0)\n",
    "        \n",
    "        predicted_labels = y_train[nearest_indices]\n",
    "        \n",
    "        cv_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    \n",
    "    distances = metric_func(X_train, X_test)\n",
    "    \n",
    "    nearest_indices = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predicted_labels = y_train[nearest_indices]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, predicted_labels, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    results1[name] = {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "\n",
    "print(results_df1)\n",
    "\n",
    "results_df2 = pd.DataFrame(results1).transpose()\n",
    "\n",
    "print(results_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Unification - 0.1_0.06**********************\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.303124                    0.696876   \n",
      "df_normalised_char                     0.171996                    0.828004   \n",
      "df_normalised_quality                  0.208484                    0.791516   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.156627        0.843373   0.14815  0.156627   \n",
      "df_normalised_char         0.162791        0.837209  0.184787  0.162791   \n",
      "df_normalised_quality      0.211111        0.788889  0.220671  0.211111   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.151515   \n",
      "df_normalised_char     0.170603   \n",
      "df_normalised_quality  0.210414   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[2, 3, 4, 3, 2], [2, 1, 3, 3, 4], [4, 3, 1, 5...  \n",
      "df_normalised_char     [[2, 6, 4, 3, 0], [2, 0, 2, 4, 5], [7, 2, 3, 4...  \n",
      "df_normalised_quality  [[5, 2, 3, 4, 1], [7, 3, 3, 3, 0], [2, 4, 4, 4...  \n",
      "***************Unification - majority voting**********************\n",
      "                      Cross-Validation Accuracy Cross-Validation Error Rate  \\\n",
      "df_normalised                          0.305895                    0.694105   \n",
      "df_normalised_char                     0.181982                    0.818018   \n",
      "df_normalised_quality                  0.197537                    0.802463   \n",
      "\n",
      "                      Test Accuracy Test Error Rate Precision    Recall  \\\n",
      "df_normalised              0.162162        0.837838  0.165907  0.162162   \n",
      "df_normalised_char           0.1125          0.8875  0.129081    0.1125   \n",
      "df_normalised_quality      0.277108        0.722892  0.317415  0.277108   \n",
      "\n",
      "                       F1 Score  \\\n",
      "df_normalised          0.163039   \n",
      "df_normalised_char     0.116623   \n",
      "df_normalised_quality  0.285418   \n",
      "\n",
      "                                                        Confusion Matrix  \n",
      "df_normalised          [[1, 3, 2, 3, 5], [2, 2, 4, 1, 2], [1, 1, 1, 2...  \n",
      "df_normalised_char     [[0, 4, 2, 6, 4], [4, 2, 5, 3, 0], [3, 1, 2, 0...  \n",
      "df_normalised_quality  [[3, 4, 4, 4, 1], [3, 2, 4, 3, 2], [1, 1, 4, 2...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def unify_features(test_sample, train_data, train_labels):\n",
    "    test_features = test_sample.values\n",
    "    matching_indices = np.all(train_data == test_features, axis=1)\n",
    "    if matching_indices.any():\n",
    "        matching_labels = train_labels[matching_indices]\n",
    "        return np.unique(matching_labels)\n",
    "    return [\"unknown\"]\n",
    "\n",
    "def evaluate_unification(df, random_state=33):\n",
    "    df = df.copy()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "   \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # Ensure y_encoded is 1D\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    test_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=33)\n",
    "\n",
    "    smote = SMOTE(random_state=33)\n",
    "\n",
    "    pipeline = Pipeline([('ros', ros), ('smote', smote)])\n",
    "\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X, y_encoded)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "        \n",
    "        predicted_labels = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "            predicted_labels.append(label)\n",
    "        \n",
    "        predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "        valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        if not valid_indices:\n",
    "            continue\n",
    "        \n",
    "        valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "\n",
    "        valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "        cv_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "       \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=33)\n",
    "    predicted_labels = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        label = unify_features(X_test.iloc[i], X_train, y_train)\n",
    "        predicted_labels.append(label)\n",
    "    predicted_labels = [item for sublist in predicted_labels for item in sublist]\n",
    "        \n",
    "    valid_indices = [i for i, label in enumerate(predicted_labels) if label != \"unknown\" and i < len(y_test)]\n",
    "        \n",
    "    valid_predictions = np.array([predicted_labels[i] for i in valid_indices])\n",
    "    valid_truth = np.array([y_test[i] for i in valid_indices])\n",
    "        \n",
    "    precision = precision_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(valid_truth, valid_predictions, average='weighted', zero_division=0)\n",
    "    confusion_matrix_result = confusion_matrix(valid_truth, valid_predictions)    \n",
    "    test_accuracy = accuracy_score(valid_truth, valid_predictions)\n",
    "\n",
    "    return {\n",
    "        'Cross-Validation Accuracy': np.mean(cv_accuracies),\n",
    "        'Cross-Validation Error Rate': np.mean([1 - acc for acc in cv_accuracies]),\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Error Rate': 1 - test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix_result\n",
    "    }\n",
    "\n",
    "\n",
    "results1 = {}\n",
    "results2 = {}\n",
    "\n",
    "for name, df in datasets1.items():\n",
    "    results1[name] = evaluate_unification(df)\n",
    "for name, df in datasets2.items():\n",
    "    results2[name] = evaluate_unification(df)\n",
    "\n",
    "results_df1 = pd.DataFrame(results1).transpose()\n",
    "results_df2 = pd.DataFrame(results2).transpose()\n",
    "\n",
    "print(\"***************Unification - 0.1_0.06**********************\")\n",
    "print(results_df1)\n",
    "print(\"***************Unification - majority voting**********************\")\n",
    "print(results_df2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".deeplearningClass",
   "language": "python",
   "name": ".deeplearningclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "551cc31cf9c5f57e891734d9457a3bee3a72ddf11065444d1381168b3dccfbde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
